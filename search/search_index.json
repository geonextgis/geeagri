{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to geeagri","text":"<p>A Python package for agricultural monitoring and analysis using Google Earth Engine</p> <ul> <li>GitHub repo: https://github.com/geonextgis/geeagri</li> <li>Documentation: https://geonextgis.github.io/geeagri</li> <li>PyPI: https://pypi.org/project/geeagri</li> <li>Notebooks: https://github.com/geonextgis/geeagri/tree/main/docs/examples</li> <li>License: MIT</li> </ul>"},{"location":"#introduction","title":"Introduction","text":"<p>geeagri is a Python package that integrates the power of Google Earth Engine (GEE) with domain-specific agricultural analysis. It enables scalable processing, downloading, and visualization of satellite data for crop monitoring, yield estimation, and agro-environmental assessment.</p> <p>This package builds upon geospatial tools like <code>geemap</code> and simplifies workflows for scientists, researchers, and policymakers working in agriculture. Whether you're interested in vegetation monitoring, drought assessment, phenology extraction, or productivity mapping, geeagri offers tools and prebuilt pipelines to make your analysis easier and faster.</p> <p>geeagri is ideal for: - Researchers working with satellite-derived agricultural indicators. - Practitioners and analysts from development, environmental, and governmental organizations. - Students and educators looking to learn remote sensing for agriculture.</p> <p>For a complete list of examples and use cases, visit the notebooks section.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Extracting long-term time series data from GEE for both point and polygon geometries.</li> <li>Extract image patches from satellite imagery in GEE to support local-scale computer vision model training.</li> <li>Quickly transform complex multivariate datasets into a few principal components while preserving critical information.</li> <li>Easy implementation of Harmonic Regression on vegetation or climate indices.</li> </ul>"},{"location":"analysis/","title":"analysis module","text":"<p>Module for analyzing data in Google Earth Engine.</p>"},{"location":"analysis/#geeagri.analysis.HarmonicRegression","title":"<code> HarmonicRegression        </code>","text":"<p>Perform harmonic regression on an Earth Engine ImageCollection.</p> <p>Attributes:</p> Name Type Description <code>image_collection</code> <code>ee.ImageCollection</code> <p>Input time series of selected band.</p> <code>ref_date</code> <code>ee.Date</code> <p>Reference date to calculate time.</p> <code>band</code> <code>str</code> <p>Name of dependent variable band.</p> <code>order</code> <code>int</code> <p>Number of harmonics.</p> <code>omega</code> <code>float</code> <p>Base frequency multiplier.</p> <code>independents</code> <code>List[str]</code> <p>Names of independent variable bands.</p> <code>composite</code> <code>ee.Image</code> <p>Median composite of the selected band.</p> Source code in <code>geeagri/analysis.py</code> <pre><code>class HarmonicRegression:\n    \"\"\"\n    Perform harmonic regression on an Earth Engine ImageCollection.\n\n    Attributes:\n        image_collection (ee.ImageCollection): Input time series of selected band.\n        ref_date (ee.Date): Reference date to calculate time.\n        band (str): Name of dependent variable band.\n        order (int): Number of harmonics.\n        omega (float): Base frequency multiplier.\n        independents (List[str]): Names of independent variable bands.\n        composite (ee.Image): Median composite of the selected band.\n    \"\"\"\n\n    def __init__(self, image_collection, ref_date, band_name, order=1, omega=1):\n        \"\"\"\n        Initialize the HarmonicRegression object.\n\n        Args:\n            image_collection (ee.ImageCollection): Input image collection.\n            ref_date (str or ee.Date): Reference date to compute relative time.\n            band_name (str): Name of dependent variable band.\n            order (int): Number of harmonics (default 1).\n            omega (float): Base frequency multiplier (default 1).\n        \"\"\"\n        self.image_collection = image_collection.select(band_name)\n        self.ref_date = ee.Date(ref_date) if isinstance(ref_date, str) else ref_date\n        self.band = band_name\n        self.order = order\n        self.omega = omega\n\n        # Names of independent variables: constant, cos_1, ..., sin_1, ...\n        self.independents = (\n            [\"constant\"]\n            + [f\"cos_{i}\" for i in range(1, order + 1)]\n            + [f\"sin_{i}\" for i in range(1, order + 1)]\n        )\n\n        # Precompute mean composite of the selected band\n        self.composite = self.image_collection.mean()\n\n    def _add_time_unit(self, image):\n        \"\"\"\n        Add time difference in years from ref_date as band 't'.\n\n        Args:\n            image (ee.Image): Input image.\n\n        Returns:\n            ee.Image: Image with additional 't' band.\n        \"\"\"\n        dyear = ee.Number(image.date().difference(self.ref_date, \"year\"))\n        return image.addBands(ee.Image.constant(dyear).rename(\"t\").float())\n\n    def _add_harmonics(self, image):\n        \"\"\"\n        Add harmonic basis functions: constant, cos_i, sin_i bands.\n\n        Args:\n            image (ee.Image): Input image.\n\n        Returns:\n            ee.Image: Image with added harmonic bands.\n        \"\"\"\n        image = self._add_time_unit(image)\n        t = image.select(\"t\")\n\n        harmonic_bands = [ee.Image.constant(1).rename(\"constant\")]\n        for i in range(1, self.order + 1):\n            freq = ee.Number(i).multiply(self.omega).multiply(2 * math.pi)\n            harmonic_bands.append(t.multiply(freq).cos().rename(f\"cos_{i}\"))\n            harmonic_bands.append(t.multiply(freq).sin().rename(f\"sin_{i}\"))\n\n        return image.addBands(ee.Image(harmonic_bands))\n\n    def get_harmonic_coeffs(self):\n        \"\"\"\n        Fit harmonic regression and return coefficients image.\n\n        Returns:\n            ee.Image: Coefficients image with bands like &lt;band&gt;_constant, &lt;band&gt;_cos_1, etc.\n        \"\"\"\n        harmonic_coll = self.image_collection.map(self._add_harmonics)\n\n        regression = harmonic_coll.select(self.independents + [self.band]).reduce(\n            ee.Reducer.linearRegression(len(self.independents), 1)\n        )\n\n        coeffs = (\n            regression.select(\"coefficients\")\n            .arrayProject([0])\n            .arrayFlatten([self.independents])\n            .multiply(10000)\n            .toInt32()\n        )\n\n        new_names = [f\"{self.band}_{name}\" for name in self.independents]\n        return coeffs.rename(new_names)\n\n    def get_phase_amplitude(\n        self, harmonic_coeffs, cos_band, sin_band, hsv=True, stretch_factor=5\n    ):\n        \"\"\"\n        Compute phase and amplitude from harmonic coefficients. Optionally return an\n        HSV-based RGB visualization.\n\n        Args:\n            harmonic_coeffs (ee.Image): Coefficients image from get_harmonic_coeffs().\n            cos_band (str): Name of cosine coefficient band (e.g., '&lt;band&gt;_cos_1').\n            sin_band (str): Name of sine coefficient band (e.g., '&lt;band&gt;_sin_1').\n            hsv (bool, optional): If True (default), return an RGB image built from HSV\n                encoding (phase \u2192 hue, amplitude \u2192 saturation, composite \u2192 value).\n                If False, return the raw 'phase' (radians) and 'amplitude' bands.\n            stretch_factor (float, optional): Multiplier applied to amplitude before\n                mapping it to saturation in the HSV visualization.\n\n        Returns:\n            ee.Image:\n                - If hsv=True: 3-band RGB image derived from HSV.\n                - If hsv=False: Image with 'phase' (radians) and 'amplitude' bands.\n        \"\"\"\n\n        scale = 10000\n\n        # De-scale to original floating values\n        cos = harmonic_coeffs.select(cos_band).divide(scale).toFloat()\n        sin = harmonic_coeffs.select(sin_band).divide(scale).toFloat()\n\n        # Phase in [-pi, pi], Amplitude &gt;= 0\n        phase = sin.atan2(cos).rename(\"phase\")\n        amplitude = sin.hypot(cos).rename(\"amplitude\")\n\n        if hsv:\n            # Normalize to HSV ranges\n            hsv = (\n                phase.unitScale(-math.pi, math.pi)  # hue\n                .addBands(amplitude.multiply(stretch_factor).clamp(0, 1))  # sat\n                .addBands(self.composite)  # val\n                .rename([\"phase\", \"amplitude\", \"value\"])\n            )\n\n            return hsv.hsvToRgb()\n\n        else:\n            return phase.addBands(amplitude)\n\n    def _fit_harmonics(self, harmonic_coeffs, image):\n        \"\"\"\n        Compute fitted values from harmonic coefficients and harmonic bands.\n\n        Args:\n            harmonic_coeffs (ee.Image): Coefficients image divided by 10000.\n            image (ee.Image): Image with harmonic bands.\n\n        Returns:\n            ee.Image: Image with fitted values.\n        \"\"\"\n        return (\n            image.select(self.independents)\n            .multiply(harmonic_coeffs)\n            .reduce(\"sum\")\n            .rename(\"fitted\")\n            .copyProperties(image, [\"system:time_start\"])\n        )\n\n    def get_fitted_harmonics(self, harmonic_coeffs):\n        \"\"\"\n        Compute fitted harmonic time series over the collection.\n\n        Args:\n            harmonic_coeffs (ee.Image): Coefficients image from get_harmonic_coeffs().\n\n        Returns:\n            ee.ImageCollection: Collection with fitted harmonic value as 'fitted' band.\n        \"\"\"\n        harmonic_coeffs_scaled = harmonic_coeffs.divide(10000)\n        harmonic_coll = self.image_collection.map(self._add_harmonics)\n\n        return harmonic_coll.map(\n            lambda img: self._fit_harmonics(harmonic_coeffs_scaled, img)\n        )\n</code></pre>"},{"location":"analysis/#geeagri.analysis.HarmonicRegression.__init__","title":"<code>__init__(self, image_collection, ref_date, band_name, order=1, omega=1)</code>  <code>special</code>","text":"<p>Initialize the HarmonicRegression object.</p> <p>Parameters:</p> Name Type Description Default <code>image_collection</code> <code>ee.ImageCollection</code> <p>Input image collection.</p> required <code>ref_date</code> <code>str or ee.Date</code> <p>Reference date to compute relative time.</p> required <code>band_name</code> <code>str</code> <p>Name of dependent variable band.</p> required <code>order</code> <code>int</code> <p>Number of harmonics (default 1).</p> <code>1</code> <code>omega</code> <code>float</code> <p>Base frequency multiplier (default 1).</p> <code>1</code> Source code in <code>geeagri/analysis.py</code> <pre><code>def __init__(self, image_collection, ref_date, band_name, order=1, omega=1):\n    \"\"\"\n    Initialize the HarmonicRegression object.\n\n    Args:\n        image_collection (ee.ImageCollection): Input image collection.\n        ref_date (str or ee.Date): Reference date to compute relative time.\n        band_name (str): Name of dependent variable band.\n        order (int): Number of harmonics (default 1).\n        omega (float): Base frequency multiplier (default 1).\n    \"\"\"\n    self.image_collection = image_collection.select(band_name)\n    self.ref_date = ee.Date(ref_date) if isinstance(ref_date, str) else ref_date\n    self.band = band_name\n    self.order = order\n    self.omega = omega\n\n    # Names of independent variables: constant, cos_1, ..., sin_1, ...\n    self.independents = (\n        [\"constant\"]\n        + [f\"cos_{i}\" for i in range(1, order + 1)]\n        + [f\"sin_{i}\" for i in range(1, order + 1)]\n    )\n\n    # Precompute mean composite of the selected band\n    self.composite = self.image_collection.mean()\n</code></pre>"},{"location":"analysis/#geeagri.analysis.HarmonicRegression.get_fitted_harmonics","title":"<code>get_fitted_harmonics(self, harmonic_coeffs)</code>","text":"<p>Compute fitted harmonic time series over the collection.</p> <p>Parameters:</p> Name Type Description Default <code>harmonic_coeffs</code> <code>ee.Image</code> <p>Coefficients image from get_harmonic_coeffs().</p> required <p>Returns:</p> Type Description <code>ee.ImageCollection</code> <p>Collection with fitted harmonic value as 'fitted' band.</p> Source code in <code>geeagri/analysis.py</code> <pre><code>def get_fitted_harmonics(self, harmonic_coeffs):\n    \"\"\"\n    Compute fitted harmonic time series over the collection.\n\n    Args:\n        harmonic_coeffs (ee.Image): Coefficients image from get_harmonic_coeffs().\n\n    Returns:\n        ee.ImageCollection: Collection with fitted harmonic value as 'fitted' band.\n    \"\"\"\n    harmonic_coeffs_scaled = harmonic_coeffs.divide(10000)\n    harmonic_coll = self.image_collection.map(self._add_harmonics)\n\n    return harmonic_coll.map(\n        lambda img: self._fit_harmonics(harmonic_coeffs_scaled, img)\n    )\n</code></pre>"},{"location":"analysis/#geeagri.analysis.HarmonicRegression.get_harmonic_coeffs","title":"<code>get_harmonic_coeffs(self)</code>","text":"<p>Fit harmonic regression and return coefficients image.</p> <p>Returns:</p> Type Description <code>ee.Image</code> <p>Coefficients image with bands like _constant, _cos_1, etc. Source code in <code>geeagri/analysis.py</code> <pre><code>def get_harmonic_coeffs(self):\n    \"\"\"\n    Fit harmonic regression and return coefficients image.\n\n    Returns:\n        ee.Image: Coefficients image with bands like &lt;band&gt;_constant, &lt;band&gt;_cos_1, etc.\n    \"\"\"\n    harmonic_coll = self.image_collection.map(self._add_harmonics)\n\n    regression = harmonic_coll.select(self.independents + [self.band]).reduce(\n        ee.Reducer.linearRegression(len(self.independents), 1)\n    )\n\n    coeffs = (\n        regression.select(\"coefficients\")\n        .arrayProject([0])\n        .arrayFlatten([self.independents])\n        .multiply(10000)\n        .toInt32()\n    )\n\n    new_names = [f\"{self.band}_{name}\" for name in self.independents]\n    return coeffs.rename(new_names)\n</code></pre>"},{"location":"analysis/#geeagri.analysis.HarmonicRegression.get_phase_amplitude","title":"<code>get_phase_amplitude(self, harmonic_coeffs, cos_band, sin_band, hsv=True, stretch_factor=5)</code>","text":"<p>Compute phase and amplitude from harmonic coefficients. Optionally return an HSV-based RGB visualization.</p> <p>Parameters:</p> Name Type Description Default <code>harmonic_coeffs</code> <code>ee.Image</code> <p>Coefficients image from get_harmonic_coeffs().</p> required <code>cos_band</code> <code>str</code> <p>Name of cosine coefficient band (e.g., '_cos_1'). required <code>sin_band</code> <code>str</code> <p>Name of sine coefficient band (e.g., '_sin_1'). required <code>hsv</code> <code>bool</code> <p>If True (default), return an RGB image built from HSV encoding (phase \u2192 hue, amplitude \u2192 saturation, composite \u2192 value). If False, return the raw 'phase' (radians) and 'amplitude' bands.</p> <code>True</code> <code>stretch_factor</code> <code>float</code> <p>Multiplier applied to amplitude before mapping it to saturation in the HSV visualization.</p> <code>5</code> <p>Returns:</p> Type Description <code>ee.Image</code> <ul> <li>If hsv=True: 3-band RGB image derived from HSV.<ul> <li>If hsv=False: Image with 'phase' (radians) and 'amplitude' bands.</li> </ul> </li> </ul> Source code in <code>geeagri/analysis.py</code> <pre><code>def get_phase_amplitude(\n    self, harmonic_coeffs, cos_band, sin_band, hsv=True, stretch_factor=5\n):\n    \"\"\"\n    Compute phase and amplitude from harmonic coefficients. Optionally return an\n    HSV-based RGB visualization.\n\n    Args:\n        harmonic_coeffs (ee.Image): Coefficients image from get_harmonic_coeffs().\n        cos_band (str): Name of cosine coefficient band (e.g., '&lt;band&gt;_cos_1').\n        sin_band (str): Name of sine coefficient band (e.g., '&lt;band&gt;_sin_1').\n        hsv (bool, optional): If True (default), return an RGB image built from HSV\n            encoding (phase \u2192 hue, amplitude \u2192 saturation, composite \u2192 value).\n            If False, return the raw 'phase' (radians) and 'amplitude' bands.\n        stretch_factor (float, optional): Multiplier applied to amplitude before\n            mapping it to saturation in the HSV visualization.\n\n    Returns:\n        ee.Image:\n            - If hsv=True: 3-band RGB image derived from HSV.\n            - If hsv=False: Image with 'phase' (radians) and 'amplitude' bands.\n    \"\"\"\n\n    scale = 10000\n\n    # De-scale to original floating values\n    cos = harmonic_coeffs.select(cos_band).divide(scale).toFloat()\n    sin = harmonic_coeffs.select(sin_band).divide(scale).toFloat()\n\n    # Phase in [-pi, pi], Amplitude &gt;= 0\n    phase = sin.atan2(cos).rename(\"phase\")\n    amplitude = sin.hypot(cos).rename(\"amplitude\")\n\n    if hsv:\n        # Normalize to HSV ranges\n        hsv = (\n            phase.unitScale(-math.pi, math.pi)  # hue\n            .addBands(amplitude.multiply(stretch_factor).clamp(0, 1))  # sat\n            .addBands(self.composite)  # val\n            .rename([\"phase\", \"amplitude\", \"value\"])\n        )\n\n        return hsv.hsvToRgb()\n\n    else:\n        return phase.addBands(amplitude)\n</code></pre>"},{"location":"analysis/#geeagri.analysis.PCA","title":"<code> PCA        </code>","text":"<p>Performs Principal Component Analysis on an Earth Engine image.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>ee.Image</code> <p>Multi-band image to apply PCA to.</p> required <code>region</code> <code>ee.Geometry</code> <p>Geometry to use for statistical analysis.</p> required <code>scale</code> <code>int</code> <p>Pixel resolution for calculations. Defaults to 100.</p> <code>100</code> <code>max_pixels</code> <code>int</code> <p>Max number of pixels to process. Defaults to 1e9.</p> <code>1000000000</code> <p>Exceptions:</p> Type Description <code>ValueError</code> <p>If input image or region is invalid.</p> Source code in <code>geeagri/analysis.py</code> <pre><code>class PCA:\n    \"\"\"\n    Performs Principal Component Analysis on an Earth Engine image.\n\n    Args:\n        image (ee.Image): Multi-band image to apply PCA to.\n        region (ee.Geometry): Geometry to use for statistical analysis.\n        scale (int, optional): Pixel resolution for calculations. Defaults to 100.\n        max_pixels (int, optional): Max number of pixels to process. Defaults to 1e9.\n\n    Raises:\n        ValueError: If input image or region is invalid.\n    \"\"\"\n\n    def __init__(\n        self,\n        image: ee.Image,\n        region: ee.Geometry,\n        scale: int = 100,\n        max_pixels: int = int(1e9),\n    ):\n        if not isinstance(image, ee.Image):\n            raise ValueError(\"`image` must be an instance of ee.Image.\")\n        if not isinstance(region, ee.Geometry):\n            raise ValueError(\"`region` must be an instance of ee.Geometry.\")\n\n        self.image = image\n        self.region = region\n        self.scale = scale\n        self._max_pixels = max_pixels\n\n        self._scaler = MeanCentering(self.image, self.region, self.scale)\n        self.centered_image = self._scaler.transform()\n\n        self._eigen_values = None  # For storing eigenvalues for variance computation\n        self._pc_names = None  # Names of the principal components\n\n    def get_principal_components(self) -&gt; ee.Image:\n        \"\"\"Computes normalized principal components of the image.\n\n        Returns:\n            ee.Image: Image with bands ['pc1', 'pc2', ..., 'pcN'] representing normalized PCs.\n        \"\"\"\n        arrays = self.centered_image.toArray()\n\n        covar = arrays.reduceRegion(\n            reducer=ee.Reducer.centeredCovariance(),\n            geometry=self.region,\n            scale=self.scale,\n            maxPixels=self._max_pixels,\n        )\n\n        if covar is None or covar.get(\"array\") is None:\n            raise RuntimeError(\n                \"Covariance matrix could not be computed. Check region/image coverage.\"\n            )\n\n        covar_array = ee.Array(covar.get(\"array\"))\n        eigens = covar_array.eigen()\n        eigen_values = eigens.slice(1, 0, 1)\n        eigen_vectors = eigens.slice(1, 1)\n\n        self._eigen_values = eigen_values  # Save for explained variance calculation\n\n        array_image = arrays.toArray(1)\n        principal_components = ee.Image(eigen_vectors).matrixMultiply(array_image)\n\n        band_count = self.image.bandNames().size()\n        band_names = ee.List.sequence(1, band_count).map(\n            lambda i: ee.String(\"pc\").cat(ee.Number(i).toInt().format())\n        )\n        self._pc_names = band_names\n\n        sd_image = (\n            ee.Image(eigen_values.sqrt()).arrayProject([0]).arrayFlatten([band_names])\n        )\n\n        pc_image = (\n            principal_components.arrayProject([0])\n            .arrayFlatten([band_names])\n            .divide(sd_image)\n        )\n\n        return pc_image\n\n    def get_explained_variance(self) -&gt; pd.DataFrame:\n        \"\"\"Returns explained variance ratio for each principal component.\n\n        Returns:\n            pd.DataFrame: DataFrame with columns ['pc', 'variance_explained'].\n        \"\"\"\n        if self._eigen_values is None:\n            raise RuntimeError(\n                \"Call `get_principal_components()` before computing explained variance.\"\n            )\n\n        eigen_values = np.array(self._eigen_values.getInfo()).flatten()\n        total_variance = eigen_values.sum()\n        explained_variance = eigen_values / total_variance\n\n        return pd.DataFrame(\n            {\"pc\": self._pc_names.getInfo(), \"variance_explained\": explained_variance}\n        )\n</code></pre>"},{"location":"analysis/#geeagri.analysis.PCA.get_explained_variance","title":"<code>get_explained_variance(self)</code>","text":"<p>Returns explained variance ratio for each principal component.</p> <p>Returns:</p> Type Description <code>pd.DataFrame</code> <p>DataFrame with columns ['pc', 'variance_explained'].</p> Source code in <code>geeagri/analysis.py</code> <pre><code>def get_explained_variance(self) -&gt; pd.DataFrame:\n    \"\"\"Returns explained variance ratio for each principal component.\n\n    Returns:\n        pd.DataFrame: DataFrame with columns ['pc', 'variance_explained'].\n    \"\"\"\n    if self._eigen_values is None:\n        raise RuntimeError(\n            \"Call `get_principal_components()` before computing explained variance.\"\n        )\n\n    eigen_values = np.array(self._eigen_values.getInfo()).flatten()\n    total_variance = eigen_values.sum()\n    explained_variance = eigen_values / total_variance\n\n    return pd.DataFrame(\n        {\"pc\": self._pc_names.getInfo(), \"variance_explained\": explained_variance}\n    )\n</code></pre>"},{"location":"analysis/#geeagri.analysis.PCA.get_principal_components","title":"<code>get_principal_components(self)</code>","text":"<p>Computes normalized principal components of the image.</p> <p>Returns:</p> Type Description <code>ee.Image</code> <p>Image with bands ['pc1', 'pc2', ..., 'pcN'] representing normalized PCs.</p> Source code in <code>geeagri/analysis.py</code> <pre><code>def get_principal_components(self) -&gt; ee.Image:\n    \"\"\"Computes normalized principal components of the image.\n\n    Returns:\n        ee.Image: Image with bands ['pc1', 'pc2', ..., 'pcN'] representing normalized PCs.\n    \"\"\"\n    arrays = self.centered_image.toArray()\n\n    covar = arrays.reduceRegion(\n        reducer=ee.Reducer.centeredCovariance(),\n        geometry=self.region,\n        scale=self.scale,\n        maxPixels=self._max_pixels,\n    )\n\n    if covar is None or covar.get(\"array\") is None:\n        raise RuntimeError(\n            \"Covariance matrix could not be computed. Check region/image coverage.\"\n        )\n\n    covar_array = ee.Array(covar.get(\"array\"))\n    eigens = covar_array.eigen()\n    eigen_values = eigens.slice(1, 0, 1)\n    eigen_vectors = eigens.slice(1, 1)\n\n    self._eigen_values = eigen_values  # Save for explained variance calculation\n\n    array_image = arrays.toArray(1)\n    principal_components = ee.Image(eigen_vectors).matrixMultiply(array_image)\n\n    band_count = self.image.bandNames().size()\n    band_names = ee.List.sequence(1, band_count).map(\n        lambda i: ee.String(\"pc\").cat(ee.Number(i).toInt().format())\n    )\n    self._pc_names = band_names\n\n    sd_image = (\n        ee.Image(eigen_values.sqrt()).arrayProject([0]).arrayFlatten([band_names])\n    )\n\n    pc_image = (\n        principal_components.arrayProject([0])\n        .arrayFlatten([band_names])\n        .divide(sd_image)\n    )\n\n    return pc_image\n</code></pre>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#v013-2025-09-20","title":"v0.1.3 \u2013 2025-09-20","text":"<p>New Features:</p> <ul> <li><code>MovingWindowSmoothing</code> class for applying moving window smoothing to time series data.</li> <li>Helps in reducing noise and filling short cloud-induced gaps.</li> <li><code>TemporalInterpolation</code> class for interpolating gaps in satellite time series.</li> <li><code>RegularTimeseries</code> class for converting irregular satellite time series into regular intervals.</li> <li>Flexible frequency specification (e.g., 5-day, 10-day, 15-day).</li> </ul> <p>Improvements:</p> <ul> <li>Expanded documentation with notebook examples for smoothing, interpolation, and regularization workflows.</li> </ul>"},{"location":"changelog/#v012-2025-09-01","title":"v0.1.2 \u2013 2025-09-01","text":"<p>New Features:</p> <ul> <li><code>TimeseriesExtractor</code> class for downloading per-feature CSV time series from Earth Engine <code>ee.ImageCollection</code>.</li> <li>Point geometries: uses <code>getRegion</code>, no reducer required.</li> <li>Polygon/MultiPolygon geometries: supports reducers for aggregation.</li> <li>Exports directly to CSV for downstream analysis.</li> <li><code>HarmonicRegression</code> class for performing harmonic regression on Earth Engine <code>ee.ImageCollection</code>.</li> <li>Computes harmonic coefficients with configurable order and base frequency.</li> <li>Provides phase and amplitude outputs for phenology and seasonal dynamics analysis.</li> <li>Supports fitted harmonic time series generation for visualization or modeling.</li> </ul> <p>Improvements:</p> <ul> <li>Updated docstrings for clarity and alignment with function behavior.</li> <li>Documentation expanded to include harmonic regression and time series extraction workflows.</li> </ul>"},{"location":"changelog/#v011-2025-08-06","title":"v0.1.1 \u2013 2025-08-06","text":"<p>New Features:</p> <ul> <li><code>ImagePatchExtractor</code> class added for efficient extraction of image patches from Earth Engine <code>ee.Image</code> objects using local sample points as <code>GeoDataFrame</code>.</li> <li>Supports multiple export formats: <code>png</code>, <code>jpg</code>, <code>GEO_TIFF</code>, and others.</li> <li>Fully parallelized with configurable number of processes.</li> <li>Uses a specified identifier column for naming output files.</li> <li>Automatically handles patch sizing via <code>dimensions</code> and <code>buffer</code> parameters.</li> </ul> <p>Improvements - Improved documentation and example notebooks:</p>"},{"location":"changelog/#v010-2025-07-29","title":"v0.1.0 - 2025-07-29","text":"<p>Improvements:</p> <ul> <li>Improved initial project scaffolding and modular structure.</li> <li>Enhanced configuration for easier customization and extension.</li> </ul> <p>New Features:</p> <ul> <li>Added preprocessing module with various image scaling options:</li> <li>MeanCentering</li> <li>MinMaxScaler</li> <li>StandardScaler</li> <li>RobustScaler</li> <li>Added analysis module including easy implementation of PCA with explained variance calculation.</li> <li>Added new example notebooks.</li> </ul>"},{"location":"common/","title":"common module","text":"<p>The common module contains common functions and classes used by the other modules.</p>"},{"location":"common/#geeagri.common.hello_world","title":"<code>hello_world()</code>","text":"<p>Prints \"Hello World!\" to the console.</p> Source code in <code>geeagri/common.py</code> <pre><code>def hello_world():\n    \"\"\"Prints \"Hello World!\" to the console.\"\"\"\n    print(\"Hello World!\")\n</code></pre>"},{"location":"contributing/","title":"Contributing","text":"<p>Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given.</p> <p>You can contribute in many ways:</p>"},{"location":"contributing/#types-of-contributions","title":"Types of Contributions","text":""},{"location":"contributing/#report-bugs","title":"Report Bugs","text":"<p>Report bugs at https://github.com/geonextgis/geeagri/issues.</p> <p>If you are reporting a bug, please include:</p> <ul> <li>Your operating system name and version.</li> <li>Any details about your local setup that might be helpful in troubleshooting.</li> <li>Detailed steps to reproduce the bug.</li> </ul>"},{"location":"contributing/#fix-bugs","title":"Fix Bugs","text":"<p>Look through the GitHub issues for bugs. Anything tagged with <code>bug</code> and <code>help wanted</code> is open to whoever wants to implement it.</p>"},{"location":"contributing/#implement-features","title":"Implement Features","text":"<p>Look through the GitHub issues for features. Anything tagged with <code>enhancement</code> and <code>help wanted</code> is open to whoever wants to implement it.</p>"},{"location":"contributing/#write-documentation","title":"Write Documentation","text":"<p>geeagri could always use more documentation, whether as part of the official geeagri docs, in docstrings, or even on the web in blog posts, articles, and such.</p>"},{"location":"contributing/#submit-feedback","title":"Submit Feedback","text":"<p>The best way to send feedback is to file an issue at https://github.com/geonextgis/geeagri/issues.</p> <p>If you are proposing a feature:</p> <ul> <li>Explain in detail how it would work.</li> <li>Keep the scope as narrow as possible, to make it easier to implement.</li> <li>Remember that this is a volunteer-driven project, and that contributions are welcome :)</li> </ul>"},{"location":"contributing/#get-started","title":"Get Started!","text":"<p>Ready to contribute? Here's how to set up geeagri for local development.</p> <ol> <li> <p>Fork the geeagri repo on GitHub.</p> </li> <li> <p>Clone your fork locally:</p> <pre><code>$ git clone git@github.com:your_name_here/geeagri.git\n</code></pre> </li> <li> <p>Install your local copy into a virtualenv. Assuming you have     virtualenvwrapper installed, this is how you set up your fork for     local development:</p> <pre><code>$ mkvirtualenv geeagri\n$ cd geeagri/\n$ python setup.py develop\n</code></pre> </li> <li> <p>Create a branch for local development:</p> <pre><code>$ git checkout -b name-of-your-bugfix-or-feature\n</code></pre> <p>Now you can make your changes locally.</p> </li> <li> <p>When you're done making changes, check that your changes pass flake8     and the tests, including testing other Python versions with tox:</p> <pre><code>$ flake8 geeagri tests\n$ python setup.py test or pytest\n$ tox\n</code></pre> <p>To get flake8 and tox, just pip install them into your virtualenv.</p> </li> <li> <p>Commit your changes and push your branch to GitHub:</p> <pre><code>$ git add .\n$ git commit -m \"Your detailed description of your changes.\"\n$ git push origin name-of-your-bugfix-or-feature\n</code></pre> </li> <li> <p>Submit a pull request through the GitHub website.</p> </li> </ol>"},{"location":"contributing/#pull-request-guidelines","title":"Pull Request Guidelines","text":"<p>Before you submit a pull request, check that it meets these guidelines:</p> <ol> <li>The pull request should include tests.</li> <li>If the pull request adds functionality, the docs should be updated.     Put your new functionality into a function with a docstring, and add     the feature to the list in README.rst.</li> <li>The pull request should work for Python 3.8 and later, and     for PyPy. Check https://github.com/geonextgis/geeagri/pull_requests and make sure that the tests pass for all     supported Python versions.</li> </ol>"},{"location":"extract/","title":"extract module","text":"<p>Module for extracting data from Google Earth Engine.</p>"},{"location":"extract/#geeagri.extract.ImagePatchExtractor","title":"<code> ImagePatchExtractor        </code>","text":"<p>Extracts image patches (chips) around sample points from an Earth Engine image.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>ee.Image</code> <p>Earth Engine image to extract patches from.</p> required <code>samples_gdf</code> <code>gpd.GeoDataFrame</code> <p>GeoDataFrame of sample points with a unique identifier column.</p> required <code>identifier</code> <code>str</code> <p>Column name in samples_gdf to use for naming patches.</p> required <code>out_dir</code> <code>str</code> <p>Directory to save extracted patches.</p> <code>'.'</code> <code>buffer</code> <code>int</code> <p>Buffer radius (in meters) around each point to define patch area.</p> <code>1270</code> <code>dimensions</code> <code>str</code> <p>Patch dimensions in the form \"widthxheight\", e.g., \"256x256\".</p> <code>'256x256'</code> <code>format</code> <code>str</code> <p>Output format (e.g., \"png\", \"jpg\", \"GEO_TIFF\").</p> <code>'png'</code> <code>num_processes</code> <code>int</code> <p>Number of parallel download processes.</p> <code>10</code> Source code in <code>geeagri/extract.py</code> <pre><code>class ImagePatchExtractor:\n    \"\"\"\n    Extracts image patches (chips) around sample points from an Earth Engine image.\n\n    Args:\n        image (ee.Image): Earth Engine image to extract patches from.\n        samples_gdf (gpd.GeoDataFrame): GeoDataFrame of sample points with a unique identifier column.\n        identifier (str): Column name in samples_gdf to use for naming patches.\n        out_dir (str): Directory to save extracted patches.\n        buffer (int): Buffer radius (in meters) around each point to define patch area.\n        dimensions (str): Patch dimensions in the form \"widthxheight\", e.g., \"256x256\".\n        format (str): Output format (e.g., \"png\", \"jpg\", \"GEO_TIFF\").\n        num_processes (int): Number of parallel download processes.\n    \"\"\"\n\n    SUPPORTED_FORMATS = {\"png\", \"jpg\", \"GEO_TIFF\", \"ZIPPED_GEO_TIFF\", \"NPY\"}\n\n    def __init__(\n        self,\n        image: ee.Image,\n        sample_gdf: gpd.GeoDataFrame,\n        identifier: str,\n        out_dir: str = \".\",\n        buffer: int = 1270,\n        dimensions: str = \"256x256\",\n        format: str = \"png\",\n        num_processes: int = 10,\n    ):\n        self.image = image\n        self.samples_gdf = sample_gdf\n        self.identifier = identifier\n        self.out_dir = out_dir\n        self.buffer = buffer\n        self.dimensions = dimensions\n        self.format = format.upper()\n        self.num_processes = num_processes\n\n        self._validate_inputs()\n        os.makedirs(self.out_dir, exist_ok=True)\n        logging.basicConfig()\n\n        self.sample_features = json.loads(self.samples_gdf.to_json())[\"features\"]\n\n    def _validate_inputs(self):\n        # Validate dimensions format\n        if not isinstance(self.dimensions, str) or \"x\" not in self.dimensions:\n            raise ValueError(\n                \"dimensions must be a string in the form 'WIDTHxHEIGHT', e.g., '256x256'.\"\n            )\n\n        dims = self.dimensions.lower().split(\"x\")\n        if len(dims) != 2 or not all(d.isdigit() for d in dims):\n            raise ValueError(\n                \"dimensions must contain two integers separated by 'x', e.g., '256x256'.\"\n            )\n\n        # Validate image format\n        if self.format not in self.SUPPORTED_FORMATS:\n            raise ValueError(\n                f\"Unsupported format: '{self.format}'. Supported formats: {self.SUPPORTED_FORMATS}\"\n            )\n\n        # Validate identifier exists\n        if self.identifier not in self.samples_gdf.columns:\n            raise ValueError(\n                f\"Identifier column '{self.identifier}' not found in sample_gdf.\"\n            )\n\n    def extract_patches(self):\n        \"\"\"\n        Initiates the parallel download of patches based on sample points.\n        \"\"\"\n        items = [\n            (f[\"id\"], f[\"properties\"], f[\"geometry\"]) for f in self.sample_features\n        ]\n\n        pool = multiprocessing.Pool(self.num_processes)\n        pool.starmap(self._download_patch, items)\n        pool.close()\n        pool.join()\n\n    @retry(tries=10, delay=1, backoff=2)\n    def _download_patch(self, id: Union[str, int], props: dict, geom: dict):\n        \"\"\"\n        Downloads a single patch based on a point geometry.\n\n        Args:\n            id (str|int): Internal ID.\n            props (dict): Properties from the GeoDataFrame row.\n            geom (dict): Geometry of the point in GeoJSON format.\n        \"\"\"\n        index = props[self.identifier]\n        coords = ee.Geometry.Point(geom[\"coordinates\"])\n        region = coords.buffer(self.buffer).bounds()\n\n        # Get the correct download URL based on format\n        if self.format in [\"PNG\", \"JPG\"]:\n            url = self.image.getThumbURL(\n                {\n                    \"region\": region,\n                    \"dimensions\": self.dimensions,\n                    \"format\": self.format.lower(),\n                }\n            )\n        else:\n            url = self.image.getDownloadURL(\n                {\"region\": region, \"dimensions\": self.dimensions, \"format\": self.format}\n            )\n\n        # Determine extension\n        ext = (\n            \"tif\"\n            if self.format in [\"GEO_TIFF\", \"ZIPPED_GEO_TIFF\"]\n            else self.format.lower()\n        )\n        filename = f\"{index}.{ext}\"\n        filepath = os.path.join(self.out_dir, filename)\n\n        # Download and save image\n        response = requests.get(url, stream=True)\n        if response.status_code != 200:\n            response.raise_for_status()\n\n        with open(filepath, \"wb\") as out_file:\n            shutil.copyfileobj(response.raw, out_file)\n\n        print(f\"Saved: {filepath}\")\n</code></pre>"},{"location":"extract/#geeagri.extract.ImagePatchExtractor.extract_patches","title":"<code>extract_patches(self)</code>","text":"<p>Initiates the parallel download of patches based on sample points.</p> Source code in <code>geeagri/extract.py</code> <pre><code>def extract_patches(self):\n    \"\"\"\n    Initiates the parallel download of patches based on sample points.\n    \"\"\"\n    items = [\n        (f[\"id\"], f[\"properties\"], f[\"geometry\"]) for f in self.sample_features\n    ]\n\n    pool = multiprocessing.Pool(self.num_processes)\n    pool.starmap(self._download_patch, items)\n    pool.close()\n    pool.join()\n</code></pre>"},{"location":"extract/#geeagri.extract.TimeseriesExtractor","title":"<code> TimeseriesExtractor        </code>","text":"<p>Downloads per-feature CSV time series from an Earth Engine ImageCollection.</p> <ul> <li>If a feature geometry is a Point: uses getRegion; no reducer needed.</li> <li>If a feature geometry is a Polygon/MultiPolygon: requires a reducer.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>sample_gdf</code> <code>gpd.GeoDataFrame</code> <p>Must contain geometry and <code>identifier</code> column.</p> required <code>identifier</code> <code>str</code> <p>Column name to use for file naming (also added to CSV).</p> required <code>out_dir</code> <code>str</code> <p>Output directory (created if absent).</p> <code>'.'</code> <code>selectors</code> <code>list|None</code> <p>Optional property list to include in CSV export.                    (If provided, 'time' will be auto-added if missing.)</p> <code>None</code> <code>scale</code> <code>int|None</code> <p>Pixel scale (meters) for sampling/reduction.</p> <code>None</code> <code>crs</code> <code>str|None</code> <p>Projection CRS. Default 'EPSG:4326'.</p> <code>'EPSG:4326'</code> <code>crsTransform</code> <code>list|None</code> <p>3x2 transform for getRegion (points) if you need it.</p> <code>None</code> <code>num_processes</code> <code>int</code> <p>Parallel workers.</p> <code>10</code> <code>start_date</code> <code>str|None</code> <p>'YYYY-MM-DD'. If provided with end_date, filters IC.</p> <code>None</code> <code>end_date</code> <code>str|None</code> <p>'YYYY-MM-DD'. If provided with start_date, filters IC.</p> <code>None</code> <code>reducer</code> <code>str|ee.Reducer|None</code> <p>Required if any feature is polygon/multipolygon.                            Ignored for point features.</p> <code>None</code> Source code in <code>geeagri/extract.py</code> <pre><code>class TimeseriesExtractor:\n    \"\"\"\n    Downloads per-feature CSV time series from an Earth Engine ImageCollection.\n\n    - If a feature geometry is a Point: uses getRegion; no reducer needed.\n    - If a feature geometry is a Polygon/MultiPolygon: requires a reducer.\n\n    Args:\n        image_collection (ee.ImageCollection)\n        sample_gdf (gpd.GeoDataFrame): Must contain geometry and `identifier` column.\n        identifier (str): Column name to use for file naming (also added to CSV).\n        out_dir (str): Output directory (created if absent).\n        selectors (list|None): Optional property list to include in CSV export.\n                               (If provided, 'time' will be auto-added if missing.)\n        scale (int|None): Pixel scale (meters) for sampling/reduction.\n        crs (str|None): Projection CRS. Default 'EPSG:4326'.\n        crsTransform (list|None): 3x2 transform for getRegion (points) if you need it.\n        num_processes (int): Parallel workers.\n        start_date (str|None): 'YYYY-MM-DD'. If provided with end_date, filters IC.\n        end_date (str|None): 'YYYY-MM-DD'. If provided with start_date, filters IC.\n        reducer (str|ee.Reducer|None): Required if any feature is polygon/multipolygon.\n                                       Ignored for point features.\n    \"\"\"\n\n    def __init__(\n        self,\n        image_collection: ee.ImageCollection,\n        sample_gdf: gpd.GeoDataFrame,\n        identifier: str,\n        out_dir: str = \".\",\n        selectors: Optional[List[str]] = None,\n        scale: Optional[int] = None,\n        crs: str = \"EPSG:4326\",\n        crsTransform: Optional[List[float]] = None,\n        num_processes: int = 10,\n        start_date: Optional[str] = None,\n        end_date: Optional[str] = None,\n        reducer: Optional[Union[str, ee.Reducer]] = None,\n    ):\n        # Filter/select up front so workers get a slim IC\n        ic = image_collection\n        if start_date and end_date:\n            ic = ic.filterDate(start_date, end_date)\n        if selectors:\n            ic = ic.select(selectors)\n        else:\n            selectors = ic.first().bandNames().getInfo()\n\n        self.image_collection = ic\n        self.samples_gdf = sample_gdf\n        self.identifier = identifier\n        self.out_dir = out_dir\n        self.selectors = selectors\n        self.scale = scale\n        self.crs = crs\n        self.crsTransform = crsTransform\n        self.num_processes = num_processes\n        self.start_date = start_date\n        self.end_date = end_date\n        self.reducer = reducer\n\n        self._validate_inputs()\n        os.makedirs(self.out_dir, exist_ok=True)\n        logging.basicConfig()\n\n        # Cache features as plain JSON tuples (id, props, geom) for Pool\n        self.sample_features = [\n            (f[\"id\"], f[\"properties\"], f[\"geometry\"])\n            for f in json.loads(self.samples_gdf.to_json())[\"features\"]\n        ]\n\n    def _validate_inputs(self):\n        if not isinstance(self.image_collection, ee.ImageCollection):\n            raise ValueError(\"image_collection must be ee.ImageCollection.\")\n        if self.identifier not in self.samples_gdf.columns:\n            raise ValueError(\n                f\"Identifier column '{self.identifier}' not found in sample_gdf.\"\n            )\n\n        # Geometry checks and reducer requirement for polygons\n        geom_types = set(self.samples_gdf.geometry.geom_type.str.upper().unique())\n        allowed = {\"POINT\", \"POLYGON\", \"MULTIPOLYGON\"}\n        if not geom_types.issubset(allowed):\n            raise ValueError(\n                f\"Only POINT/POLYGON/MULTIPOLYGON are supported; found: {geom_types}\"\n            )\n\n        has_poly = any(g in geom_types for g in (\"POLYGON\", \"MULTIPOLYGON\"))\n        if has_poly:\n            if self.reducer is None:\n                raise ValueError(\n                    \"Reducer is required when sample_gdf contains polygons.\"\n                )\n\n            self.REDUCERS = {\n                \"COUNT\": ee.Reducer.count(),\n                \"MEAN\": ee.Reducer.mean(),\n                \"MEAN_UNWEIGHTED\": ee.Reducer.mean().unweighted(),\n                \"MAXIMUM\": ee.Reducer.max(),\n                \"MEDIAN\": ee.Reducer.median(),\n                \"MINIMUM\": ee.Reducer.min(),\n                \"MODE\": ee.Reducer.mode(),\n                \"STD\": ee.Reducer.stdDev(),\n                \"MIN_MAX\": ee.Reducer.minMax(),\n                \"SUM\": ee.Reducer.sum(),\n                \"VARIANCE\": ee.Reducer.variance(),\n            }\n\n            # Normalize reducer to ee.Reducer\n            if isinstance(self.reducer, str):\n                key = self.reducer.upper()\n                if key not in self.REDUCERS:\n                    raise ValueError(\n                        f\"Reducer '{self.reducer}' not supported. \"\n                        f\"Choose from: {list(self.REDUCERS.keys())}\"\n                    )\n                self.reducer = self.REDUCERS[key]\n            elif not isinstance(self.reducer, ee.Reducer):\n                raise ValueError(\"reducer must be a string or an ee.Reducer instance.\")\n\n    def extract_timeseries(self):\n        \"\"\"Parallel per-feature CSV download.\"\"\"\n\n        with multiprocessing.Pool(processes=self.num_processes) as pool:\n            pool.starmap(self._download_timeseries, self.sample_features)\n\n    @retry(tries=10, delay=1, backoff=2)\n    def _download_timeseries(self, id_: Union[str, int], props: dict, geom: dict):\n        index_val = props[self.identifier]\n\n        gtype = geom.get(\"type\", \"\").upper()\n        if gtype == \"POINT\":\n            fc = self._fc_from_point(geom, index_val)\n        elif gtype in (\"POLYGON\", \"MULTIPOLYGON\"):\n            fc = self._fc_from_polygon(geom, index_val, self.reducer)\n        else:\n            raise ValueError(f\"Unsupported geometry type: {gtype}\")\n\n        params = {\"filename\": f\"{index_val}\"}\n\n        sels = list(self.selectors)\n        if \"time\" not in [s.lower() for s in sels]:\n            sels = [\"time\"] + sels\n        if self.identifier not in sels:\n            sels = [self.identifier] + sels\n        params[\"selectors\"] = sels\n\n        url = fc.getDownloadURL(**params)\n        resp = requests.get(url, stream=True)\n        resp.raise_for_status()\n\n        out_path = Path(self.out_dir) / f\"{index_val}.csv\"\n        resp.encoding = resp.encoding or \"utf-8\"\n        with open(out_path, \"w\", encoding=resp.encoding, newline=\"\") as f:\n            for chunk in resp.iter_content(chunk_size=65536, decode_unicode=True):\n                if chunk:\n                    f.write(chunk)\n\n        print(f\"Saved: {out_path}\")\n\n    def _fc_from_point(\n        self, geom: dict, index_val: Union[str, int]\n    ) -&gt; ee.FeatureCollection:\n        \"\"\"Convert a getRegion result at a point into a FeatureCollection with 'time' as ISO and identifier.\"\"\"\n        coords = ee.Geometry.Point(geom[\"coordinates\"])\n        result = self.image_collection.getRegion(\n            geometry=coords,\n            scale=self.scale,\n            crs=self.crs,\n            crsTransform=self.crsTransform,\n        )\n\n        headers = result.get(0)\n        rows = result.slice(1)\n\n        def make_feature(row):\n            row = ee.List(row)\n            d = ee.Dictionary.fromLists(headers, row)\n            date_str = ee.Date(ee.Number(d.get(\"time\"))).format(\"YYYY-MM-dd HH:mm:ss\")\n            d = d.set(\"time\", date_str)\n            d = d.set(self.identifier, index_val)\n            return ee.Feature(None, d)\n\n        return ee.FeatureCollection(rows.map(make_feature))\n\n    def _fc_from_polygon(\n        self, geom: dict, index_val: Union[str, int], reducer: ee.Reducer\n    ) -&gt; ee.FeatureCollection:\n        \"\"\"Map reduceRegion over images for a polygon/multipolygon, producing one feature per image.\"\"\"\n        polygon = ee.Geometry(geom)\n        ic = self.image_collection.filterBounds(polygon)\n\n        def per_image(image):\n            stats = image.reduceRegion(\n                reducer=reducer,\n                geometry=polygon,\n                scale=self.scale,\n                crs=self.crs,\n                maxPixels=1e13,\n            )\n            t = ee.Date(image.get(\"system:time_start\")).format(\"YYYY-MM-dd HH:mm:ss\")\n            feat = ee.Feature(None, stats).set(\"time\", t)\n            feat = feat.set(self.identifier, index_val)\n            return feat\n\n        fc = ee.FeatureCollection(ic.map(per_image))\n        fc = fc.filter(ee.Filter.notNull(self.image_collection.first().bandNames()))\n        return fc\n</code></pre>"},{"location":"extract/#geeagri.extract.TimeseriesExtractor.extract_timeseries","title":"<code>extract_timeseries(self)</code>","text":"<p>Parallel per-feature CSV download.</p> Source code in <code>geeagri/extract.py</code> <pre><code>def extract_timeseries(self):\n    \"\"\"Parallel per-feature CSV download.\"\"\"\n\n    with multiprocessing.Pool(processes=self.num_processes) as pool:\n        pool.starmap(self._download_timeseries, self.sample_features)\n</code></pre>"},{"location":"extract/#geeagri.extract.extract_timeseries_to_point","title":"<code>extract_timeseries_to_point(lat, lon, image_collection, start_date=None, end_date=None, band_names=None, scale=None, crs=None, crsTransform=None, out_csv=None)</code>","text":"<p>Extracts pixel time series from an ee.ImageCollection at a point.</p> <p>Parameters:</p> Name Type Description Default <code>lat</code> <code>float</code> <p>Latitude of the point.</p> required <code>lon</code> <code>float</code> <p>Longitude of the point.</p> required <code>image_collection</code> <code>ee.ImageCollection</code> <p>Image collection to sample.</p> required <code>start_date</code> <code>str</code> <p>Start date (e.g., '2020-01-01').</p> <code>None</code> <code>end_date</code> <code>str</code> <p>End date (e.g., '2020-12-31').</p> <code>None</code> <code>band_names</code> <code>list</code> <p>List of bands to extract.</p> <code>None</code> <code>scale</code> <code>float</code> <p>Sampling scale in meters.</p> <code>None</code> <code>crs</code> <code>str</code> <p>Projection CRS. Defaults to image CRS.</p> <code>None</code> <code>crsTransform</code> <code>list</code> <p>CRS transform matrix (3x2 row-major). Overrides scale.</p> <code>None</code> <code>out_csv</code> <code>str</code> <p>File path to save CSV. If None, returns a DataFrame.</p> <code>None</code> <p>Returns:</p> Type Description <code>pd.DataFrame or None</code> <p>Time series data if not exporting to CSV.</p> Source code in <code>geeagri/extract.py</code> <pre><code>def extract_timeseries_to_point(\n    lat,\n    lon,\n    image_collection,\n    start_date=None,\n    end_date=None,\n    band_names=None,\n    scale=None,\n    crs=None,\n    crsTransform=None,\n    out_csv=None,\n):\n    \"\"\"\n    Extracts pixel time series from an ee.ImageCollection at a point.\n\n    Args:\n        lat (float): Latitude of the point.\n        lon (float): Longitude of the point.\n        image_collection (ee.ImageCollection): Image collection to sample.\n        start_date (str, optional): Start date (e.g., '2020-01-01').\n        end_date (str, optional): End date (e.g., '2020-12-31').\n        band_names (list, optional): List of bands to extract.\n        scale (float, optional): Sampling scale in meters.\n        crs (str, optional): Projection CRS. Defaults to image CRS.\n        crsTransform (list, optional): CRS transform matrix (3x2 row-major). Overrides scale.\n        out_csv (str, optional): File path to save CSV. If None, returns a DataFrame.\n\n    Returns:\n        pd.DataFrame or None: Time series data if not exporting to CSV.\n    \"\"\"\n\n    if not isinstance(image_collection, ee.ImageCollection):\n        raise ValueError(\"image_collection must be an instance of ee.ImageCollection.\")\n\n    property_names = image_collection.first().propertyNames().getInfo()\n    if \"system:time_start\" not in property_names:\n        raise ValueError(\"The image collection lacks the 'system:time_start' property.\")\n\n    point = ee.Geometry.Point([lon, lat])\n\n    try:\n        if start_date and end_date:\n            image_collection = image_collection.filterDate(start_date, end_date)\n        if band_names:\n            image_collection = image_collection.select(band_names)\n        image_collection = image_collection.filterBounds(point)\n    except Exception as e:\n        raise RuntimeError(f\"Error filtering image collection: {e}\")\n\n    try:\n        result = image_collection.getRegion(\n            geometry=point, scale=scale, crs=crs, crsTransform=crsTransform\n        ).getInfo()\n\n        result_df = pd.DataFrame(result[1:], columns=result[0])\n\n        if result_df.empty:\n            raise ValueError(\n                \"Extraction returned an empty DataFrame. Check your point, date range, or selected bands.\"\n            )\n\n        result_df[\"time\"] = result_df[\"time\"].apply(\n            lambda t: datetime.utcfromtimestamp(t / 1000)\n        )\n\n        if out_csv:\n            result_df.to_csv(out_csv, index=False)\n        else:\n            return result_df\n\n    except Exception as e:\n        raise RuntimeError(f\"Error extracting data: {e}.\")\n</code></pre>"},{"location":"extract/#geeagri.extract.extract_timeseries_to_polygon","title":"<code>extract_timeseries_to_polygon(polygon, image_collection, start_date=None, end_date=None, band_names=None, scale=None, crs=None, reducer='MEAN', out_csv=None)</code>","text":"<p>Extracts time series statistics over a polygon from an ee.ImageCollection.</p> <p>Parameters:</p> Name Type Description Default <code>polygon</code> <code>ee.Geometry.Polygon</code> <p>Polygon geometry.</p> required <code>image_collection</code> <code>ee.ImageCollection</code> <p>Image collection to sample.</p> required <code>start_date</code> <code>str</code> <p>Start date (e.g., '2020-01-01').</p> <code>None</code> <code>end_date</code> <code>str</code> <p>End date (e.g., '2020-12-31').</p> <code>None</code> <code>band_names</code> <code>list</code> <p>List of bands to extract.</p> <code>None</code> <code>scale</code> <code>float</code> <p>Sampling scale in meters.</p> <code>None</code> <code>crs</code> <code>str</code> <p>Projection CRS. Defaults to image CRS.</p> <code>None</code> <code>reducer</code> <code>str or ee.Reducer</code> <p>Name of reducer or ee.Reducer instance.</p> <code>'MEAN'</code> <code>out_csv</code> <code>str</code> <p>File path to save CSV. If None, returns a DataFrame.</p> <code>None</code> <p>Returns:</p> Type Description <code>pd.DataFrame or None</code> <p>Time series data if not exporting to CSV.</p> Source code in <code>geeagri/extract.py</code> <pre><code>def extract_timeseries_to_polygon(\n    polygon,\n    image_collection,\n    start_date=None,\n    end_date=None,\n    band_names=None,\n    scale=None,\n    crs=None,\n    reducer=\"MEAN\",\n    out_csv=None,\n):\n    \"\"\"\n    Extracts time series statistics over a polygon from an ee.ImageCollection.\n\n    Args:\n        polygon (ee.Geometry.Polygon): Polygon geometry.\n        image_collection (ee.ImageCollection): Image collection to sample.\n        start_date (str, optional): Start date (e.g., '2020-01-01').\n        end_date (str, optional): End date (e.g., '2020-12-31').\n        band_names (list, optional): List of bands to extract.\n        scale (float, optional): Sampling scale in meters.\n        crs (str, optional): Projection CRS. Defaults to image CRS.\n        reducer (str or ee.Reducer): Name of reducer or ee.Reducer instance.\n        out_csv (str, optional): File path to save CSV. If None, returns a DataFrame.\n\n    Returns:\n        pd.DataFrame or None: Time series data if not exporting to CSV.\n    \"\"\"\n\n    if not isinstance(image_collection, ee.ImageCollection):\n        raise ValueError(\"image_collection must be an instance of ee.ImageCollection.\")\n    if not isinstance(polygon, ee.Geometry):\n        raise ValueError(\"polygon must be an instance of ee.Geometry.\")\n\n    # Allowed reducers\n    allowed_statistics = {\n        \"COUNT\": ee.Reducer.count(),\n        \"MEAN\": ee.Reducer.mean(),\n        \"MEAN_UNWEIGHTED\": ee.Reducer.mean().unweighted(),\n        \"MAXIMUM\": ee.Reducer.max(),\n        \"MEDIAN\": ee.Reducer.median(),\n        \"MINIMUM\": ee.Reducer.min(),\n        \"MODE\": ee.Reducer.mode(),\n        \"STD\": ee.Reducer.stdDev(),\n        \"MIN_MAX\": ee.Reducer.minMax(),\n        \"SUM\": ee.Reducer.sum(),\n        \"VARIANCE\": ee.Reducer.variance(),\n    }\n\n    # Get reducer from string or use directly\n    if isinstance(reducer, str):\n        reducer_upper = reducer.upper()\n        if reducer_upper not in allowed_statistics:\n            raise ValueError(\n                f\"Reducer '{reducer}' not supported. Choose from: {list(allowed_statistics.keys())}\"\n            )\n        reducer = allowed_statistics[reducer_upper]\n    elif not isinstance(reducer, ee.Reducer):\n        raise ValueError(\"reducer must be a string or an ee.Reducer instance.\")\n\n    # Filter dates and bands\n    if start_date and end_date:\n        image_collection = image_collection.filterDate(start_date, end_date)\n    if band_names:\n        image_collection = image_collection.select(band_names)\n\n    image_collection = image_collection.filterBounds(polygon)\n\n    def image_to_dict(image):\n        date = ee.Date(image.get(\"system:time_start\")).format(\"YYYY-MM-dd\")\n        stats = image.reduceRegion(\n            reducer=reducer, geometry=polygon, scale=scale, crs=crs, maxPixels=1e13\n        )\n        return ee.Feature(None, stats).set(\"time\", date)\n\n    stats_fc = image_collection.map(image_to_dict).filter(\n        ee.Filter.notNull(image_collection.first().bandNames())\n    )\n\n    try:\n        stats_list = stats_fc.getInfo()[\"features\"]\n    except Exception as e:\n        raise RuntimeError(f\"Error retrieving data from GEE: {e}\")\n\n    if not stats_list:\n        raise ValueError(\"No data returned for the given polygon and parameters.\")\n\n    records = []\n    for f in stats_list:\n        props = f[\"properties\"]\n        records.append(props)\n\n    df = pd.DataFrame(records)\n    df[\"time\"] = pd.to_datetime(df[\"time\"])\n    df.insert(0, \"time\", df.pop(\"time\"))\n\n    if out_csv:\n        df.to_csv(out_csv, index=False)\n    else:\n        return df\n</code></pre>"},{"location":"faq/","title":"FAQ","text":""},{"location":"geeagri/","title":"geeagri module","text":"<p>Main module.</p>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#stable-release","title":"Stable release","text":"<p>To install geeagri, run this command in your terminal:</p> <pre><code>pip install geeagri\n</code></pre> <p>This is the preferred method to install geeagri, as it will always install the most recent stable release.</p> <p>If you don't have pip installed, this Python installation guide can guide you through the process.</p>"},{"location":"installation/#from-sources","title":"From sources","text":"<p>To install geeagri from sources, run this command in your terminal:</p> <pre><code>pip install git+https://github.com/geonextgis/geeagri\n</code></pre>"},{"location":"preprocessing/","title":"preprocessing module","text":"<p>Module for preprocessing Earth Observation data using Google Earth Engine.</p>"},{"location":"preprocessing/#geeagri.preprocessing.MeanCentering","title":"<code> MeanCentering        </code>","text":"<p>Mean-centers each band of an Earth Engine image.</p> <p>The transformation is computed as:</p> <p>$$ X_{centered} = X - \\mu $$</p> <p>Where:</p> <ul> <li>$X$: original pixel value</li> <li>$\\mu$: mean of the band computed over the given region</li> </ul> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>ee.Image</code> <p>Input multi-band image to center.</p> required <code>region</code> <code>ee.Geometry</code> <p>Geometry over which statistics will be computed.</p> required <code>scale</code> <code>int</code> <p>Spatial resolution in meters. Defaults to 100.</p> <code>100</code> <code>max_pixels</code> <code>int</code> <p>Max pixels allowed in computation. Defaults to 1e9.</p> <code>1000000000</code> <p>Exceptions:</p> Type Description <code>TypeError</code> <p>If image or region is not an ee.Image or ee.Geometry.</p> Source code in <code>geeagri/preprocessing.py</code> <pre><code>class MeanCentering:\n    r\"\"\"\n    Mean-centers each band of an Earth Engine image.\n\n    The transformation is computed as:\n\n    $$\n    X_{centered} = X - \\mu\n    $$\n\n    Where:\n\n    - $X$: original pixel value\n    - $\\mu$: mean of the band computed over the given region\n\n    Args:\n        image (ee.Image): Input multi-band image to center.\n        region (ee.Geometry): Geometry over which statistics will be computed.\n        scale (int, optional): Spatial resolution in meters. Defaults to 100.\n        max_pixels (int, optional): Max pixels allowed in computation. Defaults to 1e9.\n\n    Raises:\n        TypeError: If image or region is not an ee.Image or ee.Geometry.\n    \"\"\"\n\n    def __init__(\n        self,\n        image: ee.Image,\n        region: ee.Geometry,\n        scale: int = 100,\n        max_pixels: int = int(1e9),\n    ):\n        if not isinstance(image, ee.Image):\n            raise TypeError(\"Expected 'image' to be of type ee.Image.\")\n        if not isinstance(region, ee.Geometry):\n            raise TypeError(\"Expected 'region' to be of type ee.Geometry.\")\n\n        self.image = image\n        self.region = region\n        self.scale = scale\n        self.max_pixels = max_pixels\n\n    def transform(self) -&gt; ee.Image:\n        \"\"\"\n        Applies mean-centering to each band of the image.\n\n        Returns:\n            ee.Image: The centered image with mean of each band subtracted.\n\n        Raises:\n            ValueError: If mean computation returns None or missing values.\n        \"\"\"\n        means = self.image.reduceRegion(\n            reducer=ee.Reducer.mean(),\n            geometry=self.region,\n            scale=self.scale,\n            bestEffort=True,\n            maxPixels=self.max_pixels,\n        )\n\n        if means is None:\n            raise ValueError(\"Mean computation failed \u2014 no valid pixels in the region.\")\n\n        bands = self.image.bandNames()\n\n        def center_band(band):\n            band = ee.String(band)\n            mean = ee.Number(means.get(band))\n            if mean is None:\n                raise ValueError(f\"Mean value not found for band: {band.getInfo()}\")\n            return self.image.select(band).subtract(mean).rename(band)\n\n        centered = bands.map(center_band)\n        return ee.ImageCollection(centered).toBands().rename(bands)\n</code></pre>"},{"location":"preprocessing/#geeagri.preprocessing.MeanCentering.transform","title":"<code>transform(self)</code>","text":"<p>Applies mean-centering to each band of the image.</p> <p>Returns:</p> Type Description <code>ee.Image</code> <p>The centered image with mean of each band subtracted.</p> <p>Exceptions:</p> Type Description <code>ValueError</code> <p>If mean computation returns None or missing values.</p> Source code in <code>geeagri/preprocessing.py</code> <pre><code>def transform(self) -&gt; ee.Image:\n    \"\"\"\n    Applies mean-centering to each band of the image.\n\n    Returns:\n        ee.Image: The centered image with mean of each band subtracted.\n\n    Raises:\n        ValueError: If mean computation returns None or missing values.\n    \"\"\"\n    means = self.image.reduceRegion(\n        reducer=ee.Reducer.mean(),\n        geometry=self.region,\n        scale=self.scale,\n        bestEffort=True,\n        maxPixels=self.max_pixels,\n    )\n\n    if means is None:\n        raise ValueError(\"Mean computation failed \u2014 no valid pixels in the region.\")\n\n    bands = self.image.bandNames()\n\n    def center_band(band):\n        band = ee.String(band)\n        mean = ee.Number(means.get(band))\n        if mean is None:\n            raise ValueError(f\"Mean value not found for band: {band.getInfo()}\")\n        return self.image.select(band).subtract(mean).rename(band)\n\n    centered = bands.map(center_band)\n    return ee.ImageCollection(centered).toBands().rename(bands)\n</code></pre>"},{"location":"preprocessing/#geeagri.preprocessing.MinMaxScaler","title":"<code> MinMaxScaler        </code>","text":"<p>Applies min-max normalization to each band of an Earth Engine image.</p> <p>The transformation is computed as:</p> <p>$$ X_\\text{scaled} = \\frac{X - \\min}{\\max - \\min} $$</p> <p>After clamping, $X_\\text{scaled} \\in [0, 1]$.</p> <p>Where:</p> <ul> <li>$\\min$, $\\max$: band-wise minimum and maximum values over the region.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>ee.Image</code> <p>The input multi-band image.</p> required <code>region</code> <code>ee.Geometry</code> <p>The region over which to compute min and max.</p> required <code>scale</code> <code>int</code> <p>The spatial resolution in meters. Defaults to 100.</p> <code>100</code> <code>max_pixels</code> <code>int</code> <p>Max pixels allowed during reduction. Defaults to 1e9.</p> <code>1000000000</code> <p>Exceptions:</p> Type Description <code>TypeError</code> <p>If <code>image</code> is not an <code>ee.Image</code> or <code>region</code> is not an <code>ee.Geometry</code>.</p> Source code in <code>geeagri/preprocessing.py</code> <pre><code>class MinMaxScaler:\n    r\"\"\"\n    Applies min-max normalization to each band of an Earth Engine image.\n\n    The transformation is computed as:\n\n    $$\n    X_\\\\text{scaled} = \\\\frac{X - \\\\min}{\\\\max - \\\\min}\n    $$\n\n    After clamping, $X_\\\\text{scaled} \\\\in [0, 1]$.\n\n    Where:\n\n    - $\\min$, $\\max$: band-wise minimum and maximum values over the region.\n\n    Args:\n        image (ee.Image): The input multi-band image.\n        region (ee.Geometry): The region over which to compute min and max.\n        scale (int, optional): The spatial resolution in meters. Defaults to 100.\n        max_pixels (int, optional): Max pixels allowed during reduction. Defaults to 1e9.\n\n    Raises:\n        TypeError: If `image` is not an `ee.Image` or `region` is not an `ee.Geometry`.\n    \"\"\"\n\n    def __init__(\n        self,\n        image: ee.Image,\n        region: ee.Geometry,\n        scale: int = 100,\n        max_pixels: int = int(1e9),\n    ):\n        if not isinstance(image, ee.Image):\n            raise TypeError(\"Expected 'image' to be of type ee.Image.\")\n        if not isinstance(region, ee.Geometry):\n            raise TypeError(\"Expected 'region' to be of type ee.Geometry.\")\n\n        self.image = image\n        self.region = region\n        self.scale = scale\n        self.max_pixels = max_pixels\n\n    def transform(self) -&gt; ee.Image:\n        \"\"\"\n        Applies min-max scaling to each band, producing values in the range [0, 1].\n\n        Returns:\n            ee.Image: A scaled image with band values clamped between 0 and 1.\n\n        Raises:\n            ValueError: If min or max statistics are unavailable or reduction fails.\n        \"\"\"\n        stats = self.image.reduceRegion(\n            reducer=ee.Reducer.minMax(),\n            geometry=self.region,\n            scale=self.scale,\n            bestEffort=True,\n            maxPixels=self.max_pixels,\n        )\n\n        if stats is None:\n            raise ValueError(\n                \"MinMax reduction failed \u2014 possibly no valid pixels in region.\"\n            )\n\n        bands = self.image.bandNames()\n\n        def scale_band(band):\n            band = ee.String(band)\n            min_val = ee.Number(stats.get(band.cat(\"_min\")))\n            max_val = ee.Number(stats.get(band.cat(\"_max\")))\n            if min_val is None or max_val is None:\n                raise ValueError(f\"Missing min/max for band: {band.getInfo()}\")\n            scaled = (\n                self.image.select(band)\n                .subtract(min_val)\n                .divide(max_val.subtract(min_val))\n            )\n            return scaled.clamp(0, 1).rename(band)\n\n        scaled = bands.map(scale_band)\n        return ee.ImageCollection(scaled).toBands().rename(bands)\n</code></pre>"},{"location":"preprocessing/#geeagri.preprocessing.MinMaxScaler.transform","title":"<code>transform(self)</code>","text":"<p>Applies min-max scaling to each band, producing values in the range [0, 1].</p> <p>Returns:</p> Type Description <code>ee.Image</code> <p>A scaled image with band values clamped between 0 and 1.</p> <p>Exceptions:</p> Type Description <code>ValueError</code> <p>If min or max statistics are unavailable or reduction fails.</p> Source code in <code>geeagri/preprocessing.py</code> <pre><code>def transform(self) -&gt; ee.Image:\n    \"\"\"\n    Applies min-max scaling to each band, producing values in the range [0, 1].\n\n    Returns:\n        ee.Image: A scaled image with band values clamped between 0 and 1.\n\n    Raises:\n        ValueError: If min or max statistics are unavailable or reduction fails.\n    \"\"\"\n    stats = self.image.reduceRegion(\n        reducer=ee.Reducer.minMax(),\n        geometry=self.region,\n        scale=self.scale,\n        bestEffort=True,\n        maxPixels=self.max_pixels,\n    )\n\n    if stats is None:\n        raise ValueError(\n            \"MinMax reduction failed \u2014 possibly no valid pixels in region.\"\n        )\n\n    bands = self.image.bandNames()\n\n    def scale_band(band):\n        band = ee.String(band)\n        min_val = ee.Number(stats.get(band.cat(\"_min\")))\n        max_val = ee.Number(stats.get(band.cat(\"_max\")))\n        if min_val is None or max_val is None:\n            raise ValueError(f\"Missing min/max for band: {band.getInfo()}\")\n        scaled = (\n            self.image.select(band)\n            .subtract(min_val)\n            .divide(max_val.subtract(min_val))\n        )\n        return scaled.clamp(0, 1).rename(band)\n\n    scaled = bands.map(scale_band)\n    return ee.ImageCollection(scaled).toBands().rename(bands)\n</code></pre>"},{"location":"preprocessing/#geeagri.preprocessing.MovingWindowSmoothing","title":"<code> MovingWindowSmoothing        </code>","text":"<p>Applies moving window temporal smoothing to an Earth Engine ImageCollection.</p> <p>This class uses a temporal window and a reducer (e.g., mean or median) to smooth an ImageCollection over time.</p> <p>Parameters:</p> Name Type Description Default <code>image_collection</code> <code>ee.ImageCollection</code> <p>Input Earth Engine ImageCollection.</p> required <code>window</code> <code>int</code> <p>Temporal window size in days.</p> required <code>reducer</code> <code>str | ee.Reducer</code> <p>Reducer type (\"MEAN\", \"MEDIAN\") or an ee.Reducer.</p> <code>'MEAN'</code> Source code in <code>geeagri/preprocessing.py</code> <pre><code>class MovingWindowSmoothing:\n    \"\"\"Applies moving window temporal smoothing to an Earth Engine ImageCollection.\n\n    This class uses a temporal window and a reducer (e.g., mean or median)\n    to smooth an ImageCollection over time.\n\n    Args:\n        image_collection (ee.ImageCollection): Input Earth Engine ImageCollection.\n        window (int): Temporal window size in days.\n        reducer (str | ee.Reducer): Reducer type (\"MEAN\", \"MEDIAN\") or an ee.Reducer.\n    \"\"\"\n\n    def __init__(\n        self,\n        image_collection: ee.ImageCollection,\n        window: int,\n        reducer: str = \"MEAN\",\n    ):\n        self._ic = image_collection\n        self.window = window\n        self.reducer = reducer\n\n        # Convert window size from days to milliseconds\n        self._millis = ee.Number(window).multiply(1000 * 60 * 60 * 24)\n\n        self._validate_inputs()\n\n    def _validate_inputs(self) -&gt; None:\n        \"\"\"Validates user inputs and sets the reducer.\"\"\"\n        allowed_statistics = {\n            \"MEAN\": ee.Reducer.mean(),\n            \"MEDIAN\": ee.Reducer.median(),\n        }\n\n        if not isinstance(self._ic, ee.ImageCollection):\n            raise ValueError(\n                \"`image_collection` must be an instance of ee.ImageCollection.\"\n            )\n\n        if not isinstance(self.window, int):\n            raise ValueError(\"`window` must be an integer (days).\")\n\n        if isinstance(self.reducer, str):\n            reducer_upper = self.reducer.upper()\n            if reducer_upper not in allowed_statistics:\n                raise ValueError(\n                    f\"Reducer '{self.reducer}' not supported. \"\n                    f\"Choose from {list(allowed_statistics.keys())}.\"\n                )\n            self._reducer = allowed_statistics[reducer_upper]\n        elif isinstance(self.reducer, ee.Reducer):\n            self._reducer = self.reducer\n        else:\n            raise ValueError(\n                \"`reducer` must be either a string or an ee.Reducer instance.\"\n            )\n\n    def _compute(self, image: ee.Image) -&gt; ee.Image:\n        \"\"\"Computes smoothed image for a single time step.\n\n        Args:\n            image (ee.Image): An image containing a list of matched images under 'images'.\n\n        Returns:\n            ee.Image: A smoothed image with preserved `system:time_start`.\n        \"\"\"\n        matching_images = ee.ImageCollection.fromImages(image.get(\"images\"))\n        computed_image = matching_images.reduce(self._reducer).copyProperties(\n            image, [\"system:time_start\"]\n        )\n        return computed_image\n\n    def get_smoothed_collection(self) -&gt; ee.ImageCollection:\n        \"\"\"Applies moving window smoothing to the input collection.\n\n        Returns:\n            ee.ImageCollection: The smoothed ImageCollection.\n        \"\"\"\n        join = ee.Join.saveAll(matchesKey=\"images\")\n\n        diffFilter = ee.Filter.maxDifference(\n            difference=self._millis,\n            leftField=\"system:time_start\",\n            rightField=\"system:time_start\",\n        )\n\n        joined_collection = join.apply(\n            primary=self._ic,\n            secondary=self._ic,\n            condition=diffFilter,\n        )\n\n        smoothed_collection = joined_collection.map(self._compute)\n\n        return ee.ImageCollection(smoothed_collection)\n</code></pre>"},{"location":"preprocessing/#geeagri.preprocessing.MovingWindowSmoothing.get_smoothed_collection","title":"<code>get_smoothed_collection(self)</code>","text":"<p>Applies moving window smoothing to the input collection.</p> <p>Returns:</p> Type Description <code>ee.ImageCollection</code> <p>The smoothed ImageCollection.</p> Source code in <code>geeagri/preprocessing.py</code> <pre><code>def get_smoothed_collection(self) -&gt; ee.ImageCollection:\n    \"\"\"Applies moving window smoothing to the input collection.\n\n    Returns:\n        ee.ImageCollection: The smoothed ImageCollection.\n    \"\"\"\n    join = ee.Join.saveAll(matchesKey=\"images\")\n\n    diffFilter = ee.Filter.maxDifference(\n        difference=self._millis,\n        leftField=\"system:time_start\",\n        rightField=\"system:time_start\",\n    )\n\n    joined_collection = join.apply(\n        primary=self._ic,\n        secondary=self._ic,\n        condition=diffFilter,\n    )\n\n    smoothed_collection = joined_collection.map(self._compute)\n\n    return ee.ImageCollection(smoothed_collection)\n</code></pre>"},{"location":"preprocessing/#geeagri.preprocessing.RegularTimeseries","title":"<code> RegularTimeseries        </code>","text":"<p>Generate a regularized and interpolated time series from an Earth Engine ImageCollection.</p> <p>This class creates a temporally regular image collection by inserting empty \"placeholder\" images at fixed intervals and then interpolating the original collection to those dates.</p> <p>Parameters:</p> Name Type Description Default <code>image_collection</code> <code>ee.ImageCollection</code> <p>Original input image collection.</p> required <code>interval</code> <code>int</code> <p>Interval (in days) between consecutive target dates.</p> required <code>window</code> <code>int</code> <p>Window size (in days) for temporal interpolation.</p> required Source code in <code>geeagri/preprocessing.py</code> <pre><code>class RegularTimeseries:\n    \"\"\"\n    Generate a regularized and interpolated time series from an Earth Engine ImageCollection.\n\n    This class creates a temporally regular image collection by inserting empty\n    \"placeholder\" images at fixed intervals and then interpolating the original\n    collection to those dates.\n\n    Args:\n        image_collection (ee.ImageCollection): Original input image collection.\n        interval (int): Interval (in days) between consecutive target dates.\n        window (int): Window size (in days) for temporal interpolation.\n    \"\"\"\n\n    def __init__(\n        self, image_collection: ee.ImageCollection, interval: int, window: int\n    ):\n        \"\"\"\n        Args:\n            image_collection (ee.ImageCollection): Input collection to regularize.\n            interval (int): Interval (in days) between consecutive target dates.\n            window (int): Window size (in days) for interpolation.\n        \"\"\"\n        self._ic = image_collection\n        self.interval = interval\n        self.window = window\n\n        self._validate_inputs()\n\n        # Extract band names\n        self._band_names = ee.Image(self._ic.first()).bandNames()\n        self._n_bands = self._band_names.size()\n\n        self._init_bands = ee.List.repeat(ee.Image(), self._n_bands)\n        self._init_image = (\n            ee.ImageCollection(self._init_bands).toBands().rename(self._band_names)\n        )\n\n        # First and last images\n        self._first_image = ee.Image(self._ic.sort(\"system:time_start\").first())\n        self._last_image = ee.Image(self._ic.sort(\"system:time_start\", False).first())\n        self._time_start = ee.Date(self._first_image.get(\"system:time_start\"))\n        self._time_end = ee.Date(self._last_image.get(\"system:time_start\"))\n\n        # Generate list of target days\n        total_days = self._time_end.difference(self._time_start, \"day\")\n        self._days_to_interpolate = ee.List.sequence(0, total_days, self.interval)\n\n    def _validate_inputs(self) -&gt; None:\n        \"\"\"Validate user inputs and raise descriptive errors.\"\"\"\n        if not isinstance(self._ic, ee.ImageCollection):\n            raise ValueError(\n                \"`image_collection` must be an instance of ee.ImageCollection.\"\n            )\n        if not isinstance(self.interval, int):\n            raise ValueError(\"`interval` must be an integer (days).\")\n        if not isinstance(self.window, int):\n            raise ValueError(\"`window` must be an integer (days).\")\n\n    def _init_img(self, day: ee.Number) -&gt; ee.Image:\n        \"\"\"\n        Create a placeholder image for a given day offset.\n\n        Args:\n            day (ee.Number): Offset in days from the start date.\n\n        Returns:\n            ee.Image: Placeholder image with metadata for interpolation.\n        \"\"\"\n        day = ee.Number(day)\n        return self._init_image.set(\n            {\n                \"system:index\": day.format(\"%d\"),\n                \"system:time_start\": self._time_start.advance(day, \"day\").millis(),\n                \"type\": \"interpolated\",\n            }\n        )\n\n    def get_regular_timeseries(self) -&gt; ee.ImageCollection:\n        \"\"\"\n        Build a regularized and interpolated time series.\n\n        Returns:\n            ee.ImageCollection: Interpolated collection at regular time intervals.\n        \"\"\"\n        # Create placeholder images at target dates\n        init_col = ee.ImageCollection(\n            self._days_to_interpolate.map(lambda d: self._init_img(d))\n        )\n\n        # Merge placeholders with original collection\n        merged = self._ic.merge(init_col)\n\n        # Interpolate (requires TemporalInterpolation class)\n        temp_interp = TemporalInterpolation(merged, self.window)\n        interpolated_col = temp_interp.get_interpolated_collection()\n\n        # Keep only interpolated (regular) images\n        regular_col = interpolated_col.filter(ee.Filter.eq(\"type\", \"interpolated\"))\n\n        return regular_col\n</code></pre>"},{"location":"preprocessing/#geeagri.preprocessing.RegularTimeseries.__init__","title":"<code>__init__(self, image_collection, interval, window)</code>  <code>special</code>","text":"<p>Parameters:</p> Name Type Description Default <code>image_collection</code> <code>ee.ImageCollection</code> <p>Input collection to regularize.</p> required <code>interval</code> <code>int</code> <p>Interval (in days) between consecutive target dates.</p> required <code>window</code> <code>int</code> <p>Window size (in days) for interpolation.</p> required Source code in <code>geeagri/preprocessing.py</code> <pre><code>def __init__(\n    self, image_collection: ee.ImageCollection, interval: int, window: int\n):\n    \"\"\"\n    Args:\n        image_collection (ee.ImageCollection): Input collection to regularize.\n        interval (int): Interval (in days) between consecutive target dates.\n        window (int): Window size (in days) for interpolation.\n    \"\"\"\n    self._ic = image_collection\n    self.interval = interval\n    self.window = window\n\n    self._validate_inputs()\n\n    # Extract band names\n    self._band_names = ee.Image(self._ic.first()).bandNames()\n    self._n_bands = self._band_names.size()\n\n    self._init_bands = ee.List.repeat(ee.Image(), self._n_bands)\n    self._init_image = (\n        ee.ImageCollection(self._init_bands).toBands().rename(self._band_names)\n    )\n\n    # First and last images\n    self._first_image = ee.Image(self._ic.sort(\"system:time_start\").first())\n    self._last_image = ee.Image(self._ic.sort(\"system:time_start\", False).first())\n    self._time_start = ee.Date(self._first_image.get(\"system:time_start\"))\n    self._time_end = ee.Date(self._last_image.get(\"system:time_start\"))\n\n    # Generate list of target days\n    total_days = self._time_end.difference(self._time_start, \"day\")\n    self._days_to_interpolate = ee.List.sequence(0, total_days, self.interval)\n</code></pre>"},{"location":"preprocessing/#geeagri.preprocessing.RegularTimeseries.get_regular_timeseries","title":"<code>get_regular_timeseries(self)</code>","text":"<p>Build a regularized and interpolated time series.</p> <p>Returns:</p> Type Description <code>ee.ImageCollection</code> <p>Interpolated collection at regular time intervals.</p> Source code in <code>geeagri/preprocessing.py</code> <pre><code>def get_regular_timeseries(self) -&gt; ee.ImageCollection:\n    \"\"\"\n    Build a regularized and interpolated time series.\n\n    Returns:\n        ee.ImageCollection: Interpolated collection at regular time intervals.\n    \"\"\"\n    # Create placeholder images at target dates\n    init_col = ee.ImageCollection(\n        self._days_to_interpolate.map(lambda d: self._init_img(d))\n    )\n\n    # Merge placeholders with original collection\n    merged = self._ic.merge(init_col)\n\n    # Interpolate (requires TemporalInterpolation class)\n    temp_interp = TemporalInterpolation(merged, self.window)\n    interpolated_col = temp_interp.get_interpolated_collection()\n\n    # Keep only interpolated (regular) images\n    regular_col = interpolated_col.filter(ee.Filter.eq(\"type\", \"interpolated\"))\n\n    return regular_col\n</code></pre>"},{"location":"preprocessing/#geeagri.preprocessing.RobustScaler","title":"<code> RobustScaler        </code>","text":"<p>Applies robust scaling to each band of an Earth Engine image using percentiles, which reduces the influence of outliers compared to min-max scaling.</p> <p>The transformation is computed as:</p> <p>$$ X_\\text{scaled} = \\frac{X - P_{\\text{lower}}}{P_{\\text{upper}} - P_{\\text{lower}}} $$</p> <p>After clamping, $X_\\text{scaled} \\in [0, 1]$.</p> <p>Where:</p> <ul> <li>$X$: original pixel value</li> <li>$P_{\\text{lower}}$: lower percentile value (e.g., 25th percentile)</li> <li>$P_{\\text{upper}}$: upper percentile value (e.g., 75th percentile)</li> </ul> <p>This method is particularly useful when the image contains outliers or skewed distributions.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>ee.Image</code> <p>The input multi-band image.</p> required <code>region</code> <code>ee.Geometry</code> <p>Geometry over which percentiles are computed.</p> required <code>scale</code> <code>int</code> <p>Spatial resolution in meters for computation.</p> <code>100</code> <code>lower</code> <code>int</code> <p>Lower percentile to use (default: 25).</p> <code>25</code> <code>upper</code> <code>int</code> <p>Upper percentile to use (default: 75).</p> <code>75</code> <code>max_pixels</code> <code>int</code> <p>Maximum number of pixels allowed for region reduction.</p> <code>1000000000</code> <p>Exceptions:</p> Type Description <code>TypeError</code> <p>If <code>image</code> is not an <code>ee.Image</code> or <code>region</code> is not an <code>ee.Geometry</code>.</p> Source code in <code>geeagri/preprocessing.py</code> <pre><code>class RobustScaler:\n    r\"\"\"\n    Applies robust scaling to each band of an Earth Engine image using percentiles,\n    which reduces the influence of outliers compared to min-max scaling.\n\n    The transformation is computed as:\n\n    $$\n    X_\\\\text{scaled} = \\\\frac{X - P_{\\\\text{lower}}}{P_{\\\\text{upper}} - P_{\\\\text{lower}}}\n    $$\n\n    After clamping, $X_\\\\text{scaled} \\\\in [0, 1]$.\n\n    Where:\n\n    - $X$: original pixel value\n    - $P_{\\\\text{lower}}$: lower percentile value (e.g., 25th percentile)\n    - $P_{\\\\text{upper}}$: upper percentile value (e.g., 75th percentile)\n\n    This method is particularly useful when the image contains outliers or skewed distributions.\n\n    Args:\n        image (ee.Image): The input multi-band image.\n        region (ee.Geometry): Geometry over which percentiles are computed.\n        scale (int): Spatial resolution in meters for computation.\n        lower (int): Lower percentile to use (default: 25).\n        upper (int): Upper percentile to use (default: 75).\n        max_pixels (int): Maximum number of pixels allowed for region reduction.\n\n    Raises:\n        TypeError: If `image` is not an `ee.Image` or `region` is not an `ee.Geometry`.\n    \"\"\"\n\n    def __init__(\n        self,\n        image: ee.Image,\n        region: ee.Geometry,\n        scale: int = 100,\n        lower: int = 25,\n        upper: int = 75,\n        max_pixels: int = int(1e9),\n    ):\n        if not isinstance(image, ee.Image):\n            raise TypeError(\"Expected 'image' to be of type ee.Image.\")\n        if not isinstance(region, ee.Geometry):\n            raise TypeError(\"Expected 'region' to be of type ee.Geometry.\")\n        if not (0 &lt;= lower &lt; upper &lt;= 100):\n            raise ValueError(\"Percentiles must satisfy 0 &lt;= lower &lt; upper &lt;= 100.\")\n\n        self.image = image\n        self.region = region\n        self.scale = scale\n        self.lower = lower\n        self.upper = upper\n        self.max_pixels = max_pixels\n\n    def transform(self) -&gt; ee.Image:\n        \"\"\"\n        Applies percentile-based scaling to each band in the image.\n        Values are scaled to the [0, 1] range and clamped.\n\n        Returns:\n            ee.Image: The scaled image with values between 0 and 1.\n\n        Raises:\n            ValueError: If percentile reduction fails.\n        \"\"\"\n        bands = self.image.bandNames()\n        percentiles = self.image.reduceRegion(\n            reducer=ee.Reducer.percentile([self.lower, self.upper]),\n            geometry=self.region,\n            scale=self.scale,\n            bestEffort=True,\n            maxPixels=self.max_pixels,\n        )\n\n        if percentiles is None:\n            raise ValueError(\"Percentile computation failed.\")\n\n        def scale_band(band):\n            band = ee.String(band)\n            p_min = ee.Number(percentiles.get(band.cat(f\"_p{self.lower}\")))\n            p_max = ee.Number(percentiles.get(band.cat(f\"_p{self.upper}\")))\n            if p_min is None or p_max is None:\n                raise ValueError(\n                    f\"Missing percentile values for band: {band.getInfo()}\"\n                )\n\n            scaled = (\n                self.image.select(band).subtract(p_min).divide(p_max.subtract(p_min))\n            )\n            return scaled.clamp(0, 1).rename(band)\n\n        scaled = bands.map(scale_band)\n        return ee.ImageCollection(scaled).toBands().rename(bands)\n</code></pre>"},{"location":"preprocessing/#geeagri.preprocessing.RobustScaler.transform","title":"<code>transform(self)</code>","text":"<p>Applies percentile-based scaling to each band in the image. Values are scaled to the [0, 1] range and clamped.</p> <p>Returns:</p> Type Description <code>ee.Image</code> <p>The scaled image with values between 0 and 1.</p> <p>Exceptions:</p> Type Description <code>ValueError</code> <p>If percentile reduction fails.</p> Source code in <code>geeagri/preprocessing.py</code> <pre><code>def transform(self) -&gt; ee.Image:\n    \"\"\"\n    Applies percentile-based scaling to each band in the image.\n    Values are scaled to the [0, 1] range and clamped.\n\n    Returns:\n        ee.Image: The scaled image with values between 0 and 1.\n\n    Raises:\n        ValueError: If percentile reduction fails.\n    \"\"\"\n    bands = self.image.bandNames()\n    percentiles = self.image.reduceRegion(\n        reducer=ee.Reducer.percentile([self.lower, self.upper]),\n        geometry=self.region,\n        scale=self.scale,\n        bestEffort=True,\n        maxPixels=self.max_pixels,\n    )\n\n    if percentiles is None:\n        raise ValueError(\"Percentile computation failed.\")\n\n    def scale_band(band):\n        band = ee.String(band)\n        p_min = ee.Number(percentiles.get(band.cat(f\"_p{self.lower}\")))\n        p_max = ee.Number(percentiles.get(band.cat(f\"_p{self.upper}\")))\n        if p_min is None or p_max is None:\n            raise ValueError(\n                f\"Missing percentile values for band: {band.getInfo()}\"\n            )\n\n        scaled = (\n            self.image.select(band).subtract(p_min).divide(p_max.subtract(p_min))\n        )\n        return scaled.clamp(0, 1).rename(band)\n\n    scaled = bands.map(scale_band)\n    return ee.ImageCollection(scaled).toBands().rename(bands)\n</code></pre>"},{"location":"preprocessing/#geeagri.preprocessing.Sentinel2CloudMask","title":"<code> Sentinel2CloudMask        </code>","text":"<p>A utility class for creating cloud- and shadow-masked Sentinel-2 image collections.</p> <p>This class uses Sentinel-2 Level-2A Surface Reflectance (SR) data in combination with Sentinel-2 Cloud Probability (s2cloudless) data to generate a cloud-free ImageCollection.</p> <p>Attributes:</p> Name Type Description <code>region</code> <code>ee.Geometry</code> <p>The region of interest for filtering the ImageCollection.</p> <code>start_date</code> <code>str</code> <p>Start date (inclusive) in 'YYYY-MM-DD' format.</p> <code>end_date</code> <code>str</code> <p>End date (exclusive) in 'YYYY-MM-DD' format.</p> <code>cloud_filter</code> <code>int</code> <p>Maximum scene-level cloudiness allowed (%).</p> <code>cloud_prob_threshold</code> <code>int</code> <p>Cloud probability threshold (values above are considered clouds).</p> <code>nir_dark_threshold</code> <code>float</code> <p>NIR reflectance threshold (values below considered potential shadows).</p> <code>shadow_proj_dist</code> <code>int</code> <p>Maximum distance (km) to search for shadows from clouds.</p> <code>buffer</code> <code>int</code> <p>Buffer distance (m) to dilate cloud/shadow masks.</p> Source code in <code>geeagri/preprocessing.py</code> <pre><code>class Sentinel2CloudMask:\n    \"\"\"A utility class for creating cloud- and shadow-masked Sentinel-2 image collections.\n\n    This class uses Sentinel-2 Level-2A Surface Reflectance (SR) data in combination\n    with Sentinel-2 Cloud Probability (s2cloudless) data to generate a\n    cloud-free ImageCollection.\n\n    Attributes:\n        region (ee.Geometry): The region of interest for filtering the ImageCollection.\n        start_date (str): Start date (inclusive) in 'YYYY-MM-DD' format.\n        end_date (str): End date (exclusive) in 'YYYY-MM-DD' format.\n        cloud_filter (int): Maximum scene-level cloudiness allowed (%).\n        cloud_prob_threshold (int): Cloud probability threshold (values above are considered clouds).\n        nir_dark_threshold (float): NIR reflectance threshold (values below considered potential shadows).\n        shadow_proj_dist (int): Maximum distance (km) to search for shadows from clouds.\n        buffer (int): Buffer distance (m) to dilate cloud/shadow masks.\n    \"\"\"\n\n    def __init__(\n        self,\n        region,\n        start_date,\n        end_date,\n        cloud_filter=60,\n        cloud_prob_threshold=50,\n        nir_dark_threshold=0.15,\n        shadow_proj_dist=1,\n        buffer=50,\n    ):\n\n        if not isinstance(region, ee.Geometry):\n            raise ValueError(\"`region` must be an instance of ee.Geometry.\")\n\n        self.region = region\n        self.start_date = start_date\n        self.end_date = end_date\n        self.cloud_filter = cloud_filter\n        self.cloud_prob_threshold = cloud_prob_threshold\n        self.nir_dark_threshold = nir_dark_threshold\n        self.shadow_proj_dist = shadow_proj_dist\n        self.buffer = buffer\n\n    def get_cloud_collection(self):\n        \"\"\"Retrieve Sentinel-2 images joined with s2cloudless cloud probability.\n\n        Returns:\n            ee.ImageCollection: Sentinel-2 SR images with a property containing\n            the matching s2cloudless image.\n        \"\"\"\n        s2_sr = (\n            ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\")\n            .filterBounds(self.region)\n            .filterDate(self.start_date, self.end_date)\n            .filter(ee.Filter.lte(\"CLOUDY_PIXEL_PERCENTAGE\", self.cloud_filter))\n        )\n\n        s2_cloud_prob = (\n            ee.ImageCollection(\"COPERNICUS/S2_CLOUD_PROBABILITY\")\n            .filterBounds(self.region)\n            .filterDate(self.start_date, self.end_date)\n        )\n\n        joined = ee.ImageCollection(\n            ee.Join.saveFirst(\"cloud_prob\").apply(\n                primary=s2_sr,\n                secondary=s2_cloud_prob,\n                condition=ee.Filter.equals(\n                    leftField=\"system:index\", rightField=\"system:index\"\n                ),\n            )\n        )\n\n        return joined\n\n    def _add_cloud_bands(self, image):\n        \"\"\"Add cloud probability and binary cloud mask bands.\n\n        Args:\n            image (ee.Image): Sentinel-2 image.\n\n        Returns:\n            ee.Image: Image with added `cloud_prob` and `clouds` bands.\n        \"\"\"\n        cloud_prob = ee.Image(image.get(\"cloud_prob\")).select(\"probability\")\n        is_cloud = cloud_prob.gt(self.cloud_prob_threshold).rename(\"clouds\")\n\n        return image.addBands([cloud_prob.rename(\"cloud_prob\"), is_cloud])\n\n    def _add_shadow_bands(self, image):\n        \"\"\"Add potential shadow bands to the image.\n\n        Args:\n            image (ee.Image): Sentinel-2 image with cloud mask.\n\n        Returns:\n            ee.Image: Image with added `dark_pixels`, `cloud_transform`, and `shadows` bands.\n        \"\"\"\n        not_water = image.select(\"SCL\").neq(6)\n\n        scale_factor = 1e4\n        dark_pixels = (\n            image.select(\"B8\")\n            .lt(self.nir_dark_threshold * scale_factor)\n            .multiply(not_water)\n            .rename(\"dark_pixels\")\n        )\n\n        shadow_azimuth = ee.Number(90).subtract(\n            ee.Number(image.get(\"MEAN_SOLAR_AZIMUTH_ANGLE\"))\n        )\n\n        cloud_proj = (\n            image.select(\"clouds\")\n            .directionalDistanceTransform(shadow_azimuth, self.shadow_proj_dist * 10)\n            .reproject(crs=image.select(0).projection(), scale=100)\n            .select(\"distance\")\n            .mask()\n            .rename(\"cloud_transform\")\n        )\n\n        shadows = cloud_proj.multiply(dark_pixels).rename(\"shadows\")\n\n        return image.addBands([dark_pixels, cloud_proj, shadows])\n\n    def _add_cloud_shadow_mask(self, image):\n        \"\"\"Create combined cloud + shadow mask.\n\n        Args:\n            image (ee.Image): Sentinel-2 image.\n\n        Returns:\n            ee.Image: Image with an added `cloudmask` band.\n        \"\"\"\n        image = self._add_cloud_bands(image)\n        image = self._add_shadow_bands(image)\n\n        cloud_shadow_mask = image.select(\"clouds\").add(image.select(\"shadows\")).gt(0)\n\n        cloud_shadow_mask = (\n            cloud_shadow_mask.focal_min(2)\n            .focal_max(self.buffer * 2 / 20)\n            .reproject(crs=image.select(0).projection(), scale=20)\n            .rename(\"cloudmask\")\n        )\n\n        return image.addBands(cloud_shadow_mask)\n\n    def _apply_cloud_shadow_mask(self, image):\n        \"\"\"Apply cloud/shadow mask to reflectance bands.\n\n        Args:\n            image (ee.Image): Sentinel-2 image with `cloudmask` band.\n\n        Returns:\n            ee.Image: Cloud/shadow-masked image (reflectance bands only).\n        \"\"\"\n        not_cloud_shadow = image.select(\"cloudmask\").Not()\n        return image.select(\"B.*\").updateMask(not_cloud_shadow)\n\n    def get_cloudfree_collection(self):\n        \"\"\"Generate cloud-free Sentinel-2 ImageCollection.\n\n        Returns:\n            ee.ImageCollection: Cloud- and shadow-masked Sentinel-2 SR collection.\n        \"\"\"\n        cloud_collection = self.get_cloud_collection()\n        return cloud_collection.map(self._add_cloud_shadow_mask).map(\n            self._apply_cloud_shadow_mask\n        )\n</code></pre>"},{"location":"preprocessing/#geeagri.preprocessing.Sentinel2CloudMask.get_cloud_collection","title":"<code>get_cloud_collection(self)</code>","text":"<p>Retrieve Sentinel-2 images joined with s2cloudless cloud probability.</p> <p>Returns:</p> Type Description <code>ee.ImageCollection</code> <p>Sentinel-2 SR images with a property containing the matching s2cloudless image.</p> Source code in <code>geeagri/preprocessing.py</code> <pre><code>def get_cloud_collection(self):\n    \"\"\"Retrieve Sentinel-2 images joined with s2cloudless cloud probability.\n\n    Returns:\n        ee.ImageCollection: Sentinel-2 SR images with a property containing\n        the matching s2cloudless image.\n    \"\"\"\n    s2_sr = (\n        ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\")\n        .filterBounds(self.region)\n        .filterDate(self.start_date, self.end_date)\n        .filter(ee.Filter.lte(\"CLOUDY_PIXEL_PERCENTAGE\", self.cloud_filter))\n    )\n\n    s2_cloud_prob = (\n        ee.ImageCollection(\"COPERNICUS/S2_CLOUD_PROBABILITY\")\n        .filterBounds(self.region)\n        .filterDate(self.start_date, self.end_date)\n    )\n\n    joined = ee.ImageCollection(\n        ee.Join.saveFirst(\"cloud_prob\").apply(\n            primary=s2_sr,\n            secondary=s2_cloud_prob,\n            condition=ee.Filter.equals(\n                leftField=\"system:index\", rightField=\"system:index\"\n            ),\n        )\n    )\n\n    return joined\n</code></pre>"},{"location":"preprocessing/#geeagri.preprocessing.Sentinel2CloudMask.get_cloudfree_collection","title":"<code>get_cloudfree_collection(self)</code>","text":"<p>Generate cloud-free Sentinel-2 ImageCollection.</p> <p>Returns:</p> Type Description <code>ee.ImageCollection</code> <p>Cloud- and shadow-masked Sentinel-2 SR collection.</p> Source code in <code>geeagri/preprocessing.py</code> <pre><code>def get_cloudfree_collection(self):\n    \"\"\"Generate cloud-free Sentinel-2 ImageCollection.\n\n    Returns:\n        ee.ImageCollection: Cloud- and shadow-masked Sentinel-2 SR collection.\n    \"\"\"\n    cloud_collection = self.get_cloud_collection()\n    return cloud_collection.map(self._add_cloud_shadow_mask).map(\n        self._apply_cloud_shadow_mask\n    )\n</code></pre>"},{"location":"preprocessing/#geeagri.preprocessing.StandardScaler","title":"<code> StandardScaler        </code>","text":"<p>Standardizes each band of an Earth Engine image using z-score normalization.</p> <p>The transformation is computed as:</p> <p>$$ X_\\text{standardized} = \\frac{X - \\mu}{\\sigma} $$</p> <p>Where:</p> <ul> <li>$X$: original pixel value</li> <li>$\\mu$: mean of the band over the specified region</li> <li>$\\sigma$: standard deviation of the band over the specified region</li> </ul> <p>This transformation results in a standardized image where each band has zero mean and unit variance (approximately), assuming normally distributed values.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>ee.Image</code> <p>The input multi-band image to be standardized.</p> required <code>region</code> <code>ee.Geometry</code> <p>The geographic region over which to compute the statistics.</p> required <code>scale</code> <code>int</code> <p>Spatial resolution (in meters) to use for region reduction. Defaults to 100.</p> <code>100</code> <code>max_pixels</code> <code>int</code> <p>Maximum number of pixels allowed in reduction. Defaults to 1e9.</p> <code>1000000000</code> <p>Exceptions:</p> Type Description <code>TypeError</code> <p>If <code>image</code> is not an <code>ee.Image</code> or <code>region</code> is not an <code>ee.Geometry</code>.</p> Source code in <code>geeagri/preprocessing.py</code> <pre><code>class StandardScaler:\n    r\"\"\"\n    Standardizes each band of an Earth Engine image using z-score normalization.\n\n    The transformation is computed as:\n\n    $$\n    X_\\\\text{standardized} = \\\\frac{X - \\\\mu}{\\\\sigma}\n    $$\n\n    Where:\n\n    - $X$: original pixel value\n    - $\\mu$: mean of the band over the specified region\n    - $\\sigma$: standard deviation of the band over the specified region\n\n    This transformation results in a standardized image where each band has\n    zero mean and unit variance (approximately), assuming normally distributed values.\n\n    Args:\n        image (ee.Image): The input multi-band image to be standardized.\n        region (ee.Geometry): The geographic region over which to compute the statistics.\n        scale (int, optional): Spatial resolution (in meters) to use for region reduction. Defaults to 100.\n        max_pixels (int, optional): Maximum number of pixels allowed in reduction. Defaults to 1e9.\n\n    Raises:\n        TypeError: If `image` is not an `ee.Image` or `region` is not an `ee.Geometry`.\n    \"\"\"\n\n    def __init__(\n        self,\n        image: ee.Image,\n        region: ee.Geometry,\n        scale: int = 100,\n        max_pixels: int = int(1e9),\n    ):\n        if not isinstance(image, ee.Image):\n            raise TypeError(\"Expected 'image' to be of type ee.Image.\")\n        if not isinstance(region, ee.Geometry):\n            raise TypeError(\"Expected 'region' to be of type ee.Geometry.\")\n\n        self.image = image\n        self.region = region\n        self.scale = scale\n        self.max_pixels = max_pixels\n\n    def transform(self) -&gt; ee.Image:\n        \"\"\"\n        Applies z-score normalization to each band.\n\n        Returns:\n            ee.Image: Standardized image with zero mean and unit variance.\n\n        Raises:\n            ValueError: If statistics could not be computed.\n        \"\"\"\n        means = self.image.reduceRegion(\n            reducer=ee.Reducer.mean(),\n            geometry=self.region,\n            scale=self.scale,\n            bestEffort=True,\n            maxPixels=self.max_pixels,\n        )\n        stds = self.image.reduceRegion(\n            reducer=ee.Reducer.stdDev(),\n            geometry=self.region,\n            scale=self.scale,\n            bestEffort=True,\n            maxPixels=self.max_pixels,\n        )\n\n        if means is None or stds is None:\n            raise ValueError(\n                \"Statistic computation failed \u2014 check if region has valid pixels.\"\n            )\n\n        bands = self.image.bandNames()\n\n        def scale_band(band):\n            band = ee.String(band)\n            mean = ee.Number(means.get(band))\n            std = ee.Number(stds.get(band))\n            if mean is None or std is None:\n                raise ValueError(f\"Missing stats for band: {band.getInfo()}\")\n            return self.image.select(band).subtract(mean).divide(std).rename(band)\n\n        scaled = bands.map(scale_band)\n        return ee.ImageCollection(scaled).toBands().rename(bands)\n</code></pre>"},{"location":"preprocessing/#geeagri.preprocessing.StandardScaler.transform","title":"<code>transform(self)</code>","text":"<p>Applies z-score normalization to each band.</p> <p>Returns:</p> Type Description <code>ee.Image</code> <p>Standardized image with zero mean and unit variance.</p> <p>Exceptions:</p> Type Description <code>ValueError</code> <p>If statistics could not be computed.</p> Source code in <code>geeagri/preprocessing.py</code> <pre><code>def transform(self) -&gt; ee.Image:\n    \"\"\"\n    Applies z-score normalization to each band.\n\n    Returns:\n        ee.Image: Standardized image with zero mean and unit variance.\n\n    Raises:\n        ValueError: If statistics could not be computed.\n    \"\"\"\n    means = self.image.reduceRegion(\n        reducer=ee.Reducer.mean(),\n        geometry=self.region,\n        scale=self.scale,\n        bestEffort=True,\n        maxPixels=self.max_pixels,\n    )\n    stds = self.image.reduceRegion(\n        reducer=ee.Reducer.stdDev(),\n        geometry=self.region,\n        scale=self.scale,\n        bestEffort=True,\n        maxPixels=self.max_pixels,\n    )\n\n    if means is None or stds is None:\n        raise ValueError(\n            \"Statistic computation failed \u2014 check if region has valid pixels.\"\n        )\n\n    bands = self.image.bandNames()\n\n    def scale_band(band):\n        band = ee.String(band)\n        mean = ee.Number(means.get(band))\n        std = ee.Number(stds.get(band))\n        if mean is None or std is None:\n            raise ValueError(f\"Missing stats for band: {band.getInfo()}\")\n        return self.image.select(band).subtract(mean).divide(std).rename(band)\n\n    scaled = bands.map(scale_band)\n    return ee.ImageCollection(scaled).toBands().rename(bands)\n</code></pre>"},{"location":"preprocessing/#geeagri.preprocessing.TemporalInterpolation","title":"<code> TemporalInterpolation        </code>","text":"<p>Perform temporal interpolation on an Earth Engine ImageCollection.</p> <p>This class fills temporal gaps in an image collection by interpolating pixel values between the nearest available \"before\" and \"after\" images within a specified temporal window.</p> <p>Attributes:</p> Name Type Description <code>image_collection</code> <code>ee.ImageCollection</code> <p>The input Earth Engine image collection.</p> <code>window</code> <code>int</code> <p>The time window in days for searching before/after images.</p> Source code in <code>geeagri/preprocessing.py</code> <pre><code>class TemporalInterpolation:\n    \"\"\"Perform temporal interpolation on an Earth Engine ImageCollection.\n\n    This class fills temporal gaps in an image collection by interpolating pixel\n    values between the nearest available \"before\" and \"after\" images within a\n    specified temporal window.\n\n    Attributes:\n        image_collection (ee.ImageCollection): The input Earth Engine image collection.\n        window (int): The time window in days for searching before/after images.\n    \"\"\"\n\n    def __init__(self, image_collection: ee.ImageCollection, window: int):\n        self._ic = image_collection\n        self.window = window\n\n        self._validate_inputs()\n\n        # Convert window size from days \u2192 milliseconds\n        self._millis = ee.Number(window).multiply(1000 * 60 * 60 * 24)\n\n    def _validate_inputs(self) -&gt; None:\n        \"\"\"Validates user inputs.\n\n        Raises:\n            ValueError: If image_collection is not an ee.ImageCollection.\n            ValueError: If window is not an integer.\n        \"\"\"\n        if not isinstance(self._ic, ee.ImageCollection):\n            raise ValueError(\n                \"`image_collection` must be an instance of ee.ImageCollection.\"\n            )\n        if not isinstance(self.window, int):\n            raise ValueError(\"`window` must be an integer (days).\")\n\n    def _add_time_band(self, image: ee.Image) -&gt; ee.Image:\n        \"\"\"Adds a time band to an image.\n\n        Args:\n            image (ee.Image): Input image.\n\n        Returns:\n            ee.Image: The input image with an added 't' band representing acquisition time.\n        \"\"\"\n        t = image.metadata(\"system:time_start\").rename(\"t\")\n        # Mask time band with valid data pixels\n        t_masked = t.updateMask(image.mask().select(0))\n        return image.addBands(t_masked).toFloat()\n\n    def _compute(self, image: ee.Image) -&gt; ee.Image:\n        \"\"\"Interpolates missing pixels in an image using temporal neighbors.\n\n        Args:\n            image (ee.Image): An image with 'before' and 'after' neighbors attached.\n\n        Returns:\n            ee.Image: The image with gaps filled using temporal interpolation.\n        \"\"\"\n        image = ee.Image(image)\n\n        # Collect before and after mosaics\n        before_images = ee.List(image.get(\"before\"))\n        before_mosaic = ee.ImageCollection.fromImages(before_images).mosaic()\n\n        after_images = ee.List(image.get(\"after\"))\n        after_mosaic = ee.ImageCollection.fromImages(after_images).mosaic()\n\n        # Extract acquisition times\n        t1 = before_mosaic.select(\"t\").rename(\"t1\")\n        t2 = after_mosaic.select(\"t\").rename(\"t2\")\n        t = image.metadata(\"system:time_start\").rename(\"t\")\n\n        # Compute interpolation weight (0 at t1, 1 at t2)\n        time_image = ee.Image.cat([t1, t2, t])\n        time_ratio = time_image.expression(\n            \"(t - t1) / (t2 - t1)\",\n            {\n                \"t\": time_image.select(\"t\"),\n                \"t1\": time_image.select(\"t1\"),\n                \"t2\": time_image.select(\"t2\"),\n            },\n        )\n\n        # Linear interpolation\n        interpolated = before_mosaic.add(\n            (after_mosaic.subtract(before_mosaic)).multiply(time_ratio)\n        )\n\n        # Fill missing pixels with interpolated values\n        result = image.unmask(interpolated)\n\n        # Preserve original metadata\n        return result.copyProperties(image, [\"system:time_start\"])\n\n    def get_interpolated_collection(self) -&gt; ee.ImageCollection:\n        \"\"\"Generates a temporally interpolated image collection.\n\n        This method finds nearest before/after images within the time window\n        and performs linear interpolation to fill missing pixels.\n\n        Returns:\n            ee.ImageCollection: The temporally interpolated image collection.\n        \"\"\"\n        # Add acquisition time band to all images\n        self._ic = self._ic.map(self._add_time_band)\n\n        # Define filters for temporal proximity\n        maxDiffFilter = ee.Filter.maxDifference(\n            difference=self._millis,\n            leftField=\"system:time_start\",\n            rightField=\"system:time_start\",\n        )\n\n        # Match after-images (images captured later)\n        lessEqFilter = ee.Filter.lessThanOrEquals(\n            leftField=\"system:time_start\", rightField=\"system:time_start\"\n        )\n\n        after_filter = ee.Filter.And(maxDiffFilter, lessEqFilter)\n\n        after_join = ee.Join.saveAll(\n            matchesKey=\"after\", ordering=\"system:time_start\", ascending=False\n        )\n\n        with_after = after_join.apply(\n            primary=self._ic, secondary=self._ic, condition=after_filter\n        )\n\n        # Match before-images (images captured earlier)\n        greaterEqFilter = ee.Filter.greaterThanOrEquals(\n            leftField=\"system:time_start\", rightField=\"system:time_start\"\n        )\n\n        before_filter = ee.Filter.And(maxDiffFilter, greaterEqFilter)\n\n        before_join = ee.Join.saveAll(\n            matchesKey=\"before\", ordering=\"system:time_start\", ascending=True\n        )\n\n        with_neighbors = before_join.apply(\n            primary=with_after, secondary=with_after, condition=before_filter\n        )\n\n        # Apply temporal interpolation\n        interpolated = ee.ImageCollection(with_neighbors).map(self._compute)\n        band_names = interpolated.first().bandNames().removeAll([\"t\"])\n\n        # Remove the timeband\n        interpolated = interpolated.select(band_names)\n\n        return interpolated\n</code></pre>"},{"location":"preprocessing/#geeagri.preprocessing.TemporalInterpolation.get_interpolated_collection","title":"<code>get_interpolated_collection(self)</code>","text":"<p>Generates a temporally interpolated image collection.</p> <p>This method finds nearest before/after images within the time window and performs linear interpolation to fill missing pixels.</p> <p>Returns:</p> Type Description <code>ee.ImageCollection</code> <p>The temporally interpolated image collection.</p> Source code in <code>geeagri/preprocessing.py</code> <pre><code>def get_interpolated_collection(self) -&gt; ee.ImageCollection:\n    \"\"\"Generates a temporally interpolated image collection.\n\n    This method finds nearest before/after images within the time window\n    and performs linear interpolation to fill missing pixels.\n\n    Returns:\n        ee.ImageCollection: The temporally interpolated image collection.\n    \"\"\"\n    # Add acquisition time band to all images\n    self._ic = self._ic.map(self._add_time_band)\n\n    # Define filters for temporal proximity\n    maxDiffFilter = ee.Filter.maxDifference(\n        difference=self._millis,\n        leftField=\"system:time_start\",\n        rightField=\"system:time_start\",\n    )\n\n    # Match after-images (images captured later)\n    lessEqFilter = ee.Filter.lessThanOrEquals(\n        leftField=\"system:time_start\", rightField=\"system:time_start\"\n    )\n\n    after_filter = ee.Filter.And(maxDiffFilter, lessEqFilter)\n\n    after_join = ee.Join.saveAll(\n        matchesKey=\"after\", ordering=\"system:time_start\", ascending=False\n    )\n\n    with_after = after_join.apply(\n        primary=self._ic, secondary=self._ic, condition=after_filter\n    )\n\n    # Match before-images (images captured earlier)\n    greaterEqFilter = ee.Filter.greaterThanOrEquals(\n        leftField=\"system:time_start\", rightField=\"system:time_start\"\n    )\n\n    before_filter = ee.Filter.And(maxDiffFilter, greaterEqFilter)\n\n    before_join = ee.Join.saveAll(\n        matchesKey=\"before\", ordering=\"system:time_start\", ascending=True\n    )\n\n    with_neighbors = before_join.apply(\n        primary=with_after, secondary=with_after, condition=before_filter\n    )\n\n    # Apply temporal interpolation\n    interpolated = ee.ImageCollection(with_neighbors).map(self._compute)\n    band_names = interpolated.first().bandNames().removeAll([\"t\"])\n\n    # Remove the timeband\n    interpolated = interpolated.select(band_names)\n\n    return interpolated\n</code></pre>"},{"location":"usage/","title":"Usage","text":"<p>To use geeagri in a project:</p> <pre><code>import geeagri\n</code></pre>"},{"location":"examples/harmonic_regression/","title":"Harmonic regression","text":"<p>Uncomment the following line to install the latest version of geeagri if needed.</p> In\u00a0[\u00a0]: Copied! <pre># !pip install -U geeagri\n</pre> # !pip install -U geeagri In\u00a0[\u00a0]: Copied! <pre>import ee\nimport geemap\nfrom geeagri.analysis import HarmonicRegression\nfrom geeagri.preprocessing import Sentinel2CloudMask\nfrom geeagri.extract import extract_timeseries_to_point\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.rcParams[\"font.family\"] = \"DeJavu Serif\"\nplt.rcParams[\"font.serif\"] = \"Times New Roman\"\n</pre> import ee import geemap from geeagri.analysis import HarmonicRegression from geeagri.preprocessing import Sentinel2CloudMask from geeagri.extract import extract_timeseries_to_point  import matplotlib.pyplot as plt import seaborn as sns  plt.rcParams[\"font.family\"] = \"DeJavu Serif\" plt.rcParams[\"font.serif\"] = \"Times New Roman\" In\u00a0[\u00a0]: Copied! <pre># ee.Authenticate()\n# ee.Initialize(project='your-project-id')\n\nMap = geemap.Map(basemap=\"SATELLITE\")\nMap\n</pre> # ee.Authenticate() # ee.Initialize(project='your-project-id')  Map = geemap.Map(basemap=\"SATELLITE\") Map In\u00a0[\u00a0]: Copied! <pre>bbox = [-98.451233, 38.430732, -98.274765, 38.523996]\nregion = ee.Geometry.BBox(*bbox)\nregion_style = {\"color\": \"red\", \"width\": 1}\nMap.addLayer(region, region_style, \"Region\")\nMap.centerObject(region, 13)\n</pre> bbox = [-98.451233, 38.430732, -98.274765, 38.523996] region = ee.Geometry.BBox(*bbox) region_style = {\"color\": \"red\", \"width\": 1} Map.addLayer(region, region_style, \"Region\") Map.centerObject(region, 13) In\u00a0[\u00a0]: Copied! <pre>croplandcover = (\n    ee.ImageCollection(\"USDA/NASS/CDL\")\n    .filterDate(\"2020-01-01\", \"2021-01-01\")\n    .first()\n    .clip(region)\n)\n\ncultivated = croplandcover.select(\"cultivated\").eq(2).selfMask()\ncroplandcover = croplandcover.select(\"cropland\")\nMap.addLayer(cultivated, {}, \"Cultivated\")\nMap.addLayer(croplandcover, {}, \"Crop Landcover\")\n</pre> croplandcover = (     ee.ImageCollection(\"USDA/NASS/CDL\")     .filterDate(\"2020-01-01\", \"2021-01-01\")     .first()     .clip(region) )  cultivated = croplandcover.select(\"cultivated\").eq(2).selfMask() croplandcover = croplandcover.select(\"cropland\") Map.addLayer(cultivated, {}, \"Cultivated\") Map.addLayer(croplandcover, {}, \"Crop Landcover\") In\u00a0[\u00a0]: Copied! <pre>s2_cloud_masker = Sentinel2CloudMask(\n    region=region,\n    start_date=\"2020-01-01\",\n    end_date=\"2021-01-01\",\n    cloud_filter=60,  # maximum scene-level cloudiness allowed (%)\n    cloud_prob_threshold=50,  # cloud probability threshold (values above are considered clouds)\n    nir_dark_threshold=0.15,  # NIR reflectance threshold (values below considered potential shadows)\n    shadow_proj_dist=1,  # maximum distance (km) to search for shadows from clouds.\n    buffer=50,  # buffer distance (m) to dilate cloud/shadow masks.\n)\n\ns2_cloud_masked = s2_cloud_masker.get_cloudfree_collection()\n</pre> s2_cloud_masker = Sentinel2CloudMask(     region=region,     start_date=\"2020-01-01\",     end_date=\"2021-01-01\",     cloud_filter=60,  # maximum scene-level cloudiness allowed (%)     cloud_prob_threshold=50,  # cloud probability threshold (values above are considered clouds)     nir_dark_threshold=0.15,  # NIR reflectance threshold (values below considered potential shadows)     shadow_proj_dist=1,  # maximum distance (km) to search for shadows from clouds.     buffer=50,  # buffer distance (m) to dilate cloud/shadow masks. )  s2_cloud_masked = s2_cloud_masker.get_cloudfree_collection() In\u00a0[\u00a0]: Copied! <pre>def calculateNDVI(image):\n    ndvi = image.expression(\n        \"(NIR - Red) / (NIR + Red)\",\n        {\"NIR\": image.select(\"B8\"), \"Red\": image.select(\"B4\")},\n    ).copyProperties(image, [\"system:time_start\"])\n\n    ndvi = ee.Image(ndvi).rename(\"ndvi\").clip(region)\n\n    return ndvi\n\n\nndvi_col = s2_cloud_masked.map(calculateNDVI)\n</pre> def calculateNDVI(image):     ndvi = image.expression(         \"(NIR - Red) / (NIR + Red)\",         {\"NIR\": image.select(\"B8\"), \"Red\": image.select(\"B4\")},     ).copyProperties(image, [\"system:time_start\"])      ndvi = ee.Image(ndvi).rename(\"ndvi\").clip(region)      return ndvi   ndvi_col = s2_cloud_masked.map(calculateNDVI) In\u00a0[\u00a0]: Copied! <pre># Fit a 3rd order harmonic\nharmonics = HarmonicRegression(\n    image_collection=ndvi_col, ref_date=\"2020-01-01\", band_name=\"ndvi\", order=3, omega=1\n)\n\n# Get the harmonic coefficients\nharmonic_coeffs = harmonics.get_harmonic_coeffs()\n\n# Get the phase amplitude in an HSV image\nphase_amplitude_hsv = harmonics.get_phase_amplitude(\n    harmonic_coeffs,\n    cos_band=\"ndvi_cos_1\",\n    sin_band=\"ndvi_sin_1\",\n    hsv=True,\n    stretch_factor=5,\n)\nMap.addLayer(phase_amplitude_hsv, {}, \"Phase (hue), Amplitude (sat), NDVI (val)\")\n\n# Get the raw phase and amplitude image\nphase_amplitude = harmonics.get_phase_amplitude(\n    harmonic_coeffs,\n    cos_band=\"ndvi_cos_1\",\n    sin_band=\"ndvi_sin_1\",\n    hsv=False,\n)\nphase_vis = {\n    \"min\": -3.10,\n    \"max\": 3.10,\n    \"palette\": [\n        \"#d73027\",\n        \"#f46d43\",\n        \"#fdae61\",\n        \"#fee08b\",\n        \"#d9ef8b\",\n        \"#a6d96a\",\n        \"#66bd63\",\n        \"#1a9850\",\n    ],\n}\namplitude_vis = {\n    \"min\": 0,\n    \"max\": 0.4,\n    \"palette\": [\n        \"#ffffe5\",\n        \"#f7fcb9\",\n        \"#d9f0a3\",\n        \"#addd8e\",\n        \"#78c679\",\n        \"#41ab5d\",\n        \"#238443\",\n        \"#005a32\",\n    ],\n}\n\nMap.addLayer(phase_amplitude.select(\"phase\"), phase_vis, \"Phase (-\u03c0 to \u03c0)\")\nMap.addLayer(phase_amplitude.select(\"amplitude\"), amplitude_vis, \"Amplitude\")\n\n# Get fitted harmonics\nfitted_harmonics = harmonics.get_fitted_harmonics(harmonic_coeffs)\n</pre> # Fit a 3rd order harmonic harmonics = HarmonicRegression(     image_collection=ndvi_col, ref_date=\"2020-01-01\", band_name=\"ndvi\", order=3, omega=1 )  # Get the harmonic coefficients harmonic_coeffs = harmonics.get_harmonic_coeffs()  # Get the phase amplitude in an HSV image phase_amplitude_hsv = harmonics.get_phase_amplitude(     harmonic_coeffs,     cos_band=\"ndvi_cos_1\",     sin_band=\"ndvi_sin_1\",     hsv=True,     stretch_factor=5, ) Map.addLayer(phase_amplitude_hsv, {}, \"Phase (hue), Amplitude (sat), NDVI (val)\")  # Get the raw phase and amplitude image phase_amplitude = harmonics.get_phase_amplitude(     harmonic_coeffs,     cos_band=\"ndvi_cos_1\",     sin_band=\"ndvi_sin_1\",     hsv=False, ) phase_vis = {     \"min\": -3.10,     \"max\": 3.10,     \"palette\": [         \"#d73027\",         \"#f46d43\",         \"#fdae61\",         \"#fee08b\",         \"#d9ef8b\",         \"#a6d96a\",         \"#66bd63\",         \"#1a9850\",     ], } amplitude_vis = {     \"min\": 0,     \"max\": 0.4,     \"palette\": [         \"#ffffe5\",         \"#f7fcb9\",         \"#d9f0a3\",         \"#addd8e\",         \"#78c679\",         \"#41ab5d\",         \"#238443\",         \"#005a32\",     ], }  Map.addLayer(phase_amplitude.select(\"phase\"), phase_vis, \"Phase (-\u03c0 to \u03c0)\") Map.addLayer(phase_amplitude.select(\"amplitude\"), amplitude_vis, \"Amplitude\")  # Get fitted harmonics fitted_harmonics = harmonics.get_fitted_harmonics(harmonic_coeffs) In\u00a0[\u00a0]: Copied! <pre>wheat_loc = (-98.39630126953126, 38.46931531751283)\nsoybean_loc = (-98.34480285644533, 38.50022087618732)\ncorn_loc = (-98.31716537475587, 38.496190467979176)\n\nwheat_ndvi = extract_timeseries_to_point(\n    lat=wheat_loc[1], lon=wheat_loc[0], image_collection=ndvi_col, scale=10\n)\nsoybean_ndvi = extract_timeseries_to_point(\n    lat=soybean_loc[1], lon=soybean_loc[0], image_collection=ndvi_col, scale=10\n)\ncorn_ndvi = extract_timeseries_to_point(\n    lat=corn_loc[1], lon=corn_loc[0], image_collection=ndvi_col, scale=10\n)\nwheat_ndvi_fitted = extract_timeseries_to_point(\n    lat=wheat_loc[1], lon=wheat_loc[0], image_collection=fitted_harmonics, scale=10\n)\nsoybean_ndvi_fitted = extract_timeseries_to_point(\n    lat=soybean_loc[1], lon=soybean_loc[0], image_collection=fitted_harmonics, scale=10\n)\ncorn_ndvi_fitted = extract_timeseries_to_point(\n    lat=corn_loc[1], lon=corn_loc[0], image_collection=fitted_harmonics, scale=10\n)\n</pre> wheat_loc = (-98.39630126953126, 38.46931531751283) soybean_loc = (-98.34480285644533, 38.50022087618732) corn_loc = (-98.31716537475587, 38.496190467979176)  wheat_ndvi = extract_timeseries_to_point(     lat=wheat_loc[1], lon=wheat_loc[0], image_collection=ndvi_col, scale=10 ) soybean_ndvi = extract_timeseries_to_point(     lat=soybean_loc[1], lon=soybean_loc[0], image_collection=ndvi_col, scale=10 ) corn_ndvi = extract_timeseries_to_point(     lat=corn_loc[1], lon=corn_loc[0], image_collection=ndvi_col, scale=10 ) wheat_ndvi_fitted = extract_timeseries_to_point(     lat=wheat_loc[1], lon=wheat_loc[0], image_collection=fitted_harmonics, scale=10 ) soybean_ndvi_fitted = extract_timeseries_to_point(     lat=soybean_loc[1], lon=soybean_loc[0], image_collection=fitted_harmonics, scale=10 ) corn_ndvi_fitted = extract_timeseries_to_point(     lat=corn_loc[1], lon=corn_loc[0], image_collection=fitted_harmonics, scale=10 ) In\u00a0[\u00a0]: Copied! <pre>plt.figure(figsize=(12, 4))\n\nsns.lineplot(\n    data=wheat_ndvi,\n    x=\"time\",\n    y=\"ndvi\",\n    label=\"Wheat NDVI\",\n    alpha=0.5,\n    c=\"#a87000\",\n)\nsns.lineplot(\n    data=wheat_ndvi_fitted,\n    x=\"time\",\n    y=\"fitted\",\n    label=\"Wheat NDVI Fitted\",\n    c=\"#a87000\",\n    marker=\"o\",\n    markersize=5,\n)\n\nsns.lineplot(\n    data=soybean_ndvi,\n    x=\"time\",\n    y=\"ndvi\",\n    label=\"Soybean NDVI\",\n    alpha=0.5,\n    c=\"#267300\",\n)\nsns.lineplot(\n    data=soybean_ndvi_fitted,\n    x=\"time\",\n    y=\"fitted\",\n    label=\"Soybean NDVI Fitted\",\n    c=\"#267300\",\n    marker=\"o\",\n    markersize=5,\n)\n\nsns.lineplot(\n    data=corn_ndvi, x=\"time\", y=\"ndvi\", label=\"Corn NDVI\", alpha=0.5, c=\"#ffd400\"\n)\nsns.lineplot(\n    data=corn_ndvi_fitted,\n    x=\"time\",\n    y=\"fitted\",\n    label=\"Corn NDVI Fitted\",\n    c=\"#ffd400\",\n    marker=\"o\",\n    markersize=5,\n)\n\nplt.title(\"3rd-Order Harmonic Fit of NDVI Time Series\")\nplt.ylabel(\"NDVI\")\nplt.show()\n</pre> plt.figure(figsize=(12, 4))  sns.lineplot(     data=wheat_ndvi,     x=\"time\",     y=\"ndvi\",     label=\"Wheat NDVI\",     alpha=0.5,     c=\"#a87000\", ) sns.lineplot(     data=wheat_ndvi_fitted,     x=\"time\",     y=\"fitted\",     label=\"Wheat NDVI Fitted\",     c=\"#a87000\",     marker=\"o\",     markersize=5, )  sns.lineplot(     data=soybean_ndvi,     x=\"time\",     y=\"ndvi\",     label=\"Soybean NDVI\",     alpha=0.5,     c=\"#267300\", ) sns.lineplot(     data=soybean_ndvi_fitted,     x=\"time\",     y=\"fitted\",     label=\"Soybean NDVI Fitted\",     c=\"#267300\",     marker=\"o\",     markersize=5, )  sns.lineplot(     data=corn_ndvi, x=\"time\", y=\"ndvi\", label=\"Corn NDVI\", alpha=0.5, c=\"#ffd400\" ) sns.lineplot(     data=corn_ndvi_fitted,     x=\"time\",     y=\"fitted\",     label=\"Corn NDVI Fitted\",     c=\"#ffd400\",     marker=\"o\",     markersize=5, )  plt.title(\"3rd-Order Harmonic Fit of NDVI Time Series\") plt.ylabel(\"NDVI\") plt.show()"},{"location":"examples/harmonic_regression/#import-libraries","title":"Import libraries\u00b6","text":""},{"location":"examples/harmonic_regression/#initialize-a-map-object","title":"Initialize a Map object\u00b6","text":"<p>Authenticate and initialize Earth Engine. If it doesn't work, specify a project name</p>"},{"location":"examples/harmonic_regression/#import-region-of-interest","title":"Import region of interest\u00b6","text":""},{"location":"examples/harmonic_regression/#import-cropland-data-layer-cdl","title":"Import Cropland Data Layer (CDL)\u00b6","text":""},{"location":"examples/harmonic_regression/#load-sentinel-2-image-collection-and-mask-clouds-and-shadows","title":"Load Sentinel-2 image collection and mask clouds and shadows\u00b6","text":""},{"location":"examples/harmonic_regression/#calculate-normalized-difference-vegetation-index-ndvi","title":"Calculate Normalized Difference Vegetation Index (NDVI)\u00b6","text":""},{"location":"examples/harmonic_regression/#apply-harmonics","title":"Apply Harmonics\u00b6","text":""},{"location":"examples/harmonic_regression/#plot-the-fitted-harmonics-for-three-crop-samples","title":"Plot the fitted harmonics for three crop samples\u00b6","text":""},{"location":"examples/image_patch_extraction/","title":"Image patch extraction","text":"<p>Uncomment the following line to install the latest version of geeagri if needed.</p> In\u00a0[\u00a0]: Copied! <pre># !pip install -U geeagri\n</pre> # !pip install -U geeagri In\u00a0[\u00a0]: Copied! <pre>import os\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport rasterio as rio\nimport ee\nimport geemap\nfrom geeagri.extract import ImagePatchExtractor\n</pre> import os import random import numpy as np import matplotlib.pyplot as plt import rasterio as rio import ee import geemap from geeagri.extract import ImagePatchExtractor In\u00a0[\u00a0]: Copied! <pre># ee.Authenticate()\n# ee.Initialize(opt_url=\"https://earthengine-highvolume.googleapis.com\", project='your-project-id')\n\nMap = geemap.Map()\nMap\n</pre> # ee.Authenticate() # ee.Initialize(opt_url=\"https://earthengine-highvolume.googleapis.com\", project='your-project-id')  Map = geemap.Map() Map In\u00a0[\u00a0]: Copied! <pre>bbox = [-119.9875, 35.6004, -114.5383, 38.6995]\nregion = ee.Geometry.BBox(*bbox)\nregion_style = {\"color\": \"red\", \"width\": 1}\nMap.addLayer(region, region_style, \"Region\")\nMap.centerObject(region, 7)\n</pre> bbox = [-119.9875, 35.6004, -114.5383, 38.6995] region = ee.Geometry.BBox(*bbox) region_style = {\"color\": \"red\", \"width\": 1} Map.addLayer(region, region_style, \"Region\") Map.centerObject(region, 7) In\u00a0[\u00a0]: Copied! <pre>image = (\n    ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\")\n    .filterBounds(region)\n    .filterDate(\"2024-01-01\", \"2025-01-01\")\n    .filterMetadata(\"CLOUDY_PIXEL_PERCENTAGE\", \"less_than\", 10)\n    .select([\"B8\", \"B4\", \"B3\"])\n    .median()\n    .multiply(0.0001)\n    .clip(region)\n)\n\nimage_vis = {\"bands\": [\"B8\", \"B4\", \"B3\"], \"min\": 0, \"max\": 0.3}\n\nMap.addLayer(image, image_vis, \"Sentinel 2 FCC\")\n</pre> image = (     ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\")     .filterBounds(region)     .filterDate(\"2024-01-01\", \"2025-01-01\")     .filterMetadata(\"CLOUDY_PIXEL_PERCENTAGE\", \"less_than\", 10)     .select([\"B8\", \"B4\", \"B3\"])     .median()     .multiply(0.0001)     .clip(region) )  image_vis = {\"bands\": [\"B8\", \"B4\", \"B3\"], \"min\": 0, \"max\": 0.3}  Map.addLayer(image, image_vis, \"Sentinel 2 FCC\") In\u00a0[\u00a0]: Copied! <pre># Sample random points from the image\nsample = image.sample(\n    region=region.buffer(-2000),\n    scale=100,\n    numPixels=100,\n    seed=42,\n    dropNulls=True,\n    tileScale=16,\n    geometries=True,\n)\nsample_style = {\"color\": \"blue\", \"width\": 2}\nMap.addLayer(sample.style(**sample_style), {}, \"Samples\")\n\n# Convert the Earth Engine FeatureCollection to a GeoDataFrame\nsample_gdf = geemap.ee_to_gdf(sample)\nsample_gdf[\"ID\"] = sample_gdf.index  # identifier\nprint(sample_gdf.shape)\nsample_gdf.head()\n</pre> # Sample random points from the image sample = image.sample(     region=region.buffer(-2000),     scale=100,     numPixels=100,     seed=42,     dropNulls=True,     tileScale=16,     geometries=True, ) sample_style = {\"color\": \"blue\", \"width\": 2} Map.addLayer(sample.style(**sample_style), {}, \"Samples\")  # Convert the Earth Engine FeatureCollection to a GeoDataFrame sample_gdf = geemap.ee_to_gdf(sample) sample_gdf[\"ID\"] = sample_gdf.index  # identifier print(sample_gdf.shape) sample_gdf.head() In\u00a0[\u00a0]: Copied! <pre># Create an instance of the patch extractor\npatch_extractor = ImagePatchExtractor(\n    image=image,  # Earth Engine image to extract from\n    sample_gdf=sample_gdf,  # GeoDataFrame of sample points\n    identifier=\"ID\",  # Column name for naming output files\n    out_dir=\"images\",  # Output directory for patches\n    buffer=1270,  # Buffer (in meters) around each point\n    dimensions=\"256x256\",  # Output image size (width x height)\n    format=\"GEO_TIFF\",  # Output format: e.g., 'GEO_TIFF', 'png', 'jpg'\n    num_processes=20,  # Number of parallel processes to use\n)\n\n# Start extracting patches\npatch_extractor.extract_patches()\n</pre> # Create an instance of the patch extractor patch_extractor = ImagePatchExtractor(     image=image,  # Earth Engine image to extract from     sample_gdf=sample_gdf,  # GeoDataFrame of sample points     identifier=\"ID\",  # Column name for naming output files     out_dir=\"images\",  # Output directory for patches     buffer=1270,  # Buffer (in meters) around each point     dimensions=\"256x256\",  # Output image size (width x height)     format=\"GEO_TIFF\",  # Output format: e.g., 'GEO_TIFF', 'png', 'jpg'     num_processes=20,  # Number of parallel processes to use )  # Start extracting patches patch_extractor.extract_patches() In\u00a0[\u00a0]: Copied! <pre># Directory where image patches are saved\npatch_dir = \"images\"  # Update if needed\n\n# List of available GeoTIFF files\ntif_files = [f for f in os.listdir(patch_dir) if f.endswith(\".tif\")]\n\n# Randomly select 9 files\nselected_files = random.sample(tif_files, min(36, len(tif_files)))\n\n# Plot setup\nfig, axes = plt.subplots(6, 6, figsize=(12, 12))\naxes = axes.flatten()\n\nfor ax, file in zip(axes, selected_files):\n    file_path = os.path.join(patch_dir, file)\n\n    with rio.open(file_path) as src:\n        img = src.read([1, 2, 3])  # (3, H, W)\n        img = np.transpose(img, (1, 2, 0))  # (H, W, 3)\n\n    # Percentile clipping to remove outliers\n    p_low, p_high = np.percentile(img, (2, 98))\n    img = np.clip(img, p_low, p_high)\n\n    # Normalize to 0\u2013255\n    img = ((img - p_low) / (p_high - p_low)) * 255\n    img = np.clip(img, 0, 255).astype(np.uint8)\n\n    ax.imshow(img)\n    ax.set_title(file, fontsize=10)\n    ax.axis(\"off\")\n\n# Hide extra axes if fewer than 9 images\nfor ax in axes[len(selected_files) :]:\n    ax.axis(\"off\")\n\nplt.tight_layout()\nplt.show()\n</pre> # Directory where image patches are saved patch_dir = \"images\"  # Update if needed  # List of available GeoTIFF files tif_files = [f for f in os.listdir(patch_dir) if f.endswith(\".tif\")]  # Randomly select 9 files selected_files = random.sample(tif_files, min(36, len(tif_files)))  # Plot setup fig, axes = plt.subplots(6, 6, figsize=(12, 12)) axes = axes.flatten()  for ax, file in zip(axes, selected_files):     file_path = os.path.join(patch_dir, file)      with rio.open(file_path) as src:         img = src.read([1, 2, 3])  # (3, H, W)         img = np.transpose(img, (1, 2, 0))  # (H, W, 3)      # Percentile clipping to remove outliers     p_low, p_high = np.percentile(img, (2, 98))     img = np.clip(img, p_low, p_high)      # Normalize to 0\u2013255     img = ((img - p_low) / (p_high - p_low)) * 255     img = np.clip(img, 0, 255).astype(np.uint8)      ax.imshow(img)     ax.set_title(file, fontsize=10)     ax.axis(\"off\")  # Hide extra axes if fewer than 9 images for ax in axes[len(selected_files) :]:     ax.axis(\"off\")  plt.tight_layout() plt.show()"},{"location":"examples/image_patch_extraction/#import-libraries","title":"Import libraries\u00b6","text":""},{"location":"examples/image_patch_extraction/#initialize-a-map-object","title":"Initialize a Map object\u00b6","text":"<p>Authenticate and initialize Earth Engine. Replace 'your-project-id' with your actual Google Cloud project ID if needed. If you're working with high-volume data or large-scale exports, use the highvolume endpoint shown above.</p>"},{"location":"examples/image_patch_extraction/#import-region-of-interest","title":"Import region of interest\u00b6","text":""},{"location":"examples/image_patch_extraction/#load-sentinel-2-data-and-create-a-median-composite","title":"Load Sentinel-2 data and create a median composite\u00b6","text":""},{"location":"examples/image_patch_extraction/#sampling-points-from-earth-engine-and-converting-to-geodataframe","title":"Sampling points from Earth Engine and converting to GeoDataFrame\u00b6","text":"<p>\ud83d\udcdd Note: You can also skip the sampling step entirely and use your own point samples by loading a GeoDataFrame from local storage (e.g., a GeoJSON or shapefile). Just make sure the GeoDataFrame includes a unique identifier column (e.g., \"ID\") that can be used to name the extracted patches.</p>"},{"location":"examples/image_patch_extraction/#imagepatchextractor","title":"ImagePatchExtractor\u00b6","text":""},{"location":"examples/image_patch_extraction/#visualizing-random-image-patches-rgb","title":"Visualizing random image patches (RGB)\u00b6","text":""},{"location":"examples/image_scaling/","title":"Image scaling","text":"<p>Uncomment the following line to install the latest version of geeagri if needed.</p> In\u00a0[\u00a0]: Copied! <pre># !pip install -U geeagri\n</pre> # !pip install -U geeagri In\u00a0[\u00a0]: Copied! <pre>import ee\nimport geemap\nfrom geeagri.preprocessing import (\n    MeanCentering,\n    StandardScaler,\n    MinMaxScaler,\n    RobustScaler,\n)\n</pre> import ee import geemap from geeagri.preprocessing import (     MeanCentering,     StandardScaler,     MinMaxScaler,     RobustScaler, ) In\u00a0[\u00a0]: Copied! <pre># ee.Authenticate()\n# ee.Initialize(project='your-project-id')\n\nMap = geemap.Map()\nMap\n</pre> # ee.Authenticate() # ee.Initialize(project='your-project-id')  Map = geemap.Map() Map In\u00a0[\u00a0]: Copied! <pre>bbox = [-120.398369, 37.006574, -120.208168, 37.101924]\nregion = ee.Geometry.BBox(*bbox)\nregion_style = {\"color\": \"red\", \"width\": 1}\nMap.addLayer(region, region_style, \"Region\")\nMap.centerObject(region, 12)\n</pre> bbox = [-120.398369, 37.006574, -120.208168, 37.101924] region = ee.Geometry.BBox(*bbox) region_style = {\"color\": \"red\", \"width\": 1} Map.addLayer(region, region_style, \"Region\") Map.centerObject(region, 12) In\u00a0[\u00a0]: Copied! <pre>image = (\n    ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\")\n    .filterBounds(region)\n    .filterDate(\"2024-01-01\", \"2025-01-01\")\n    .filterMetadata(\"CLOUDY_PIXEL_PERCENTAGE\", \"less_than\", 10)\n    .select([\"B8\", \"B4\", \"B3\"])\n    .median()\n    .multiply(0.0001)\n    .clip(region)\n)\n\nimage_vis = {\"bands\": [\"B8\", \"B4\", \"B3\"], \"min\": 0, \"max\": 0.3}\n\nMap.addLayer(image, image_vis, \"Sentinel 2 FCC\")\n</pre> image = (     ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\")     .filterBounds(region)     .filterDate(\"2024-01-01\", \"2025-01-01\")     .filterMetadata(\"CLOUDY_PIXEL_PERCENTAGE\", \"less_than\", 10)     .select([\"B8\", \"B4\", \"B3\"])     .median()     .multiply(0.0001)     .clip(region) )  image_vis = {\"bands\": [\"B8\", \"B4\", \"B3\"], \"min\": 0, \"max\": 0.3}  Map.addLayer(image, image_vis, \"Sentinel 2 FCC\") In\u00a0[\u00a0]: Copied! <pre>scaler = MeanCentering(image, region)\ncentered_image = scaler.transform()\n\n# Adjust visualization range around 0 to reflect centered values\ncentered_image_vis = {\"bands\": [\"B8\", \"B4\", \"B3\"], \"min\": -0.09, \"max\": 0.09}\nMap.addLayer(centered_image, centered_image_vis, \"MeanCentering\")\n</pre> scaler = MeanCentering(image, region) centered_image = scaler.transform()  # Adjust visualization range around 0 to reflect centered values centered_image_vis = {\"bands\": [\"B8\", \"B4\", \"B3\"], \"min\": -0.09, \"max\": 0.09} Map.addLayer(centered_image, centered_image_vis, \"MeanCentering\") In\u00a0[\u00a0]: Copied! <pre>scaler = MinMaxScaler(image, region)\nscaled_image = scaler.transform()\n\nscaled_image_vis = {\"bands\": [\"B8\", \"B4\", \"B3\"], \"min\": 0, \"max\": 1}\nMap.addLayer(scaled_image, scaled_image_vis, \"MinMaxScaler\")\n</pre> scaler = MinMaxScaler(image, region) scaled_image = scaler.transform()  scaled_image_vis = {\"bands\": [\"B8\", \"B4\", \"B3\"], \"min\": 0, \"max\": 1} Map.addLayer(scaled_image, scaled_image_vis, \"MinMaxScaler\") In\u00a0[\u00a0]: Copied! <pre>scaler = StandardScaler(image, region)\nstandardized_image = scaler.transform()\n\n# You may want to visualize within a reasonable range\nstandardized_image_vis = {\"bands\": [\"B8\", \"B4\", \"B3\"], \"min\": -2, \"max\": 2}\nMap.addLayer(standardized_image, standardized_image_vis, \"StandardScaler\")\n</pre> scaler = StandardScaler(image, region) standardized_image = scaler.transform()  # You may want to visualize within a reasonable range standardized_image_vis = {\"bands\": [\"B8\", \"B4\", \"B3\"], \"min\": -2, \"max\": 2} Map.addLayer(standardized_image, standardized_image_vis, \"StandardScaler\") In\u00a0[\u00a0]: Copied! <pre>scaler = RobustScaler(image, region, lower=1, upper=99)\nscaled_image = scaler.transform()\n\nscaled_image_vis = {\"bands\": [\"B8\", \"B4\", \"B3\"], \"min\": 0, \"max\": 1}\nMap.addLayer(scaled_image, scaled_image_vis, \"RobustScaler\")\n</pre> scaler = RobustScaler(image, region, lower=1, upper=99) scaled_image = scaler.transform()  scaled_image_vis = {\"bands\": [\"B8\", \"B4\", \"B3\"], \"min\": 0, \"max\": 1} Map.addLayer(scaled_image, scaled_image_vis, \"RobustScaler\") <p>\ud83d\udca1 Tips for Efficient Processing</p> <ul> <li><p>Increase the <code>scale</code> parameter to reduce computation time. Calculating statistics (e.g., mean, percentiles) over high-resolution images (like Sentinel-2 at 10\u202fm) can be time-consuming or cause timeouts. Try <code>scale=100</code> or higher when possible.</p> </li> <li><p>Use simpler geometries. Avoid complex shapes like administrative boundaries or large regions. Instead, use simplified or bounding box geometries.</p> </li> <li><p>You can simplify any geometry by converting it to a bounding rectangle using:</p> <pre>simple_region = complex_region.bounds()\n</pre> <p>This can drastically speed up reduceRegion operations while still capturing spatial context.</p> </li> </ul>"},{"location":"examples/image_scaling/#import-libraries","title":"Import libraries\u00b6","text":""},{"location":"examples/image_scaling/#initialize-a-map-object","title":"Initialize a Map object\u00b6","text":"<p>Authenticate and initialize Earth Engine. If it doesn't work, specify a project name</p>"},{"location":"examples/image_scaling/#import-region-of-interest","title":"Import region of interest\u00b6","text":""},{"location":"examples/image_scaling/#load-sentinel-2-data-and-create-a-median-composite","title":"Load Sentinel-2 data and create a median composite\u00b6","text":""},{"location":"examples/image_scaling/#meancentering","title":"MeanCentering\u00b6","text":"<p>Subtracts the mean from each band to center values around zero:</p> <p>$$ X_\\text{centered} = X - \\mu $$</p> <p>Where:</p> <ul> <li>$X$: original pixel value</li> <li>$\\mu$: mean of the band computed over the given region</li> </ul>"},{"location":"examples/image_scaling/#minmaxscaler","title":"MinMaxScaler\u00b6","text":"<p>Normalizes each band using the min and max values over the region:</p> <p>$$ X_\\text{scaled} = \\frac{X - \\min}{\\max - \\min}, \\quad X_\\text{scaled} \\in [0, 1] $$</p> <p>Where:</p> <ul> <li>$\\min$, $\\max$: band-wise minimum and maximum values over the region.</li> </ul>"},{"location":"examples/image_scaling/#standardscaler","title":"StandardScaler\u00b6","text":"<p>Standardizes each band using z-score normalization (mean and standard deviation):</p> <p>$$ X_\\text{standardized} = \\frac{X - \\mu}{\\sigma} $$</p> <p>Where:</p> <ul> <li>$X$: original pixel value</li> <li>$\\mu$: mean of the band over the specified region</li> <li>$\\sigma$: standard deviation of the band over the specified region</li> </ul>"},{"location":"examples/image_scaling/#robustscaler","title":"RobustScaler\u00b6","text":"<p>Scales each band using robust percentiles (e.g., 1st and 99th) to reduce the influence of outliers:</p> <p>$$ X_\\text{scaled} = \\frac{X - P_\\text{lower}}{P_\\text{upper} - P_\\text{lower}}, \\quad X_\\text{scaled} \\in [0, 1] $$</p> <p>Where:</p> <ul> <li>$X$: original pixel value</li> <li>$P_{\\\\text{lower}}$: lower percentile value (e.g., 25th percentile)</li> <li>$P_{\\\\text{upper}}$: upper percentile value (e.g., 75th percentile)</li> </ul>"},{"location":"examples/land_surface_phenology/","title":"Land surface phenology","text":"<p>Uncomment the following line to install the latest version of geeagri if needed.</p> In\u00a0[\u00a0]: Copied! <pre># !pip install -U geeagri\n</pre> # !pip install -U geeagri In\u00a0[\u00a0]: Copied! <pre>import ee\nimport geemap\nfrom geeagri.preprocessing import Sentinel2CloudMask, RegularTimeseries\nfrom geeagri.phenology import SavitzkyGolayEE, Phenometrics\nfrom geeagri.extract import extract_timeseries_to_point\nimport matplotlib.cm as cm\nfrom matplotlib.colors import to_hex\n</pre> import ee import geemap from geeagri.preprocessing import Sentinel2CloudMask, RegularTimeseries from geeagri.phenology import SavitzkyGolayEE, Phenometrics from geeagri.extract import extract_timeseries_to_point import matplotlib.cm as cm from matplotlib.colors import to_hex In\u00a0[\u00a0]: Copied! <pre># ee.Authenticate()\n# ee.Initialize(project='your-project-id')\n\nMap = geemap.Map(basemap=\"SATELLITE\")\nMap\n</pre> # ee.Authenticate() # ee.Initialize(project='your-project-id')  Map = geemap.Map(basemap=\"SATELLITE\") Map In\u00a0[\u00a0]: Copied! <pre>bbox = [-93.79303, 43.009668, -93.753891, 43.038031]\nregion = ee.Geometry.BBox(*bbox)\nregion_style = {\"color\": \"red\", \"width\": 1}\nMap.addLayer(region, region_style, \"Region\")\nMap.centerObject(region, 14)\n</pre> bbox = [-93.79303, 43.009668, -93.753891, 43.038031] region = ee.Geometry.BBox(*bbox) region_style = {\"color\": \"red\", \"width\": 1} Map.addLayer(region, region_style, \"Region\") Map.centerObject(region, 14) In\u00a0[\u00a0]: Copied! <pre>croplandcover = (\n    ee.ImageCollection(\"USDA/NASS/CDL\")\n    .filterDate(\"2020-01-01\", \"2021-01-01\")\n    .first()\n    .clip(region)\n)\n\ncultivated = croplandcover.select(\"cultivated\").eq(2).selfMask()\ncroplandcover = croplandcover.select(\"cropland\")\nMap.addLayer(cultivated, {\"palette\": \"yellow\"}, \"Cultivated\")\nMap.addLayer(croplandcover, {}, \"Crop Landcover\")\n</pre> croplandcover = (     ee.ImageCollection(\"USDA/NASS/CDL\")     .filterDate(\"2020-01-01\", \"2021-01-01\")     .first()     .clip(region) )  cultivated = croplandcover.select(\"cultivated\").eq(2).selfMask() croplandcover = croplandcover.select(\"cropland\") Map.addLayer(cultivated, {\"palette\": \"yellow\"}, \"Cultivated\") Map.addLayer(croplandcover, {}, \"Crop Landcover\") In\u00a0[\u00a0]: Copied! <pre>s2_cloud_masker = Sentinel2CloudMask(\n    region=region,\n    start_date=\"2020-01-01\",\n    end_date=\"2021-01-01\",\n    cloud_filter=60,\n    cloud_prob_threshold=50,\n    nir_dark_threshold=0.15,\n    shadow_proj_dist=1,\n    buffer=50,\n)\n\ns2_cloud_masked = s2_cloud_masker.get_cloudfree_collection()\n</pre> s2_cloud_masker = Sentinel2CloudMask(     region=region,     start_date=\"2020-01-01\",     end_date=\"2021-01-01\",     cloud_filter=60,     cloud_prob_threshold=50,     nir_dark_threshold=0.15,     shadow_proj_dist=1,     buffer=50, )  s2_cloud_masked = s2_cloud_masker.get_cloudfree_collection() In\u00a0[\u00a0]: Copied! <pre>def calculateGCVI(image):\n    gcvi = image.expression(\n        \"(NIR/Green) - 1\", {\"NIR\": image.select(\"B8\"), \"Green\": image.select(\"B3\")}\n    ).copyProperties(image, [\"system:time_start\"])\n\n    gcvi = ee.Image(gcvi).rename(\"gcvi\").clip(region)\n\n    return gcvi\n\n\ngcvi_col = s2_cloud_masked.map(calculateGCVI)\n</pre> def calculateGCVI(image):     gcvi = image.expression(         \"(NIR/Green) - 1\", {\"NIR\": image.select(\"B8\"), \"Green\": image.select(\"B3\")}     ).copyProperties(image, [\"system:time_start\"])      gcvi = ee.Image(gcvi).rename(\"gcvi\").clip(region)      return gcvi   gcvi_col = s2_cloud_masked.map(calculateGCVI) In\u00a0[\u00a0]: Copied! <pre># Instantiate an object of 'RegularTimeseries'\nreg_timeseries = RegularTimeseries(gcvi_col, interval=5, window=45)\n\n# Get the regular timeseries\ngcvi_col_regular = reg_timeseries.get_regular_timeseries()\n</pre> # Instantiate an object of 'RegularTimeseries' reg_timeseries = RegularTimeseries(gcvi_col, interval=5, window=45)  # Get the regular timeseries gcvi_col_regular = reg_timeseries.get_regular_timeseries() In\u00a0[\u00a0]: Copied! <pre>sg = SavitzkyGolayEE(\n    image_collection=gcvi_col, window_length=11, polyorder=2, band_name=\"gcvi\"\n)\n\ncoeff = sg.coefficients()\n\nphenometrics = Phenometrics(coeff)\nmetrics = phenometrics.metrics()\n</pre> sg = SavitzkyGolayEE(     image_collection=gcvi_col, window_length=11, polyorder=2, band_name=\"gcvi\" )  coeff = sg.coefficients()  phenometrics = Phenometrics(coeff) metrics = phenometrics.metrics() In\u00a0[\u00a0]: Copied! <pre>cmap = cm.get_cmap(\"gist_rainbow\", 20)\ncmap\n</pre> cmap = cm.get_cmap(\"gist_rainbow\", 20) cmap In\u00a0[\u00a0]: Copied! <pre>cmap = cm.get_cmap(\"gist_rainbow\", 20)\ncmap = [to_hex(cmap(i)) for i in range(cmap.N)]\n\nvis = {\"min\": 100, \"max\": 330, \"palette\": cmap}\n\nMap.addLayer(metrics.select(\"SOS\"), vis, \"SOS\")\nMap.addLayer(metrics.select(\"POS\"), vis, \"POS\")\nMap.addLayer(metrics.select(\"EOS\"), vis, \"EOS\")\n</pre> cmap = cm.get_cmap(\"gist_rainbow\", 20) cmap = [to_hex(cmap(i)) for i in range(cmap.N)]  vis = {\"min\": 100, \"max\": 330, \"palette\": cmap}  Map.addLayer(metrics.select(\"SOS\"), vis, \"SOS\") Map.addLayer(metrics.select(\"POS\"), vis, \"POS\") Map.addLayer(metrics.select(\"EOS\"), vis, \"EOS\") In\u00a0[\u00a0]: Copied! <pre>modis = (\n    ee.ImageCollection(\"MODIS/061/MOD13Q1\")\n    .filterDate(\"2020-01-01\", \"2021-01-01\")\n    .map(lambda img: img.clip(region))\n)\n\nsg = SavitzkyGolayEE(\n    image_collection=modis, window_length=15, polyorder=2, band_name=\"NDVI\"\n)\n\ncoeff = sg.coefficients()\n\nphenometrics = Phenometrics(coeff)\nmetrics = phenometrics.metrics()\n\ncmap = cm.get_cmap(\"gist_rainbow\", 20)\ncmap = [to_hex(cmap(i)) for i in range(cmap.N)]\n\nvis = {\"min\": 100, \"max\": 330, \"palette\": cmap}\n\nMap.addLayer(metrics.select(\"SOS\"), vis, \"SOS (MODIS)\")\nMap.addLayer(metrics.select(\"POS\"), vis, \"POS (MODIS)\")\nMap.addLayer(metrics.select(\"EOS\"), vis, \"EOS (MODIS)\")\n</pre> modis = (     ee.ImageCollection(\"MODIS/061/MOD13Q1\")     .filterDate(\"2020-01-01\", \"2021-01-01\")     .map(lambda img: img.clip(region)) )  sg = SavitzkyGolayEE(     image_collection=modis, window_length=15, polyorder=2, band_name=\"NDVI\" )  coeff = sg.coefficients()  phenometrics = Phenometrics(coeff) metrics = phenometrics.metrics()  cmap = cm.get_cmap(\"gist_rainbow\", 20) cmap = [to_hex(cmap(i)) for i in range(cmap.N)]  vis = {\"min\": 100, \"max\": 330, \"palette\": cmap}  Map.addLayer(metrics.select(\"SOS\"), vis, \"SOS (MODIS)\") Map.addLayer(metrics.select(\"POS\"), vis, \"POS (MODIS)\") Map.addLayer(metrics.select(\"EOS\"), vis, \"EOS (MODIS)\") In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"examples/land_surface_phenology/#import-libraries","title":"Import Libraries\u00b6","text":""},{"location":"examples/land_surface_phenology/#initialize-a-map-object","title":"Initialize a Map object\u00b6","text":"<p>Authenticate and initialize Earth Engine. If it doesn't work, specify a project name</p>"},{"location":"examples/land_surface_phenology/#import-region-of-interest","title":"Import region of interest\u00b6","text":""},{"location":"examples/land_surface_phenology/#import-cropland-data-layer-cdl","title":"Import Cropland Data Layer (CDL)\u00b6","text":""},{"location":"examples/land_surface_phenology/#load-sentinel-2-image-collection-and-mask-clouds-and-shadows","title":"Load Sentinel-2 image collection and mask clouds and shadows\u00b6","text":""},{"location":"examples/land_surface_phenology/#calculate-green-chlorophyll-vegetation-index-gcvi","title":"Calculate Green Chlorophyll Vegetation Index (GCVI)\u00b6","text":""},{"location":"examples/land_surface_phenology/#smooth-the-timeseries-and-extract-the-phenometrics","title":"Smooth the timeseries and extract the phenometrics\u00b6","text":""},{"location":"examples/land_surface_phenology/#plot-the-land-surface-phenology","title":"Plot the land surface phenology\u00b6","text":""},{"location":"examples/land_surface_phenology/#apply-on-modis-data","title":"Apply on MODIS Data\u00b6","text":""},{"location":"examples/moving_window_smoothing/","title":"Moving window smoothing","text":"<p>Uncomment the following line to install the latest version of geeagri if needed.</p> In\u00a0[\u00a0]: Copied! <pre># !pip install -U geeagri\n</pre> # !pip install -U geeagri In\u00a0[\u00a0]: Copied! <pre>import ee\nimport geemap\nfrom geeagri.preprocessing import Sentinel2CloudMask, MovingWindowSmoothing\nfrom geeagri.extract import extract_timeseries_to_point\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom datetime import datetime\nfrom PIL import Image, ImageDraw, ImageFont, ImageSequence\n\nplt.rcParams[\"font.family\"] = \"DeJavu Serif\"\nplt.rcParams[\"font.serif\"] = \"Times New Roman\"\n</pre> import ee import geemap from geeagri.preprocessing import Sentinel2CloudMask, MovingWindowSmoothing from geeagri.extract import extract_timeseries_to_point  import matplotlib.pyplot as plt import seaborn as sns  from datetime import datetime from PIL import Image, ImageDraw, ImageFont, ImageSequence  plt.rcParams[\"font.family\"] = \"DeJavu Serif\" plt.rcParams[\"font.serif\"] = \"Times New Roman\" In\u00a0[\u00a0]: Copied! <pre># ee.Authenticate()\n# ee.Initialize(project='your-project-id')\n\nMap = geemap.Map(basemap=\"SATELLITE\")\nMap\n</pre> # ee.Authenticate() # ee.Initialize(project='your-project-id')  Map = geemap.Map(basemap=\"SATELLITE\") Map In\u00a0[\u00a0]: Copied! <pre>bbox = [-98.451233, 38.430732, -98.274765, 38.523996]\nregion = ee.Geometry.BBox(*bbox)\nregion_style = {\"color\": \"red\", \"width\": 1}\nMap.addLayer(region, region_style, \"Region\")\nMap.centerObject(region, 13)\n</pre> bbox = [-98.451233, 38.430732, -98.274765, 38.523996] region = ee.Geometry.BBox(*bbox) region_style = {\"color\": \"red\", \"width\": 1} Map.addLayer(region, region_style, \"Region\") Map.centerObject(region, 13) In\u00a0[\u00a0]: Copied! <pre>croplandcover = (\n    ee.ImageCollection(\"USDA/NASS/CDL\")\n    .filterDate(\"2020-01-01\", \"2021-01-01\")\n    .first()\n    .clip(region)\n)\n\ncultivated = croplandcover.select(\"cultivated\").eq(2).selfMask()\ncroplandcover = croplandcover.select(\"cropland\")\nMap.addLayer(cultivated, {}, \"Cultivated\")\nMap.addLayer(croplandcover, {}, \"Crop Landcover\")\n</pre> croplandcover = (     ee.ImageCollection(\"USDA/NASS/CDL\")     .filterDate(\"2020-01-01\", \"2021-01-01\")     .first()     .clip(region) )  cultivated = croplandcover.select(\"cultivated\").eq(2).selfMask() croplandcover = croplandcover.select(\"cropland\") Map.addLayer(cultivated, {}, \"Cultivated\") Map.addLayer(croplandcover, {}, \"Crop Landcover\") In\u00a0[\u00a0]: Copied! <pre>s2_cloud_masker = Sentinel2CloudMask(\n    region=region,\n    start_date=\"2020-01-01\",\n    end_date=\"2021-01-01\",\n    cloud_filter=60,  # maximum scene-level cloudiness allowed (%)\n    cloud_prob_threshold=50,  # cloud probability threshold (values above are considered clouds)\n    nir_dark_threshold=0.15,  # NIR reflectance threshold (values below considered potential shadows)\n    shadow_proj_dist=1,  # maximum distance (km) to search for shadows from clouds.\n    buffer=50,  # buffer distance (m) to dilate cloud/shadow masks.\n)\n\ns2_cloud_masked = s2_cloud_masker.get_cloudfree_collection()\n</pre> s2_cloud_masker = Sentinel2CloudMask(     region=region,     start_date=\"2020-01-01\",     end_date=\"2021-01-01\",     cloud_filter=60,  # maximum scene-level cloudiness allowed (%)     cloud_prob_threshold=50,  # cloud probability threshold (values above are considered clouds)     nir_dark_threshold=0.15,  # NIR reflectance threshold (values below considered potential shadows)     shadow_proj_dist=1,  # maximum distance (km) to search for shadows from clouds.     buffer=50,  # buffer distance (m) to dilate cloud/shadow masks. )  s2_cloud_masked = s2_cloud_masker.get_cloudfree_collection() In\u00a0[\u00a0]: Copied! <pre>def calculateNDVI(image):\n    ndvi = image.expression(\n        \"(NIR - Red) / (NIR + Red)\",\n        {\"NIR\": image.select(\"B8\"), \"Red\": image.select(\"B4\")},\n    ).copyProperties(image, [\"system:time_start\"])\n\n    ndvi = ee.Image(ndvi).rename(\"ndvi\").clip(region)\n\n    return ndvi\n\n\nndvi_col = s2_cloud_masked.map(calculateNDVI)\n</pre> def calculateNDVI(image):     ndvi = image.expression(         \"(NIR - Red) / (NIR + Red)\",         {\"NIR\": image.select(\"B8\"), \"Red\": image.select(\"B4\")},     ).copyProperties(image, [\"system:time_start\"])      ndvi = ee.Image(ndvi).rename(\"ndvi\").clip(region)      return ndvi   ndvi_col = s2_cloud_masked.map(calculateNDVI) In\u00a0[\u00a0]: Copied! <pre># Initialize a 'MovingWindowSmoothing' object\nsmoother = MovingWindowSmoothing(\n    image_collection=ndvi_col,  # ee.ImageCollection of NDVI\n    window=15,  # Temporal window in days\n    reducer=\"MEDIAN\",  # Reducer for smoothing (\"MEAN\" or \"MEDIAN\")\n)\n\n# Get the smoothed collectiom\nndvi_smoothed = smoother.get_smoothed_collection()\n</pre> # Initialize a 'MovingWindowSmoothing' object smoother = MovingWindowSmoothing(     image_collection=ndvi_col,  # ee.ImageCollection of NDVI     window=15,  # Temporal window in days     reducer=\"MEDIAN\",  # Reducer for smoothing (\"MEAN\" or \"MEDIAN\") )  # Get the smoothed collectiom ndvi_smoothed = smoother.get_smoothed_collection() In\u00a0[\u00a0]: Copied! <pre># Function to add timestamp of gif frames\ndef add_dates_to_gif(\n    input_gif: str,\n    output_gif: str,\n    dates: list[str],\n    font_path: str = \"DejaVuSans-Bold.ttf\",\n    font_size: int = 20,\n    position: tuple = (20, 20),\n    color: str = \"red\",\n):\n    \"\"\"\n    Overlay a list of dates onto each frame of an animated GIF.\n\n    Args:\n        input_gif (str): Path to the input GIF file.\n        output_gif (str): Path where the output GIF will be saved.\n        dates (list[str]): List of date strings (one per frame).\n        font_path (str, optional): Path to a .ttf font file. Defaults to \"DejaVuSans-Bold.ttf\".\n        font_size (int, optional): Font size. Defaults to 40.\n        position (tuple, optional): (x, y) position of the text. Defaults to (20, 20).\n        color (str, optional): Text color. Defaults to \"black\".\n    \"\"\"\n    font = ImageFont.truetype(font_path, font_size)\n\n    with Image.open(input_gif) as im:\n        frames = []\n\n        for i, frame in enumerate(ImageSequence.Iterator(im)):\n            frame = frame.convert(\"RGB\")\n            draw = ImageDraw.Draw(frame)\n\n            if i &lt; len(dates):\n                draw.text(position, dates[i], fill=color, font=font)\n\n            frames.append(frame)\n\n        # Save the annotated frames as a new GIF\n        frames[0].save(\n            output_gif,\n            save_all=True,\n            append_images=frames[1:],\n            duration=im.info.get(\"duration\", 200),  # default 200ms if not found\n            loop=0,\n        )\n</pre> # Function to add timestamp of gif frames def add_dates_to_gif(     input_gif: str,     output_gif: str,     dates: list[str],     font_path: str = \"DejaVuSans-Bold.ttf\",     font_size: int = 20,     position: tuple = (20, 20),     color: str = \"red\", ):     \"\"\"     Overlay a list of dates onto each frame of an animated GIF.      Args:         input_gif (str): Path to the input GIF file.         output_gif (str): Path where the output GIF will be saved.         dates (list[str]): List of date strings (one per frame).         font_path (str, optional): Path to a .ttf font file. Defaults to \"DejaVuSans-Bold.ttf\".         font_size (int, optional): Font size. Defaults to 40.         position (tuple, optional): (x, y) position of the text. Defaults to (20, 20).         color (str, optional): Text color. Defaults to \"black\".     \"\"\"     font = ImageFont.truetype(font_path, font_size)      with Image.open(input_gif) as im:         frames = []          for i, frame in enumerate(ImageSequence.Iterator(im)):             frame = frame.convert(\"RGB\")             draw = ImageDraw.Draw(frame)              if i &lt; len(dates):                 draw.text(position, dates[i], fill=color, font=font)              frames.append(frame)          # Save the annotated frames as a new GIF         frames[0].save(             output_gif,             save_all=True,             append_images=frames[1:],             duration=im.info.get(\"duration\", 200),  # default 200ms if not found             loop=0,         ) In\u00a0[\u00a0]: Copied! <pre># Get the image dates\ndates = ndvi_col.aggregate_array(\"system:time_start\").getInfo()\ndates_str = [datetime.fromtimestamp(d / 1000).strftime(\"%d %b %Y\") for d in dates]\n\nvideo_args = {\n    \"dimensions\": 1000,\n    \"region\": region,\n    \"framesPerSecond\": 2,\n    \"crs\": \"EPSG:4326\",\n    \"min\": -1,\n    \"max\": 1,\n    \"palette\": [\n        \"#a50026\",\n        \"#d73027\",\n        \"#f46d43\",\n        \"#fdae61\",\n        \"#fee08b\",\n        \"#d9ef8b\",\n        \"#a6d96a\",\n        \"#66bd63\",\n        \"#1a9850\",\n        \"#006837\",\n    ],\n}\n\nsaved_ndvi_gif = \"ndvi.gif\"\ngeemap.download_ee_video(ndvi_col, video_args, saved_ndvi_gif)\n\n# add timestamps and plot the timelapse of raw NDVI\nadd_dates_to_gif(saved_ndvi_gif, saved_ndvi_gif, dates_str)\ngeemap.show_image(saved_ndvi_gif)\n</pre> # Get the image dates dates = ndvi_col.aggregate_array(\"system:time_start\").getInfo() dates_str = [datetime.fromtimestamp(d / 1000).strftime(\"%d %b %Y\") for d in dates]  video_args = {     \"dimensions\": 1000,     \"region\": region,     \"framesPerSecond\": 2,     \"crs\": \"EPSG:4326\",     \"min\": -1,     \"max\": 1,     \"palette\": [         \"#a50026\",         \"#d73027\",         \"#f46d43\",         \"#fdae61\",         \"#fee08b\",         \"#d9ef8b\",         \"#a6d96a\",         \"#66bd63\",         \"#1a9850\",         \"#006837\",     ], }  saved_ndvi_gif = \"ndvi.gif\" geemap.download_ee_video(ndvi_col, video_args, saved_ndvi_gif)  # add timestamps and plot the timelapse of raw NDVI add_dates_to_gif(saved_ndvi_gif, saved_ndvi_gif, dates_str) geemap.show_image(saved_ndvi_gif) In\u00a0[\u00a0]: Copied! <pre>saved_ndvi_smoothed_gif = \"ndvi_smoothed.gif\"\ngeemap.download_ee_video(ndvi_smoothed, video_args, saved_ndvi_smoothed_gif)\n\n# add timestamps and plot the timelapse of smoothed NDVI\nadd_dates_to_gif(saved_ndvi_smoothed_gif, saved_ndvi_smoothed_gif, dates_str)\ngeemap.show_image(saved_ndvi_smoothed_gif)\n</pre> saved_ndvi_smoothed_gif = \"ndvi_smoothed.gif\" geemap.download_ee_video(ndvi_smoothed, video_args, saved_ndvi_smoothed_gif)  # add timestamps and plot the timelapse of smoothed NDVI add_dates_to_gif(saved_ndvi_smoothed_gif, saved_ndvi_smoothed_gif, dates_str) geemap.show_image(saved_ndvi_smoothed_gif) In\u00a0[\u00a0]: Copied! <pre>wheat_loc = (-98.39630126953126, 38.46931531751283)\nsoybean_loc = (-98.34480285644533, 38.50022087618732)\ncorn_loc = (-98.31716537475587, 38.496190467979176)\n\nwheat_ndvi = extract_timeseries_to_point(\n    lat=wheat_loc[1], lon=wheat_loc[0], image_collection=ndvi_col, scale=10\n)\nsoybean_ndvi = extract_timeseries_to_point(\n    lat=soybean_loc[1], lon=soybean_loc[0], image_collection=ndvi_col, scale=10\n)\ncorn_ndvi = extract_timeseries_to_point(\n    lat=corn_loc[1], lon=corn_loc[0], image_collection=ndvi_col, scale=10\n)\nwheat_ndvi_smoothed = extract_timeseries_to_point(\n    lat=wheat_loc[1], lon=wheat_loc[0], image_collection=ndvi_smoothed, scale=10\n)\nsoybean_ndvi_smoothed = extract_timeseries_to_point(\n    lat=soybean_loc[1], lon=soybean_loc[0], image_collection=ndvi_smoothed, scale=10\n)\ncorn_ndvi_smoothed = extract_timeseries_to_point(\n    lat=corn_loc[1], lon=corn_loc[0], image_collection=ndvi_smoothed, scale=10\n)\n</pre> wheat_loc = (-98.39630126953126, 38.46931531751283) soybean_loc = (-98.34480285644533, 38.50022087618732) corn_loc = (-98.31716537475587, 38.496190467979176)  wheat_ndvi = extract_timeseries_to_point(     lat=wheat_loc[1], lon=wheat_loc[0], image_collection=ndvi_col, scale=10 ) soybean_ndvi = extract_timeseries_to_point(     lat=soybean_loc[1], lon=soybean_loc[0], image_collection=ndvi_col, scale=10 ) corn_ndvi = extract_timeseries_to_point(     lat=corn_loc[1], lon=corn_loc[0], image_collection=ndvi_col, scale=10 ) wheat_ndvi_smoothed = extract_timeseries_to_point(     lat=wheat_loc[1], lon=wheat_loc[0], image_collection=ndvi_smoothed, scale=10 ) soybean_ndvi_smoothed = extract_timeseries_to_point(     lat=soybean_loc[1], lon=soybean_loc[0], image_collection=ndvi_smoothed, scale=10 ) corn_ndvi_smoothed = extract_timeseries_to_point(     lat=corn_loc[1], lon=corn_loc[0], image_collection=ndvi_smoothed, scale=10 ) In\u00a0[\u00a0]: Copied! <pre>plt.figure(figsize=(12, 4))\n\nsns.lineplot(\n    data=wheat_ndvi,\n    x=\"time\",\n    y=\"ndvi\",\n    label=\"Wheat NDVI\",\n    alpha=0.5,\n    c=\"#a87000\",\n)\nsns.lineplot(\n    data=wheat_ndvi_smoothed,\n    x=\"time\",\n    y=\"ndvi_median\",\n    label=\"Wheat NDVI Smoothed\",\n    c=\"#a87000\",\n    marker=\"o\",\n    markersize=5,\n)\n\nsns.lineplot(\n    data=soybean_ndvi,\n    x=\"time\",\n    y=\"ndvi\",\n    label=\"Soybean NDVI\",\n    alpha=0.5,\n    c=\"#267300\",\n)\nsns.lineplot(\n    data=soybean_ndvi_smoothed,\n    x=\"time\",\n    y=\"ndvi_median\",\n    label=\"Soybean NDVI Smoothed\",\n    c=\"#267300\",\n    marker=\"o\",\n    markersize=5,\n)\n\nsns.lineplot(\n    data=corn_ndvi, x=\"time\", y=\"ndvi\", label=\"Corn NDVI\", alpha=0.5, c=\"#ffd400\"\n)\nsns.lineplot(\n    data=corn_ndvi_smoothed,\n    x=\"time\",\n    y=\"ndvi_median\",\n    label=\"Corn NDVI Smoothed\",\n    c=\"#ffd400\",\n    marker=\"o\",\n    markersize=5,\n)\n\nplt.title(\"Moving Window Smoothing of NDVI Time Series\")\nplt.ylabel(\"NDVI\")\nplt.show()\n</pre> plt.figure(figsize=(12, 4))  sns.lineplot(     data=wheat_ndvi,     x=\"time\",     y=\"ndvi\",     label=\"Wheat NDVI\",     alpha=0.5,     c=\"#a87000\", ) sns.lineplot(     data=wheat_ndvi_smoothed,     x=\"time\",     y=\"ndvi_median\",     label=\"Wheat NDVI Smoothed\",     c=\"#a87000\",     marker=\"o\",     markersize=5, )  sns.lineplot(     data=soybean_ndvi,     x=\"time\",     y=\"ndvi\",     label=\"Soybean NDVI\",     alpha=0.5,     c=\"#267300\", ) sns.lineplot(     data=soybean_ndvi_smoothed,     x=\"time\",     y=\"ndvi_median\",     label=\"Soybean NDVI Smoothed\",     c=\"#267300\",     marker=\"o\",     markersize=5, )  sns.lineplot(     data=corn_ndvi, x=\"time\", y=\"ndvi\", label=\"Corn NDVI\", alpha=0.5, c=\"#ffd400\" ) sns.lineplot(     data=corn_ndvi_smoothed,     x=\"time\",     y=\"ndvi_median\",     label=\"Corn NDVI Smoothed\",     c=\"#ffd400\",     marker=\"o\",     markersize=5, )  plt.title(\"Moving Window Smoothing of NDVI Time Series\") plt.ylabel(\"NDVI\") plt.show()"},{"location":"examples/moving_window_smoothing/#initialize-a-map-object","title":"Initialize a Map object\u00b6","text":"<p>Authenticate and initialize Earth Engine. If it doesn't work, specify a project name</p>"},{"location":"examples/moving_window_smoothing/#import-region-of-interest","title":"Import region of interest\u00b6","text":""},{"location":"examples/moving_window_smoothing/#import-cropland-data-layer-cdl","title":"Import Cropland Data Layer (CDL)\u00b6","text":""},{"location":"examples/moving_window_smoothing/#load-sentinel-2-image-collection-and-mask-clouds-and-shadows","title":"Load Sentinel-2 image collection and mask clouds and shadows\u00b6","text":""},{"location":"examples/moving_window_smoothing/#calculate-normalized-difference-vegetation-index-ndvi","title":"Calculate Normalized Difference Vegetation Index (NDVI)\u00b6","text":""},{"location":"examples/moving_window_smoothing/#apply-moving-window-smoothing","title":"Apply moving window smoothing\u00b6","text":""},{"location":"examples/moving_window_smoothing/#extract-timelapse-for-raw-and-smoothed-ndvi-image-collection","title":"Extract timelapse for raw and smoothed NDVI image collection\u00b6","text":""},{"location":"examples/moving_window_smoothing/#plot-the-raw-and-smoothed-ndvi-for-three-crop-samples","title":"Plot the raw and smoothed NDVI for three crop samples\u00b6","text":""},{"location":"examples/pca/","title":"Pca","text":"<p>Uncomment the following line to install the latest version of geeagri if needed.</p> In\u00a0[\u00a0]: Copied! <pre># !pip install -U geeagri\n</pre> # !pip install -U geeagri In\u00a0[\u00a0]: Copied! <pre>import ee\nimport geemap\nfrom geeagri.analysis import PCA\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.rcParams[\"font.family\"] = \"DeJavu Serif\"\nplt.rcParams[\"font.serif\"] = \"Times New Roman\"\n</pre> import ee import geemap from geeagri.analysis import PCA import matplotlib.pyplot as plt import seaborn as sns  plt.rcParams[\"font.family\"] = \"DeJavu Serif\" plt.rcParams[\"font.serif\"] = \"Times New Roman\" In\u00a0[\u00a0]: Copied! <pre># ee.Authenticate()\n# ee.Initialize(project='your-project-id')\n\nMap = geemap.Map(basemap=\"SATELLITE\")\nMap\n</pre> # ee.Authenticate() # ee.Initialize(project='your-project-id')  Map = geemap.Map(basemap=\"SATELLITE\") Map In\u00a0[\u00a0]: Copied! <pre>bbox = [-120.398369, 37.006574, -120.208168, 37.101924]\nregion = ee.Geometry.BBox(*bbox)\nregion_style = {\"color\": \"red\", \"width\": 1}\nMap.addLayer(region, region_style, \"Region\")\nMap.centerObject(region, 12)\n</pre> bbox = [-120.398369, 37.006574, -120.208168, 37.101924] region = ee.Geometry.BBox(*bbox) region_style = {\"color\": \"red\", \"width\": 1} Map.addLayer(region, region_style, \"Region\") Map.centerObject(region, 12) In\u00a0[\u00a0]: Copied! <pre>image = (\n    ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\")\n    .filterBounds(region)\n    .filterDate(\"2024-01-01\", \"2025-01-01\")\n    .filterMetadata(\"CLOUDY_PIXEL_PERCENTAGE\", \"less_than\", 10)\n    .select([\"B.*\"])\n    .median()\n    .multiply(0.0001)\n    .clip(region)\n)\n\nimage_vis = {\"bands\": [\"B8\", \"B4\", \"B3\"], \"min\": 0, \"max\": 0.3}\n\nMap.addLayer(image, image_vis, \"Sentinel 2 FCC\")\n</pre> image = (     ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\")     .filterBounds(region)     .filterDate(\"2024-01-01\", \"2025-01-01\")     .filterMetadata(\"CLOUDY_PIXEL_PERCENTAGE\", \"less_than\", 10)     .select([\"B.*\"])     .median()     .multiply(0.0001)     .clip(region) )  image_vis = {\"bands\": [\"B8\", \"B4\", \"B3\"], \"min\": 0, \"max\": 0.3}  Map.addLayer(image, image_vis, \"Sentinel 2 FCC\") In\u00a0[\u00a0]: Copied! <pre>pca = PCA(image, region=region, scale=100)\npcs = pca.get_principal_components()\n\n# Define visualization parameters\npca_vis = {\n    \"bands\": [\"pc1\", \"pc2\", \"pc3\"],\n    \"min\": -2,\n    \"max\": 2,\n}\n\n# Add PCA layer\nMap.addLayer(pcs, pca_vis, \"PCA RGB Composite\")\n</pre> pca = PCA(image, region=region, scale=100) pcs = pca.get_principal_components()  # Define visualization parameters pca_vis = {     \"bands\": [\"pc1\", \"pc2\", \"pc3\"],     \"min\": -2,     \"max\": 2, }  # Add PCA layer Map.addLayer(pcs, pca_vis, \"PCA RGB Composite\") In\u00a0[\u00a0]: Copied! <pre># Plot the explained variance by principle components\nexplained_variance = pca.get_explained_variance()\n\nsns.barplot(\n    data=explained_variance,\n    x=\"pc\",\n    y=\"variance_explained\",\n    hue=\"variance_explained\",\n    palette=\"Greens\",\n    edgecolor=\"k\",\n)\nplt.show()\n</pre> # Plot the explained variance by principle components explained_variance = pca.get_explained_variance()  sns.barplot(     data=explained_variance,     x=\"pc\",     y=\"variance_explained\",     hue=\"variance_explained\",     palette=\"Greens\",     edgecolor=\"k\", ) plt.show()"},{"location":"examples/pca/#import-libraries","title":"Import libraries\u00b6","text":""},{"location":"examples/pca/#initialize-a-map-object","title":"Initialize a Map object\u00b6","text":"<p>Authenticate and initialize Earth Engine. If it doesn't work, specify a project name</p>"},{"location":"examples/pca/#import-region-of-interest","title":"Import region of interest\u00b6","text":""},{"location":"examples/pca/#load-sentinel-2-data-and-create-a-median-composite","title":"Load Sentinel-2 data and create a median composite\u00b6","text":""},{"location":"examples/pca/#principal-component-analysis","title":"Principal Component Analysis\u00b6","text":""},{"location":"examples/pca/#plot-the-explained-variance-by-principal-components","title":"Plot the explained variance by principal components\u00b6","text":""},{"location":"examples/regular_timeseries/","title":"Regular timeseries","text":"<p>Uncomment the following line to install the latest version of geeagri if needed.</p> In\u00a0[\u00a0]: Copied! <pre># !pip install -U geeagri\n</pre> # !pip install -U geeagri In\u00a0[\u00a0]: Copied! <pre>import ee\nimport geemap\nfrom geeagri.preprocessing import Sentinel2CloudMask, RegularTimeseries\nfrom geeagri.extract import extract_timeseries_to_point\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom datetime import datetime\nfrom PIL import Image, ImageDraw, ImageFont, ImageSequence\n\nplt.rcParams[\"font.family\"] = \"DeJavu Serif\"\nplt.rcParams[\"font.serif\"] = \"Times New Roman\"\n</pre> import ee import geemap from geeagri.preprocessing import Sentinel2CloudMask, RegularTimeseries from geeagri.extract import extract_timeseries_to_point  import matplotlib.pyplot as plt import seaborn as sns  from datetime import datetime from PIL import Image, ImageDraw, ImageFont, ImageSequence  plt.rcParams[\"font.family\"] = \"DeJavu Serif\" plt.rcParams[\"font.serif\"] = \"Times New Roman\" In\u00a0[\u00a0]: Copied! <pre># ee.Authenticate()\n# ee.Initialize(project='your-project-id')\n\nMap = geemap.Map(basemap=\"SATELLITE\")\nMap\n</pre> # ee.Authenticate() # ee.Initialize(project='your-project-id')  Map = geemap.Map(basemap=\"SATELLITE\") Map In\u00a0[\u00a0]: Copied! <pre>bbox = [-98.451233, 38.430732, -98.274765, 38.523996]\nregion = ee.Geometry.BBox(*bbox)\nregion_style = {\"color\": \"red\", \"width\": 1}\nMap.addLayer(region, region_style, \"Region\")\nMap.centerObject(region, 13)\n</pre> bbox = [-98.451233, 38.430732, -98.274765, 38.523996] region = ee.Geometry.BBox(*bbox) region_style = {\"color\": \"red\", \"width\": 1} Map.addLayer(region, region_style, \"Region\") Map.centerObject(region, 13) In\u00a0[\u00a0]: Copied! <pre>croplandcover = (\n    ee.ImageCollection(\"USDA/NASS/CDL\")\n    .filterDate(\"2020-01-01\", \"2021-01-01\")\n    .first()\n    .clip(region)\n)\n\ncultivated = croplandcover.select(\"cultivated\").eq(2).selfMask()\ncroplandcover = croplandcover.select(\"cropland\")\nMap.addLayer(cultivated, {}, \"Cultivated\")\nMap.addLayer(croplandcover, {}, \"Crop Landcover\")\n</pre> croplandcover = (     ee.ImageCollection(\"USDA/NASS/CDL\")     .filterDate(\"2020-01-01\", \"2021-01-01\")     .first()     .clip(region) )  cultivated = croplandcover.select(\"cultivated\").eq(2).selfMask() croplandcover = croplandcover.select(\"cropland\") Map.addLayer(cultivated, {}, \"Cultivated\") Map.addLayer(croplandcover, {}, \"Crop Landcover\") In\u00a0[\u00a0]: Copied! <pre>s2_cloud_masker = Sentinel2CloudMask(\n    region=region,\n    start_date=\"2020-01-01\",\n    end_date=\"2021-01-01\",\n    cloud_filter=60,  # maximum scene-level cloudiness allowed (%)\n    cloud_prob_threshold=50,  # cloud probability threshold (values above are considered clouds)\n    nir_dark_threshold=0.15,  # NIR reflectance threshold (values below considered potential shadows)\n    shadow_proj_dist=1,  # maximum distance (km) to search for shadows from clouds.\n    buffer=50,  # buffer distance (m) to dilate cloud/shadow masks.\n)\n\ns2_cloud_masked = s2_cloud_masker.get_cloudfree_collection()\n</pre> s2_cloud_masker = Sentinel2CloudMask(     region=region,     start_date=\"2020-01-01\",     end_date=\"2021-01-01\",     cloud_filter=60,  # maximum scene-level cloudiness allowed (%)     cloud_prob_threshold=50,  # cloud probability threshold (values above are considered clouds)     nir_dark_threshold=0.15,  # NIR reflectance threshold (values below considered potential shadows)     shadow_proj_dist=1,  # maximum distance (km) to search for shadows from clouds.     buffer=50,  # buffer distance (m) to dilate cloud/shadow masks. )  s2_cloud_masked = s2_cloud_masker.get_cloudfree_collection() In\u00a0[\u00a0]: Copied! <pre>def calculateNDVI(image):\n    ndvi = image.expression(\n        \"(NIR - Red) / (NIR + Red)\",\n        {\"NIR\": image.select(\"B8\"), \"Red\": image.select(\"B4\")},\n    ).copyProperties(image, [\"system:time_start\"])\n\n    ndvi = ee.Image(ndvi).rename(\"ndvi\").clip(region)\n\n    return ndvi\n\n\nndvi_col = s2_cloud_masked.map(calculateNDVI)\n</pre> def calculateNDVI(image):     ndvi = image.expression(         \"(NIR - Red) / (NIR + Red)\",         {\"NIR\": image.select(\"B8\"), \"Red\": image.select(\"B4\")},     ).copyProperties(image, [\"system:time_start\"])      ndvi = ee.Image(ndvi).rename(\"ndvi\").clip(region)      return ndvi   ndvi_col = s2_cloud_masked.map(calculateNDVI) In\u00a0[\u00a0]: Copied! <pre># Instantiate a 'RegularTimeseries' object\nreg_timeseries = RegularTimeseries(\n    image_collection=ndvi_col,  # ee.ImageCollection of NDVI\n    interval=5,  # Interval (in days) between consecutive target dates\n    window=45,  # Temporal window in days\n)\n\n# Get the regular timeseries\nndvi_regular = reg_timeseries.get_regular_timeseries()\n</pre> # Instantiate a 'RegularTimeseries' object reg_timeseries = RegularTimeseries(     image_collection=ndvi_col,  # ee.ImageCollection of NDVI     interval=5,  # Interval (in days) between consecutive target dates     window=45,  # Temporal window in days )  # Get the regular timeseries ndvi_regular = reg_timeseries.get_regular_timeseries() In\u00a0[\u00a0]: Copied! <pre># Function to add timestamp of gif frames\ndef add_dates_to_gif(\n    input_gif: str,\n    output_gif: str,\n    dates: list[str],\n    font_path: str = \"DejaVuSans-Bold.ttf\",\n    font_size: int = 20,\n    position: tuple = (20, 20),\n    color: str = \"red\",\n):\n    \"\"\"\n    Overlay a list of dates onto each frame of an animated GIF.\n\n    Args:\n        input_gif (str): Path to the input GIF file.\n        output_gif (str): Path where the output GIF will be saved.\n        dates (list[str]): List of date strings (one per frame).\n        font_path (str, optional): Path to a .ttf font file. Defaults to \"DejaVuSans-Bold.ttf\".\n        font_size (int, optional): Font size. Defaults to 40.\n        position (tuple, optional): (x, y) position of the text. Defaults to (20, 20).\n        color (str, optional): Text color. Defaults to \"black\".\n    \"\"\"\n    font = ImageFont.truetype(font_path, font_size)\n\n    with Image.open(input_gif) as im:\n        frames = []\n\n        for i, frame in enumerate(ImageSequence.Iterator(im)):\n            frame = frame.convert(\"RGB\")\n            draw = ImageDraw.Draw(frame)\n\n            if i &lt; len(dates):\n                draw.text(position, dates[i], fill=color, font=font)\n\n            frames.append(frame)\n\n        # Save the annotated frames as a new GIF\n        frames[0].save(\n            output_gif,\n            save_all=True,\n            append_images=frames[1:],\n            duration=im.info.get(\"duration\", 200),  # default 200ms if not found\n            loop=0,\n        )\n</pre> # Function to add timestamp of gif frames def add_dates_to_gif(     input_gif: str,     output_gif: str,     dates: list[str],     font_path: str = \"DejaVuSans-Bold.ttf\",     font_size: int = 20,     position: tuple = (20, 20),     color: str = \"red\", ):     \"\"\"     Overlay a list of dates onto each frame of an animated GIF.      Args:         input_gif (str): Path to the input GIF file.         output_gif (str): Path where the output GIF will be saved.         dates (list[str]): List of date strings (one per frame).         font_path (str, optional): Path to a .ttf font file. Defaults to \"DejaVuSans-Bold.ttf\".         font_size (int, optional): Font size. Defaults to 40.         position (tuple, optional): (x, y) position of the text. Defaults to (20, 20).         color (str, optional): Text color. Defaults to \"black\".     \"\"\"     font = ImageFont.truetype(font_path, font_size)      with Image.open(input_gif) as im:         frames = []          for i, frame in enumerate(ImageSequence.Iterator(im)):             frame = frame.convert(\"RGB\")             draw = ImageDraw.Draw(frame)              if i &lt; len(dates):                 draw.text(position, dates[i], fill=color, font=font)              frames.append(frame)          # Save the annotated frames as a new GIF         frames[0].save(             output_gif,             save_all=True,             append_images=frames[1:],             duration=im.info.get(\"duration\", 200),  # default 200ms if not found             loop=0,         ) In\u00a0[\u00a0]: Copied! <pre># Get the image dates\ndates = ndvi_col.aggregate_array(\"system:time_start\").getInfo()\ndates_str = [datetime.fromtimestamp(d / 1000).strftime(\"%d %b %Y\") for d in dates]\n\nvideo_args = {\n    \"dimensions\": 800,\n    \"region\": region,\n    \"framesPerSecond\": 2,\n    \"crs\": \"EPSG:4326\",\n    \"min\": -1,\n    \"max\": 1,\n    \"palette\": [\n        \"#a50026\",\n        \"#d73027\",\n        \"#f46d43\",\n        \"#fdae61\",\n        \"#fee08b\",\n        \"#d9ef8b\",\n        \"#a6d96a\",\n        \"#66bd63\",\n        \"#1a9850\",\n        \"#006837\",\n    ],\n}\n\nsaved_ndvi_gif = \"ndvi.gif\"\ngeemap.download_ee_video(ndvi_col, video_args, saved_ndvi_gif)\n\n# add timestamps and plot the timelapse of raw NDVI\nadd_dates_to_gif(saved_ndvi_gif, saved_ndvi_gif, dates_str)\ngeemap.show_image(saved_ndvi_gif)\n</pre> # Get the image dates dates = ndvi_col.aggregate_array(\"system:time_start\").getInfo() dates_str = [datetime.fromtimestamp(d / 1000).strftime(\"%d %b %Y\") for d in dates]  video_args = {     \"dimensions\": 800,     \"region\": region,     \"framesPerSecond\": 2,     \"crs\": \"EPSG:4326\",     \"min\": -1,     \"max\": 1,     \"palette\": [         \"#a50026\",         \"#d73027\",         \"#f46d43\",         \"#fdae61\",         \"#fee08b\",         \"#d9ef8b\",         \"#a6d96a\",         \"#66bd63\",         \"#1a9850\",         \"#006837\",     ], }  saved_ndvi_gif = \"ndvi.gif\" geemap.download_ee_video(ndvi_col, video_args, saved_ndvi_gif)  # add timestamps and plot the timelapse of raw NDVI add_dates_to_gif(saved_ndvi_gif, saved_ndvi_gif, dates_str) geemap.show_image(saved_ndvi_gif) In\u00a0[\u00a0]: Copied! <pre># Get the image dates of the regular timeseries\ndates = ndvi_regular.aggregate_array(\"system:time_start\").getInfo()\ndates_str = [datetime.fromtimestamp(d / 1000).strftime(\"%d %b %Y\") for d in dates]\n\nsaved_ndvi_regular_gif = \"ndvi_regular.gif\"\ngeemap.download_ee_video(ndvi_regular, video_args, saved_ndvi_regular_gif)\n\n# add timestamps and plot the timelapse of interpolated NDVI\nadd_dates_to_gif(saved_ndvi_regular_gif, saved_ndvi_regular_gif, dates_str)\ngeemap.show_image(saved_ndvi_regular_gif)\n</pre> # Get the image dates of the regular timeseries dates = ndvi_regular.aggregate_array(\"system:time_start\").getInfo() dates_str = [datetime.fromtimestamp(d / 1000).strftime(\"%d %b %Y\") for d in dates]  saved_ndvi_regular_gif = \"ndvi_regular.gif\" geemap.download_ee_video(ndvi_regular, video_args, saved_ndvi_regular_gif)  # add timestamps and plot the timelapse of interpolated NDVI add_dates_to_gif(saved_ndvi_regular_gif, saved_ndvi_regular_gif, dates_str) geemap.show_image(saved_ndvi_regular_gif) In\u00a0[\u00a0]: Copied! <pre>wheat_loc = (-98.39630126953126, 38.46931531751283)\nsoybean_loc = (-98.34480285644533, 38.50008653288019)\ncorn_loc = (-98.3169937133789, 38.49645916887533)\n\nwheat_ndvi = extract_timeseries_to_point(\n    lat=wheat_loc[1], lon=wheat_loc[0], image_collection=ndvi_col, scale=10\n)\nsoybean_ndvi = extract_timeseries_to_point(\n    lat=soybean_loc[1], lon=soybean_loc[0], image_collection=ndvi_col, scale=10\n)\ncorn_ndvi = extract_timeseries_to_point(\n    lat=corn_loc[1], lon=corn_loc[0], image_collection=ndvi_col, scale=10\n)\nwheat_ndvi_regular = extract_timeseries_to_point(\n    lat=wheat_loc[1], lon=wheat_loc[0], image_collection=ndvi_regular, scale=10\n)\nsoybean_ndvi_regular = extract_timeseries_to_point(\n    lat=soybean_loc[1], lon=soybean_loc[0], image_collection=ndvi_regular, scale=10\n)\ncorn_ndvi_regular = extract_timeseries_to_point(\n    lat=corn_loc[1], lon=corn_loc[0], image_collection=ndvi_regular, scale=10\n)\n</pre> wheat_loc = (-98.39630126953126, 38.46931531751283) soybean_loc = (-98.34480285644533, 38.50008653288019) corn_loc = (-98.3169937133789, 38.49645916887533)  wheat_ndvi = extract_timeseries_to_point(     lat=wheat_loc[1], lon=wheat_loc[0], image_collection=ndvi_col, scale=10 ) soybean_ndvi = extract_timeseries_to_point(     lat=soybean_loc[1], lon=soybean_loc[0], image_collection=ndvi_col, scale=10 ) corn_ndvi = extract_timeseries_to_point(     lat=corn_loc[1], lon=corn_loc[0], image_collection=ndvi_col, scale=10 ) wheat_ndvi_regular = extract_timeseries_to_point(     lat=wheat_loc[1], lon=wheat_loc[0], image_collection=ndvi_regular, scale=10 ) soybean_ndvi_regular = extract_timeseries_to_point(     lat=soybean_loc[1], lon=soybean_loc[0], image_collection=ndvi_regular, scale=10 ) corn_ndvi_regular = extract_timeseries_to_point(     lat=corn_loc[1], lon=corn_loc[0], image_collection=ndvi_regular, scale=10 ) In\u00a0[\u00a0]: Copied! <pre># Define datasets and colors\ndatasets = {\n    \"Wheat\": (\"#a87000\", wheat_ndvi, wheat_ndvi_regular),\n    \"Soybean\": (\"#267300\", soybean_ndvi, soybean_ndvi_regular),\n    \"Corn\": (\"#ffd400\", corn_ndvi, corn_ndvi_regular),\n}\n\nfig, axes = plt.subplots(2, 1, figsize=(10, 7), sharey=True)\n\n# Raw NDVI\nfor crop, (color, raw, regular) in datasets.items():\n    sns.lineplot(\n        data=raw,\n        x=\"time\",\n        y=\"ndvi\",\n        label=f\"{crop} NDVI\",\n        c=color,\n        marker=\"o\",\n        ax=axes[0],\n    )\n\naxes[0].set_title(\"Raw NDVI\")\naxes[0].set_ylabel(\"NDVI\")\n\n# Interpolated NDVI\nfor crop, (color, raw, regular) in datasets.items():\n    sns.lineplot(\n        data=regular,\n        x=\"time\",\n        y=\"ndvi\",\n        label=f\"{crop} NDVI Regular\",\n        c=color,\n        marker=\"o\",\n        markersize=5,\n        ax=axes[1],\n    )\n\naxes[1].set_title(\"Regular NDVI (5 Days Interval)\")\naxes[1].set_ylabel(\"NDVI\")\n\nplt.tight_layout()\nplt.show()\n</pre> # Define datasets and colors datasets = {     \"Wheat\": (\"#a87000\", wheat_ndvi, wheat_ndvi_regular),     \"Soybean\": (\"#267300\", soybean_ndvi, soybean_ndvi_regular),     \"Corn\": (\"#ffd400\", corn_ndvi, corn_ndvi_regular), }  fig, axes = plt.subplots(2, 1, figsize=(10, 7), sharey=True)  # Raw NDVI for crop, (color, raw, regular) in datasets.items():     sns.lineplot(         data=raw,         x=\"time\",         y=\"ndvi\",         label=f\"{crop} NDVI\",         c=color,         marker=\"o\",         ax=axes[0],     )  axes[0].set_title(\"Raw NDVI\") axes[0].set_ylabel(\"NDVI\")  # Interpolated NDVI for crop, (color, raw, regular) in datasets.items():     sns.lineplot(         data=regular,         x=\"time\",         y=\"ndvi\",         label=f\"{crop} NDVI Regular\",         c=color,         marker=\"o\",         markersize=5,         ax=axes[1],     )  axes[1].set_title(\"Regular NDVI (5 Days Interval)\") axes[1].set_ylabel(\"NDVI\")  plt.tight_layout() plt.show()"},{"location":"examples/regular_timeseries/#initialize-a-map-object","title":"Initialize a Map object\u00b6","text":"<p>Authenticate and initialize Earth Engine. If it doesn't work, specify a project name</p>"},{"location":"examples/regular_timeseries/#import-region-of-interest","title":"Import region of interest\u00b6","text":""},{"location":"examples/regular_timeseries/#import-cropland-data-layer-cdl","title":"Import Cropland Data Layer (CDL)\u00b6","text":""},{"location":"examples/regular_timeseries/#load-sentinel-2-image-collection-and-mask-clouds-and-shadows","title":"Load Sentinel-2 image collection and mask clouds and shadows\u00b6","text":""},{"location":"examples/regular_timeseries/#calculate-normalized-difference-vegetation-index-ndvi","title":"Calculate Normalized Difference Vegetation Index (NDVI)\u00b6","text":""},{"location":"examples/regular_timeseries/#create-regular-timeseries","title":"Create regular timeseries\u00b6","text":""},{"location":"examples/regular_timeseries/#extract-timelapse-for-raw-and-regular-ndvi-image-collection","title":"Extract timelapse for raw and regular NDVI image collection\u00b6","text":""},{"location":"examples/regular_timeseries/#plot-the-smoothed-ndvi-for-three-crop-samples","title":"Plot the smoothed NDVI for three crop samples\u00b6","text":""},{"location":"examples/timeseries_extraction/","title":"Timeseries extraction","text":"<p>Uncomment the following line to install geeagri if needed.</p> In\u00a0[\u00a0]: Copied! <pre># !pip install geeagri\n</pre> # !pip install geeagri In\u00a0[\u00a0]: Copied! <pre>import ee\nimport geemap\nfrom geeagri.extract import (\n    extract_timeseries_to_point,\n    extract_timeseries_to_polygon,\n    TimeseriesExtractor,\n)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.rcParams[\"font.family\"] = \"DeJavu Serif\"\nplt.rcParams[\"font.serif\"] = \"Times New Roman\"\n</pre> import ee import geemap from geeagri.extract import (     extract_timeseries_to_point,     extract_timeseries_to_polygon,     TimeseriesExtractor, )  import matplotlib.pyplot as plt import seaborn as sns  plt.rcParams[\"font.family\"] = \"DeJavu Serif\" plt.rcParams[\"font.serif\"] = \"Times New Roman\" In\u00a0[\u00a0]: Copied! <pre># ee.Authenticate()\n# ee.Initialize(project='your-project-id')\n\nMap = geemap.Map()\nMap\n</pre> # ee.Authenticate() # ee.Initialize(project='your-project-id')  Map = geemap.Map() Map In\u00a0[\u00a0]: Copied! <pre>bbox = [-100.612793, 29.084977, -95.679932, 31.896214]\npolygon = ee.Geometry.BBox(*bbox)\npolygon_style = {\"color\": \"red\", \"width\": 1}\nMap.addLayer(polygon, polygon_style, \"Polygon\")\nMap.centerObject(polygon, 8)\n\nlon, lat = -98.15, 30.50\npoint = ee.Geometry.Point([lon, lat])\nMap.addLayer(point, {\"color\": \"blue\"}, \"Point\")\n</pre> bbox = [-100.612793, 29.084977, -95.679932, 31.896214] polygon = ee.Geometry.BBox(*bbox) polygon_style = {\"color\": \"red\", \"width\": 1} Map.addLayer(polygon, polygon_style, \"Polygon\") Map.centerObject(polygon, 8)  lon, lat = -98.15, 30.50 point = ee.Geometry.Point([lon, lat]) Map.addLayer(point, {\"color\": \"blue\"}, \"Point\") In\u00a0[\u00a0]: Copied! <pre>era5_land = ee.ImageCollection(\"ECMWF/ERA5_LAND/DAILY_AGGR\")\n\n# Generate or load sample points\nsample = (\n    era5_land.first()\n    .select(\"temperature_2m_min\")\n    .sample(\n        region=polygon,\n        scale=11132,  # ~11 km\n        numPixels=100,  # number of samples\n        seed=42,\n        dropNulls=True,\n        tileScale=16,\n        geometries=True,\n    )\n)\n\n# Convert samples to GeoDataFrame\nsample_gdf = geemap.ee_to_gdf(sample)\nsample_gdf[\"ID\"] = sample_gdf.index\nsample_gdf = sample_gdf[[\"ID\", \"geometry\"]]\n\nprint(f\"Sample size: {sample_gdf.shape[0]}\")\nsample_gdf.head()\n</pre> era5_land = ee.ImageCollection(\"ECMWF/ERA5_LAND/DAILY_AGGR\")  # Generate or load sample points sample = (     era5_land.first()     .select(\"temperature_2m_min\")     .sample(         region=polygon,         scale=11132,  # ~11 km         numPixels=100,  # number of samples         seed=42,         dropNulls=True,         tileScale=16,         geometries=True,     ) )  # Convert samples to GeoDataFrame sample_gdf = geemap.ee_to_gdf(sample) sample_gdf[\"ID\"] = sample_gdf.index sample_gdf = sample_gdf[[\"ID\", \"geometry\"]]  print(f\"Sample size: {sample_gdf.shape[0]}\") sample_gdf.head() In\u00a0[\u00a0]: Copied! <pre># Extract timeseries in parallel for all samples\nts_extractor = TimeseriesExtractor(\n    image_collection=era5_land,\n    sample_gdf=sample_gdf,\n    identifier=\"ID\",\n    out_dir=\"test\",  # output directory\n    selectors=[\n        \"temperature_2m_min\",\n        \"temperature_2m_max\",\n        \"total_precipitation_sum\",\n        \"surface_solar_radiation_downwards_sum\",\n    ],\n    scale=11132,\n    num_processes=20,  # parallel processes\n    start_date=\"2000-01-01\",\n    end_date=\"2010-01-01\",\n)\n\n# Run extraction\nts_extractor.extract_timeseries()\n</pre> # Extract timeseries in parallel for all samples ts_extractor = TimeseriesExtractor(     image_collection=era5_land,     sample_gdf=sample_gdf,     identifier=\"ID\",     out_dir=\"test\",  # output directory     selectors=[         \"temperature_2m_min\",         \"temperature_2m_max\",         \"total_precipitation_sum\",         \"surface_solar_radiation_downwards_sum\",     ],     scale=11132,     num_processes=20,  # parallel processes     start_date=\"2000-01-01\",     end_date=\"2010-01-01\", )  # Run extraction ts_extractor.extract_timeseries() In\u00a0[\u00a0]: Copied! <pre>era5_land = ee.ImageCollection(\"ECMWF/ERA5_LAND/DAILY_AGGR\")\n\nera5_land_point_ts = extract_timeseries_to_point(\n    lat=lat,\n    lon=lon,\n    image_collection=era5_land,\n    start_date=\"2010-01-01\",\n    end_date=\"2015-01-01\",\n    band_names=[\n        \"temperature_2m_min\",\n        \"temperature_2m_max\",\n        \"total_precipitation_sum\",\n        \"surface_solar_radiation_downwards_sum\",\n    ],\n    scale=11132,\n)\n\nera5_land_polygon_ts = extract_timeseries_to_polygon(\n    polygon=polygon,\n    image_collection=era5_land,\n    start_date=\"2010-01-01\",\n    end_date=\"2015-01-01\",\n    band_names=[\n        \"temperature_2m_min\",\n        \"temperature_2m_max\",\n        \"total_precipitation_sum\",\n        \"surface_solar_radiation_downwards_sum\",\n    ],\n    scale=11132,\n    reducer=\"MEAN\",\n)\n</pre> era5_land = ee.ImageCollection(\"ECMWF/ERA5_LAND/DAILY_AGGR\")  era5_land_point_ts = extract_timeseries_to_point(     lat=lat,     lon=lon,     image_collection=era5_land,     start_date=\"2010-01-01\",     end_date=\"2015-01-01\",     band_names=[         \"temperature_2m_min\",         \"temperature_2m_max\",         \"total_precipitation_sum\",         \"surface_solar_radiation_downwards_sum\",     ],     scale=11132, )  era5_land_polygon_ts = extract_timeseries_to_polygon(     polygon=polygon,     image_collection=era5_land,     start_date=\"2010-01-01\",     end_date=\"2015-01-01\",     band_names=[         \"temperature_2m_min\",         \"temperature_2m_max\",         \"total_precipitation_sum\",         \"surface_solar_radiation_downwards_sum\",     ],     scale=11132,     reducer=\"MEAN\", ) In\u00a0[\u00a0]: Copied! <pre># Plot the data\nfig, axes = plt.subplots(nrows=2, ncols=1, figsize=(12, 6))\naxes = axes.flatten()\n\nsns.lineplot(\n    data=era5_land_point_ts,\n    x=\"time\",\n    y=\"temperature_2m_max\",\n    c=\"r\",\n    linewidth=0.5,\n    ax=axes[0],\n    label=\"Tmax\",\n)\nsns.lineplot(\n    data=era5_land_point_ts,\n    x=\"time\",\n    y=\"temperature_2m_min\",\n    c=\"b\",\n    linewidth=0.5,\n    ax=axes[0],\n    label=\"Tmax\",\n)\naxes[0].set_ylabel(\"Values\")\naxes[0].legend()\naxes[0].set_title(\"Daily timeseries of climate data based on point\")\n\nsns.lineplot(\n    data=era5_land_polygon_ts,\n    x=\"time\",\n    y=\"temperature_2m_max\",\n    c=\"r\",\n    linewidth=0.5,\n    ax=axes[1],\n    label=\"Tmax\",\n)\nsns.lineplot(\n    data=era5_land_polygon_ts,\n    x=\"time\",\n    y=\"temperature_2m_min\",\n    c=\"b\",\n    linewidth=0.5,\n    ax=axes[1],\n    label=\"Tmax\",\n)\naxes[1].set_ylabel(\"Values\")\naxes[1].legend()\naxes[1].set_title(\"Daily timeseries of climate data based on polygon\")\n\nplt.tight_layout()\nplt.show()\n</pre> # Plot the data fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(12, 6)) axes = axes.flatten()  sns.lineplot(     data=era5_land_point_ts,     x=\"time\",     y=\"temperature_2m_max\",     c=\"r\",     linewidth=0.5,     ax=axes[0],     label=\"Tmax\", ) sns.lineplot(     data=era5_land_point_ts,     x=\"time\",     y=\"temperature_2m_min\",     c=\"b\",     linewidth=0.5,     ax=axes[0],     label=\"Tmax\", ) axes[0].set_ylabel(\"Values\") axes[0].legend() axes[0].set_title(\"Daily timeseries of climate data based on point\")  sns.lineplot(     data=era5_land_polygon_ts,     x=\"time\",     y=\"temperature_2m_max\",     c=\"r\",     linewidth=0.5,     ax=axes[1],     label=\"Tmax\", ) sns.lineplot(     data=era5_land_polygon_ts,     x=\"time\",     y=\"temperature_2m_min\",     c=\"b\",     linewidth=0.5,     ax=axes[1],     label=\"Tmax\", ) axes[1].set_ylabel(\"Values\") axes[1].legend() axes[1].set_title(\"Daily timeseries of climate data based on polygon\")  plt.tight_layout() plt.show() In\u00a0[\u00a0]: Copied! <pre>modis_ndvi = ee.ImageCollection(\"MODIS/061/MOD13Q1\")\n\nmodis_ndvi_point_ts = extract_timeseries_to_point(\n    lat=lat,\n    lon=lon,\n    image_collection=modis_ndvi,\n    start_date=\"2010-01-01\",\n    end_date=\"2015-01-01\",\n    band_names=[\"NDVI\", \"EVI\"],\n    scale=250,\n)\n\nmodis_ndvi_polygon_ts = extract_timeseries_to_polygon(\n    polygon=polygon,\n    image_collection=modis_ndvi,\n    start_date=\"2010-01-01\",\n    end_date=\"2015-01-01\",\n    band_names=[\"NDVI\", \"EVI\"],\n    scale=250,\n    reducer=\"MEAN\",\n)\n\n# Apply scale factors\nmodis_ndvi_point_ts[[\"NDVI\", \"EVI\"]] = modis_ndvi_point_ts[[\"NDVI\", \"EVI\"]] * 0.0001\nmodis_ndvi_polygon_ts[[\"NDVI\", \"EVI\"]] = modis_ndvi_polygon_ts[[\"NDVI\", \"EVI\"]] * 0.0001\n</pre> modis_ndvi = ee.ImageCollection(\"MODIS/061/MOD13Q1\")  modis_ndvi_point_ts = extract_timeseries_to_point(     lat=lat,     lon=lon,     image_collection=modis_ndvi,     start_date=\"2010-01-01\",     end_date=\"2015-01-01\",     band_names=[\"NDVI\", \"EVI\"],     scale=250, )  modis_ndvi_polygon_ts = extract_timeseries_to_polygon(     polygon=polygon,     image_collection=modis_ndvi,     start_date=\"2010-01-01\",     end_date=\"2015-01-01\",     band_names=[\"NDVI\", \"EVI\"],     scale=250,     reducer=\"MEAN\", )  # Apply scale factors modis_ndvi_point_ts[[\"NDVI\", \"EVI\"]] = modis_ndvi_point_ts[[\"NDVI\", \"EVI\"]] * 0.0001 modis_ndvi_polygon_ts[[\"NDVI\", \"EVI\"]] = modis_ndvi_polygon_ts[[\"NDVI\", \"EVI\"]] * 0.0001 In\u00a0[\u00a0]: Copied! <pre># Plot the data\nfig, axes = plt.subplots(nrows=2, ncols=1, figsize=(12, 6))\naxes = axes.flatten()\n\nsns.lineplot(\n    data=modis_ndvi_point_ts,\n    x=\"time\",\n    y=\"NDVI\",\n    c=\"green\",\n    marker=\"o\",\n    markersize=5,\n    linewidth=1,\n    ax=axes[0],\n    label=\"NDVI\",\n)\nsns.lineplot(\n    data=modis_ndvi_point_ts,\n    x=\"time\",\n    y=\"EVI\",\n    c=\"orange\",\n    marker=\"o\",\n    markersize=5,\n    linewidth=1,\n    ax=axes[0],\n    label=\"EVI\",\n)\naxes[0].set_ylabel(\"Values\")\naxes[0].legend()\naxes[0].set_title(\"Daily timeseries of NDVI and EVI data based on point\")\n\nsns.lineplot(\n    data=modis_ndvi_polygon_ts,\n    x=\"time\",\n    y=\"NDVI\",\n    c=\"green\",\n    marker=\"o\",\n    markersize=5,\n    linewidth=1,\n    ax=axes[1],\n    label=\"NDVI\",\n)\nsns.lineplot(\n    data=modis_ndvi_polygon_ts,\n    x=\"time\",\n    y=\"EVI\",\n    c=\"orange\",\n    marker=\"o\",\n    markersize=5,\n    linewidth=1,\n    ax=axes[1],\n    label=\"EVI\",\n)\naxes[1].set_ylabel(\"Values\")\naxes[1].legend()\naxes[1].set_title(\"Daily timeseries of NDVI and EVI data based on polygon\")\n\nplt.tight_layout()\nplt.show()\n</pre> # Plot the data fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(12, 6)) axes = axes.flatten()  sns.lineplot(     data=modis_ndvi_point_ts,     x=\"time\",     y=\"NDVI\",     c=\"green\",     marker=\"o\",     markersize=5,     linewidth=1,     ax=axes[0],     label=\"NDVI\", ) sns.lineplot(     data=modis_ndvi_point_ts,     x=\"time\",     y=\"EVI\",     c=\"orange\",     marker=\"o\",     markersize=5,     linewidth=1,     ax=axes[0],     label=\"EVI\", ) axes[0].set_ylabel(\"Values\") axes[0].legend() axes[0].set_title(\"Daily timeseries of NDVI and EVI data based on point\")  sns.lineplot(     data=modis_ndvi_polygon_ts,     x=\"time\",     y=\"NDVI\",     c=\"green\",     marker=\"o\",     markersize=5,     linewidth=1,     ax=axes[1],     label=\"NDVI\", ) sns.lineplot(     data=modis_ndvi_polygon_ts,     x=\"time\",     y=\"EVI\",     c=\"orange\",     marker=\"o\",     markersize=5,     linewidth=1,     ax=axes[1],     label=\"EVI\", ) axes[1].set_ylabel(\"Values\") axes[1].legend() axes[1].set_title(\"Daily timeseries of NDVI and EVI data based on polygon\")  plt.tight_layout() plt.show()"},{"location":"examples/timeseries_extraction/#import-libraries","title":"Import libraries\u00b6","text":""},{"location":"examples/timeseries_extraction/#initialize-a-map-object","title":"Initialize a Map object\u00b6","text":"<p>Authenticate and initialize Earth Engine. If it doesn't work, specify a project name</p>"},{"location":"examples/timeseries_extraction/#import-region-of-interest","title":"Import region of interest\u00b6","text":""},{"location":"examples/timeseries_extraction/#parallel-export-of-timeseries-for-large-sample-sets-with-timeseriesextractor","title":"Parallel export of timeseries for large sample sets with <code>TimeseriesExtractor</code>\u00b6","text":""},{"location":"examples/timeseries_extraction/#export-single-timeseries-from-climate-data-era5-land-daily","title":"Export single timeseries from climate data (ERA5-Land Daily)\u00b6","text":""},{"location":"examples/timeseries_extraction/#export-single-timeseries-from-ndvi-data-mod13q1061-terra-vegetation-indices-16-day","title":"Export single timeseries from NDVI data (MOD13Q1.061 Terra Vegetation Indices 16-Day)\u00b6","text":""},{"location":"examples/timeseries_gap_filling/","title":"Timeseries gap filling","text":"<p>Uncomment the following line to install the latest version of geeagri if needed.</p> In\u00a0[\u00a0]: Copied! <pre># !pip install -U geeagri\n</pre> # !pip install -U geeagri In\u00a0[\u00a0]: Copied! <pre>import ee\nimport geemap\nfrom geeagri.preprocessing import Sentinel2CloudMask, TemporalInterpolation\nfrom geeagri.extract import extract_timeseries_to_point\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom datetime import datetime\nfrom PIL import Image, ImageDraw, ImageFont, ImageSequence\n\nplt.rcParams[\"font.family\"] = \"DeJavu Serif\"\nplt.rcParams[\"font.serif\"] = \"Times New Roman\"\n</pre> import ee import geemap from geeagri.preprocessing import Sentinel2CloudMask, TemporalInterpolation from geeagri.extract import extract_timeseries_to_point  import matplotlib.pyplot as plt import seaborn as sns  from datetime import datetime from PIL import Image, ImageDraw, ImageFont, ImageSequence  plt.rcParams[\"font.family\"] = \"DeJavu Serif\" plt.rcParams[\"font.serif\"] = \"Times New Roman\" In\u00a0[\u00a0]: Copied! <pre># ee.Authenticate()\n# ee.Initialize(project='your-project-id')\n\nMap = geemap.Map(basemap=\"SATELLITE\")\nMap\n</pre> # ee.Authenticate() # ee.Initialize(project='your-project-id')  Map = geemap.Map(basemap=\"SATELLITE\") Map In\u00a0[\u00a0]: Copied! <pre>bbox = [-98.451233, 38.430732, -98.274765, 38.523996]\nregion = ee.Geometry.BBox(*bbox)\nregion_style = {\"color\": \"red\", \"width\": 1}\nMap.addLayer(region, region_style, \"Region\")\nMap.centerObject(region, 13)\n</pre> bbox = [-98.451233, 38.430732, -98.274765, 38.523996] region = ee.Geometry.BBox(*bbox) region_style = {\"color\": \"red\", \"width\": 1} Map.addLayer(region, region_style, \"Region\") Map.centerObject(region, 13) In\u00a0[\u00a0]: Copied! <pre>croplandcover = (\n    ee.ImageCollection(\"USDA/NASS/CDL\")\n    .filterDate(\"2020-01-01\", \"2021-01-01\")\n    .first()\n    .clip(region)\n)\n\ncultivated = croplandcover.select(\"cultivated\").eq(2).selfMask()\ncroplandcover = croplandcover.select(\"cropland\")\nMap.addLayer(cultivated, {}, \"Cultivated\")\nMap.addLayer(croplandcover, {}, \"Crop Landcover\")\n</pre> croplandcover = (     ee.ImageCollection(\"USDA/NASS/CDL\")     .filterDate(\"2020-01-01\", \"2021-01-01\")     .first()     .clip(region) )  cultivated = croplandcover.select(\"cultivated\").eq(2).selfMask() croplandcover = croplandcover.select(\"cropland\") Map.addLayer(cultivated, {}, \"Cultivated\") Map.addLayer(croplandcover, {}, \"Crop Landcover\") In\u00a0[\u00a0]: Copied! <pre>s2_cloud_masker = Sentinel2CloudMask(\n    region=region,\n    start_date=\"2020-01-01\",\n    end_date=\"2021-01-01\",\n    cloud_filter=60,  # maximum scene-level cloudiness allowed (%)\n    cloud_prob_threshold=50,  # cloud probability threshold (values above are considered clouds)\n    nir_dark_threshold=0.15,  # NIR reflectance threshold (values below considered potential shadows)\n    shadow_proj_dist=1,  # maximum distance (km) to search for shadows from clouds.\n    buffer=50,  # buffer distance (m) to dilate cloud/shadow masks.\n)\n\ns2_cloud_masked = s2_cloud_masker.get_cloudfree_collection()\n</pre> s2_cloud_masker = Sentinel2CloudMask(     region=region,     start_date=\"2020-01-01\",     end_date=\"2021-01-01\",     cloud_filter=60,  # maximum scene-level cloudiness allowed (%)     cloud_prob_threshold=50,  # cloud probability threshold (values above are considered clouds)     nir_dark_threshold=0.15,  # NIR reflectance threshold (values below considered potential shadows)     shadow_proj_dist=1,  # maximum distance (km) to search for shadows from clouds.     buffer=50,  # buffer distance (m) to dilate cloud/shadow masks. )  s2_cloud_masked = s2_cloud_masker.get_cloudfree_collection() In\u00a0[\u00a0]: Copied! <pre>def calculateNDVI(image):\n    ndvi = image.expression(\n        \"(NIR - Red) / (NIR + Red)\",\n        {\"NIR\": image.select(\"B8\"), \"Red\": image.select(\"B4\")},\n    ).copyProperties(image, [\"system:time_start\"])\n\n    ndvi = ee.Image(ndvi).rename(\"ndvi\").clip(region)\n\n    return ndvi\n\n\nndvi_col = s2_cloud_masked.map(calculateNDVI)\n</pre> def calculateNDVI(image):     ndvi = image.expression(         \"(NIR - Red) / (NIR + Red)\",         {\"NIR\": image.select(\"B8\"), \"Red\": image.select(\"B4\")},     ).copyProperties(image, [\"system:time_start\"])      ndvi = ee.Image(ndvi).rename(\"ndvi\").clip(region)      return ndvi   ndvi_col = s2_cloud_masked.map(calculateNDVI) In\u00a0[\u00a0]: Copied! <pre># Initialize a 'TemporalInterpolation' object\ntemp_interp = TemporalInterpolation(\n    image_collection=ndvi_col,  # ee.ImageCollection of NDVI\n    window=45,  # Temporal window in days\n)\n\n# Get the interpolation collection\nndvi_interpolated = temp_interp.get_interpolated_collection()\n</pre> # Initialize a 'TemporalInterpolation' object temp_interp = TemporalInterpolation(     image_collection=ndvi_col,  # ee.ImageCollection of NDVI     window=45,  # Temporal window in days )  # Get the interpolation collection ndvi_interpolated = temp_interp.get_interpolated_collection() In\u00a0[\u00a0]: Copied! <pre># Function to add timestamp of gif frames\ndef add_dates_to_gif(\n    input_gif: str,\n    output_gif: str,\n    dates: list[str],\n    font_path: str = \"DejaVuSans-Bold.ttf\",\n    font_size: int = 20,\n    position: tuple = (20, 20),\n    color: str = \"red\",\n):\n    \"\"\"\n    Overlay a list of dates onto each frame of an animated GIF.\n\n    Args:\n        input_gif (str): Path to the input GIF file.\n        output_gif (str): Path where the output GIF will be saved.\n        dates (list[str]): List of date strings (one per frame).\n        font_path (str, optional): Path to a .ttf font file. Defaults to \"DejaVuSans-Bold.ttf\".\n        font_size (int, optional): Font size. Defaults to 40.\n        position (tuple, optional): (x, y) position of the text. Defaults to (20, 20).\n        color (str, optional): Text color. Defaults to \"black\".\n    \"\"\"\n    font = ImageFont.truetype(font_path, font_size)\n\n    with Image.open(input_gif) as im:\n        frames = []\n\n        for i, frame in enumerate(ImageSequence.Iterator(im)):\n            frame = frame.convert(\"RGB\")\n            draw = ImageDraw.Draw(frame)\n\n            if i &lt; len(dates):\n                draw.text(position, dates[i], fill=color, font=font)\n\n            frames.append(frame)\n\n        # Save the annotated frames as a new GIF\n        frames[0].save(\n            output_gif,\n            save_all=True,\n            append_images=frames[1:],\n            duration=im.info.get(\"duration\", 200),  # default 200ms if not found\n            loop=0,\n        )\n</pre> # Function to add timestamp of gif frames def add_dates_to_gif(     input_gif: str,     output_gif: str,     dates: list[str],     font_path: str = \"DejaVuSans-Bold.ttf\",     font_size: int = 20,     position: tuple = (20, 20),     color: str = \"red\", ):     \"\"\"     Overlay a list of dates onto each frame of an animated GIF.      Args:         input_gif (str): Path to the input GIF file.         output_gif (str): Path where the output GIF will be saved.         dates (list[str]): List of date strings (one per frame).         font_path (str, optional): Path to a .ttf font file. Defaults to \"DejaVuSans-Bold.ttf\".         font_size (int, optional): Font size. Defaults to 40.         position (tuple, optional): (x, y) position of the text. Defaults to (20, 20).         color (str, optional): Text color. Defaults to \"black\".     \"\"\"     font = ImageFont.truetype(font_path, font_size)      with Image.open(input_gif) as im:         frames = []          for i, frame in enumerate(ImageSequence.Iterator(im)):             frame = frame.convert(\"RGB\")             draw = ImageDraw.Draw(frame)              if i &lt; len(dates):                 draw.text(position, dates[i], fill=color, font=font)              frames.append(frame)          # Save the annotated frames as a new GIF         frames[0].save(             output_gif,             save_all=True,             append_images=frames[1:],             duration=im.info.get(\"duration\", 200),  # default 200ms if not found             loop=0,         ) In\u00a0[\u00a0]: Copied! <pre># Get the image dates\ndates = ndvi_col.aggregate_array(\"system:time_start\").getInfo()\ndates_str = [datetime.fromtimestamp(d / 1000).strftime(\"%d %b %Y\") for d in dates]\n\nvideo_args = {\n    \"dimensions\": 1000,\n    \"region\": region,\n    \"framesPerSecond\": 2,\n    \"crs\": \"EPSG:4326\",\n    \"min\": -1,\n    \"max\": 1,\n    \"palette\": [\n        \"#a50026\",\n        \"#d73027\",\n        \"#f46d43\",\n        \"#fdae61\",\n        \"#fee08b\",\n        \"#d9ef8b\",\n        \"#a6d96a\",\n        \"#66bd63\",\n        \"#1a9850\",\n        \"#006837\",\n    ],\n}\n\nsaved_ndvi_gif = \"ndvi.gif\"\ngeemap.download_ee_video(ndvi_col, video_args, saved_ndvi_gif)\n\n# add timestamps and plot the timelapse of raw NDVI\nadd_dates_to_gif(saved_ndvi_gif, saved_ndvi_gif, dates_str)\ngeemap.show_image(saved_ndvi_gif)\n</pre> # Get the image dates dates = ndvi_col.aggregate_array(\"system:time_start\").getInfo() dates_str = [datetime.fromtimestamp(d / 1000).strftime(\"%d %b %Y\") for d in dates]  video_args = {     \"dimensions\": 1000,     \"region\": region,     \"framesPerSecond\": 2,     \"crs\": \"EPSG:4326\",     \"min\": -1,     \"max\": 1,     \"palette\": [         \"#a50026\",         \"#d73027\",         \"#f46d43\",         \"#fdae61\",         \"#fee08b\",         \"#d9ef8b\",         \"#a6d96a\",         \"#66bd63\",         \"#1a9850\",         \"#006837\",     ], }  saved_ndvi_gif = \"ndvi.gif\" geemap.download_ee_video(ndvi_col, video_args, saved_ndvi_gif)  # add timestamps and plot the timelapse of raw NDVI add_dates_to_gif(saved_ndvi_gif, saved_ndvi_gif, dates_str) geemap.show_image(saved_ndvi_gif) In\u00a0[\u00a0]: Copied! <pre>saved_ndvi_interpolated_gif = \"ndvi_interpolated.gif\"\ngeemap.download_ee_video(ndvi_interpolated, video_args, saved_ndvi_interpolated_gif)\n\n# add timestamps and plot the timelapse of interpolated NDVI\nadd_dates_to_gif(saved_ndvi_interpolated_gif, saved_ndvi_interpolated_gif, dates_str)\ngeemap.show_image(saved_ndvi_interpolated_gif)\n</pre> saved_ndvi_interpolated_gif = \"ndvi_interpolated.gif\" geemap.download_ee_video(ndvi_interpolated, video_args, saved_ndvi_interpolated_gif)  # add timestamps and plot the timelapse of interpolated NDVI add_dates_to_gif(saved_ndvi_interpolated_gif, saved_ndvi_interpolated_gif, dates_str) geemap.show_image(saved_ndvi_interpolated_gif) In\u00a0[\u00a0]: Copied! <pre>wheat_loc = (-98.39630126953126, 38.46931531751283)\nsoybean_loc = (-98.34480285644533, 38.50008653288019)\ncorn_loc = (-98.3169937133789, 38.49645916887533)\n\nwheat_ndvi = extract_timeseries_to_point(\n    lat=wheat_loc[1], lon=wheat_loc[0], image_collection=ndvi_col, scale=10\n)\nsoybean_ndvi = extract_timeseries_to_point(\n    lat=soybean_loc[1], lon=soybean_loc[0], image_collection=ndvi_col, scale=10\n)\ncorn_ndvi = extract_timeseries_to_point(\n    lat=corn_loc[1], lon=corn_loc[0], image_collection=ndvi_col, scale=10\n)\nwheat_ndvi_interpolated = extract_timeseries_to_point(\n    lat=wheat_loc[1], lon=wheat_loc[0], image_collection=ndvi_interpolated, scale=10\n)\nsoybean_ndvi_interpolated = extract_timeseries_to_point(\n    lat=soybean_loc[1], lon=soybean_loc[0], image_collection=ndvi_interpolated, scale=10\n)\ncorn_ndvi_interpolated = extract_timeseries_to_point(\n    lat=corn_loc[1], lon=corn_loc[0], image_collection=ndvi_interpolated, scale=10\n)\n</pre> wheat_loc = (-98.39630126953126, 38.46931531751283) soybean_loc = (-98.34480285644533, 38.50008653288019) corn_loc = (-98.3169937133789, 38.49645916887533)  wheat_ndvi = extract_timeseries_to_point(     lat=wheat_loc[1], lon=wheat_loc[0], image_collection=ndvi_col, scale=10 ) soybean_ndvi = extract_timeseries_to_point(     lat=soybean_loc[1], lon=soybean_loc[0], image_collection=ndvi_col, scale=10 ) corn_ndvi = extract_timeseries_to_point(     lat=corn_loc[1], lon=corn_loc[0], image_collection=ndvi_col, scale=10 ) wheat_ndvi_interpolated = extract_timeseries_to_point(     lat=wheat_loc[1], lon=wheat_loc[0], image_collection=ndvi_interpolated, scale=10 ) soybean_ndvi_interpolated = extract_timeseries_to_point(     lat=soybean_loc[1], lon=soybean_loc[0], image_collection=ndvi_interpolated, scale=10 ) corn_ndvi_interpolated = extract_timeseries_to_point(     lat=corn_loc[1], lon=corn_loc[0], image_collection=ndvi_interpolated, scale=10 ) In\u00a0[\u00a0]: Copied! <pre># Define datasets and colors\ndatasets = {\n    \"Wheat\": (\"#a87000\", wheat_ndvi, wheat_ndvi_interpolated),\n    \"Soybean\": (\"#267300\", soybean_ndvi, soybean_ndvi_interpolated),\n    \"Corn\": (\"#ffd400\", corn_ndvi, corn_ndvi_interpolated),\n}\n\nfig, axes = plt.subplots(2, 1, figsize=(10, 7), sharey=True)\n\n# Raw NDVI\nfor crop, (color, raw, interp) in datasets.items():\n    sns.lineplot(\n        data=raw,\n        x=\"time\",\n        y=\"ndvi\",\n        label=f\"{crop} NDVI\",\n        c=color,\n        marker=\"o\",\n        ax=axes[0],\n    )\n\n    # plot NaNs as crosses\n    nan_points = raw[raw[\"ndvi\"].isna()]\n    axes[0].scatter(\n        nan_points[\"time\"],\n        [0] * len(nan_points),\n        marker=\"x\",\n        c=color,\n        label=f\"{crop} NaN\",\n    )\n\naxes[0].set_title(\"Raw NDVI (with gaps)\")\naxes[0].set_ylabel(\"NDVI\")\n\n# Interpolated NDVI\nfor crop, (color, raw, interp) in datasets.items():\n    sns.lineplot(\n        data=interp,\n        x=\"time\",\n        y=\"ndvi\",\n        label=f\"{crop} NDVI Interpolated\",\n        c=color,\n        marker=\"o\",\n        markersize=5,\n        ax=axes[1],\n    )\n\naxes[1].set_title(\"Interpolated NDVI\")\naxes[1].set_ylabel(\"NDVI\")\n\nplt.tight_layout()\nplt.show()\n</pre> # Define datasets and colors datasets = {     \"Wheat\": (\"#a87000\", wheat_ndvi, wheat_ndvi_interpolated),     \"Soybean\": (\"#267300\", soybean_ndvi, soybean_ndvi_interpolated),     \"Corn\": (\"#ffd400\", corn_ndvi, corn_ndvi_interpolated), }  fig, axes = plt.subplots(2, 1, figsize=(10, 7), sharey=True)  # Raw NDVI for crop, (color, raw, interp) in datasets.items():     sns.lineplot(         data=raw,         x=\"time\",         y=\"ndvi\",         label=f\"{crop} NDVI\",         c=color,         marker=\"o\",         ax=axes[0],     )      # plot NaNs as crosses     nan_points = raw[raw[\"ndvi\"].isna()]     axes[0].scatter(         nan_points[\"time\"],         [0] * len(nan_points),         marker=\"x\",         c=color,         label=f\"{crop} NaN\",     )  axes[0].set_title(\"Raw NDVI (with gaps)\") axes[0].set_ylabel(\"NDVI\")  # Interpolated NDVI for crop, (color, raw, interp) in datasets.items():     sns.lineplot(         data=interp,         x=\"time\",         y=\"ndvi\",         label=f\"{crop} NDVI Interpolated\",         c=color,         marker=\"o\",         markersize=5,         ax=axes[1],     )  axes[1].set_title(\"Interpolated NDVI\") axes[1].set_ylabel(\"NDVI\")  plt.tight_layout() plt.show()"},{"location":"examples/timeseries_gap_filling/#initialize-a-map-object","title":"Initialize a Map object\u00b6","text":"<p>Authenticate and initialize Earth Engine. If it doesn't work, specify a project name</p>"},{"location":"examples/timeseries_gap_filling/#import-region-of-interest","title":"Import region of interest\u00b6","text":""},{"location":"examples/timeseries_gap_filling/#import-cropland-data-layer-cdl","title":"Import Cropland Data Layer (CDL)\u00b6","text":""},{"location":"examples/timeseries_gap_filling/#load-sentinel-2-image-collection-and-mask-clouds-and-shadows","title":"Load Sentinel-2 image collection and mask clouds and shadows\u00b6","text":""},{"location":"examples/timeseries_gap_filling/#calculate-normalized-difference-vegetation-index-ndvi","title":"Calculate Normalized Difference Vegetation Index (NDVI)\u00b6","text":""},{"location":"examples/timeseries_gap_filling/#timeseries-gap-filling-using-temporal-interpolation","title":"Timeseries gap filling using Temporal Interpolation\u00b6","text":""},{"location":"examples/timeseries_gap_filling/#extract-timelapse-for-raw-and-interpolated-ndvi-image-collection","title":"Extract timelapse for raw and interpolated NDVI image collection\u00b6","text":""},{"location":"examples/timeseries_gap_filling/#plot-the-raw-and-interpolated-ndvi-for-three-crop-samples","title":"Plot the raw and interpolated NDVI for three crop samples\u00b6","text":""}]}